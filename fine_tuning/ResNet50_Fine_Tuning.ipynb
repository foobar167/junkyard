{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc26bc89-3b17-4a26-a012-b9f69082caae",
   "metadata": {},
   "source": [
    "# ResNet50 fine-tuning for classification on medical images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e75150-16a0-4c9b-8872-d99036ca6537",
   "metadata": {},
   "source": [
    "## Part 1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92289daf-7717-4312-8d8a-10c97dfb6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main variables\n",
    "gpu = 3  # for DL4 server GPU can be: 0 (H800), 1 (V100), 2 (V100), 3 (V100), 4 (V100).\n",
    "out_dir = \"./outputs_ResNet\"\n",
    "\n",
    "model_name = \"wide_resnet50_2.tv2_in1k\"  # ResNet50 for 224x224 images\n",
    "patience = 10  # how long to wait after the last best improvement before stopping\n",
    "\n",
    "# data_dir = \"/share/data/lab225/ViT/img_CT_224_Gray_MF_c1_c2_c3\"  # dataset directory\n",
    "# csv_out_1   = f\"{out_dir}/FTR_G2_F_c1_train_fnames.csv\"  # CVS file with file names\n",
    "# csv_out_2   = f\"{out_dir}/FTR_G2_F_c1_train_featur.csv\"  # CVS file with features\n",
    "\n",
    "data_dir = \"./xray_dataset\"  # dataset directory\n",
    "csv_out_1   = f\"{out_dir}/FTR_path_train_fnames.csv\"  # CVS file with file names\n",
    "csv_out_2   = f\"{out_dir}/FTR_path_train_featur.csv\"  # CVS file with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b2dcd0-9a33-40f4-91fc-b0e483693ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n",
      "Classes (2): ['norm', 'path']\n",
      "\n",
      "Epoch 1/50\n",
      "Train: loss=0.6994, accuracy=47.74% | Val: loss=0.6873, accuracy=54.55% | 0.5 min\n",
      "\t Saved new best model: val accuracy=54.55%, val loss=0.6873.\n",
      "\n",
      "Epoch 2/50\n",
      "Train: loss=0.6890, accuracy=52.95% | Val: loss=0.6889, accuracy=54.55% | 0.2 min\n",
      "\n",
      "Epoch 3/50\n",
      "Train: loss=0.6554, accuracy=70.31% | Val: loss=0.6865, accuracy=50.00% | 0.2 min\n",
      "\t Saved new best model: val accuracy=50.00%, val loss=0.6865.\n",
      "\n",
      "Epoch 4/50\n",
      "Train: loss=0.5998, accuracy=86.63% | Val: loss=0.6747, accuracy=51.52% | 0.2 min\n",
      "\t Saved new best model: val accuracy=51.52%, val loss=0.6747.\n",
      "\n",
      "Epoch 5/50\n",
      "Train: loss=0.5304, accuracy=92.71% | Val: loss=0.6073, accuracy=77.27% | 0.2 min\n",
      "\t Saved new best model: val accuracy=77.27%, val loss=0.6073.\n",
      "\n",
      "Epoch 6/50\n",
      "Train: loss=0.4434, accuracy=95.83% | Val: loss=0.5615, accuracy=75.76% | 0.1 min\n",
      "\t Saved new best model: val accuracy=75.76%, val loss=0.5615.\n",
      "\n",
      "Epoch 7/50\n",
      "Train: loss=0.3447, accuracy=97.05% | Val: loss=0.5053, accuracy=77.27% | 0.1 min\n",
      "\t Saved new best model: val accuracy=77.27%, val loss=0.5053.\n",
      "\n",
      "Epoch 8/50\n",
      "Train: loss=0.2393, accuracy=99.13% | Val: loss=0.4575, accuracy=80.30% | 0.1 min\n",
      "\t Saved new best model: val accuracy=80.30%, val loss=0.4575.\n",
      "\n",
      "Epoch 9/50\n",
      "Train: loss=0.1538, accuracy=99.48% | Val: loss=0.4115, accuracy=84.85% | 0.1 min\n",
      "\t Saved new best model: val accuracy=84.85%, val loss=0.4115.\n",
      "\n",
      "Epoch 10/50\n",
      "Train: loss=0.0884, accuracy=100.00% | Val: loss=0.3939, accuracy=87.88% | 0.2 min\n",
      "\t Saved new best model: val accuracy=87.88%, val loss=0.3939.\n",
      "\n",
      "Epoch 11/50\n",
      "Train: loss=0.0491, accuracy=100.00% | Val: loss=0.3792, accuracy=86.36% | 0.1 min\n",
      "\t Saved new best model: val accuracy=86.36%, val loss=0.3792.\n",
      "\n",
      "Epoch 12/50\n",
      "Train: loss=0.0299, accuracy=100.00% | Val: loss=0.3798, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 13/50\n",
      "Train: loss=0.0201, accuracy=100.00% | Val: loss=0.3815, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Epoch 14/50\n",
      "Train: loss=0.0189, accuracy=100.00% | Val: loss=0.3622, accuracy=87.88% | 0.1 min\n",
      "\t Saved new best model: val accuracy=87.88%, val loss=0.3622.\n",
      "\n",
      "Epoch 15/50\n",
      "Train: loss=0.0102, accuracy=100.00% | Val: loss=0.3746, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Epoch 16/50\n",
      "Train: loss=0.0082, accuracy=100.00% | Val: loss=0.3826, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 17/50\n",
      "Train: loss=0.0076, accuracy=100.00% | Val: loss=0.3850, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 18/50\n",
      "Train: loss=0.0041, accuracy=100.00% | Val: loss=0.3802, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 19/50\n",
      "Train: loss=0.0034, accuracy=100.00% | Val: loss=0.3825, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 20/50\n",
      "Train: loss=0.0026, accuracy=100.00% | Val: loss=0.3913, accuracy=89.39% | 0.1 min\n",
      "\n",
      "Epoch 21/50\n",
      "Train: loss=0.0023, accuracy=100.00% | Val: loss=0.4056, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Epoch 22/50\n",
      "Train: loss=0.0021, accuracy=100.00% | Val: loss=0.4341, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Epoch 23/50\n",
      "Train: loss=0.0014, accuracy=100.00% | Val: loss=0.4139, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Epoch 24/50\n",
      "Train: loss=0.0024, accuracy=100.00% | Val: loss=0.4380, accuracy=87.88% | 0.1 min\n",
      "\n",
      "Stopping early as no improvement has been observed in 10 epochs.\n",
      "\n",
      "Training complete.\n",
      "Best Val Acc: 87.88%. Minimal Val Loss: 0.3622\n",
      "Saved to: ./outputs_ResNet50\n",
      "Test: loss=0.0441, accuracy=98.79%\n"
     ]
    }
   ],
   "source": [
    "# Expected data layout:\n",
    "# data/\n",
    "#     train/\n",
    "#         classA/\n",
    "#         classB/\n",
    "#         ….\n",
    "#     val/ (optional; will be auto-split from train if missing)\n",
    "#         classA/\n",
    "#         classB/\n",
    "#         ….\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import timm  # requires: pip install timm\n",
    "import random\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = False\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def build_transforms(img_size=224):\n",
    "    # # previous mean and STD values\n",
    "    # mean = [0.485, 0.456, 0.406]\n",
    "    # std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # new mean and STD values\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        transforms.Resize(int(img_size)),\n",
    "        # transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0)),\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    val_tfms = transforms.Compose([\n",
    "        transforms.Resize(int(img_size)),\n",
    "        # transforms.Resize(int(img_size * 1.14)),\n",
    "        # transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tfms, val_tfms\n",
    "\n",
    "\n",
    "def create_dataloaders(data_dir, batch_size, num_workers, img_size, val_split):\n",
    "    train_tfms, val_tfms = build_transforms(img_size)\n",
    "\n",
    "    train_dir = Path(data_dir) / \"train\"\n",
    "    val_dir = Path(data_dir) / \"val\"\n",
    "\n",
    "    if train_dir.exists() and val_dir.exists():\n",
    "        train_ds = datasets.ImageFolder(str(train_dir), transform=train_tfms)\n",
    "        val_ds = datasets.ImageFolder(str(val_dir), transform=val_tfms)\n",
    "    else:\n",
    "        # Single folder with class subfolders; auto-split into train/val\n",
    "        base_dir = train_dir if train_dir.exists() else Path(data_dir)\n",
    "        full_ds = datasets.ImageFolder(str(base_dir), transform=train_tfms)\n",
    "        n_total = len(full_ds)\n",
    "        n_val = int(n_total * val_split)\n",
    "        n_train = n_total - n_val\n",
    "        train_ds, val_ds = random_split(\n",
    "            full_ds, [n_train, n_val],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        # Apply val transforms to the validation subset\n",
    "        val_ds.dataset = datasets.ImageFolder(\n",
    "            str(base_dir),\n",
    "            transform=val_tfms\n",
    "        )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    classes = train_ds.dataset.classes \\\n",
    "        if hasattr(train_ds, \"dataset\") \\\n",
    "        else train_ds.classes\n",
    "    num_classes = len(classes)\n",
    "    return train_loader, val_loader, num_classes, classes\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    model_name, num_classes,\n",
    "    pretrained=True, freeze_backbone=False\n",
    "):\n",
    "    # global_pool='avg' yields pooled features (B, C) from forward_features\n",
    "    model = timm.create_model(\n",
    "        model_name, pretrained=pretrained,\n",
    "        num_classes=num_classes, global_pool='avg'\n",
    "    )\n",
    "\n",
    "    if freeze_backbone:\n",
    "        stop_words = ['head', 'fc', 'classifier']\n",
    "        for name, p in model.named_parameters():\n",
    "            if all(sw not in name for sw in stop_words):\n",
    "                p.requires_grad = False\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1))\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "            res.append((correct_k * (100.0 / target.size(0))).item())\n",
    "        return res\n",
    "\n",
    "\n",
    "def create_optimizer(model, lr, weight_decay):\n",
    "    # Only update trainable parameters\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    return torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "def create_scheduler(optimizer, warmup_epochs, max_epochs, train_loader_len):\n",
    "    # Linear warmup then cosine decay\n",
    "    total_steps = max_epochs * train_loader_len\n",
    "    warmup_steps = warmup_epochs * train_loader_len\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        if step < warmup_steps:\n",
    "            return float(step) / float(max(1, warmup_steps))\n",
    "        # Cosine decay from 1.0 to 0.0\n",
    "        progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "        return 0.5 * (1.0 + torch.cos(torch.tensor(progress * 3.1415926535))).item()\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model, loader, optimizer, scaler,\n",
    "    device, criterion, log_interval=50\n",
    "):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc1 = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.autocast(device, dtype=torch.float32):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        acc1 = accuracy(outputs, targets, topk=(1,))[0]\n",
    "        bs = images.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc1 += acc1 * bs\n",
    "        n += bs\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            print(f\"\\t[batch {i+1}/{len(loader)}] loss={running_loss/n:.4f} acc1={running_acc1/n:.2f}%\")\n",
    "\n",
    "    return running_loss / n, running_acc1 / n\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc1 = 0.0\n",
    "    n = 0\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        with torch.autocast(device, dtype=torch.float32):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "        acc1 = accuracy(outputs, targets, topk=(1,))[0]\n",
    "        bs = images.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc1 += acc1 * bs\n",
    "        n += bs\n",
    "    return running_loss / n, running_acc1 / n\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, accuracy, loss, path):\n",
    "    state = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict() if scheduler is not None else None,\n",
    "        \"epoch\": epoch,\n",
    "        \"best_val_acc\": accuracy,\n",
    "        \"min_val_loss\": loss,\n",
    "    }\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def train(model, device, args, train_loader, val_loader, num_classes,\n",
    "          class_names, out_dir, ckpt_path, patience, freeze):\n",
    "    \"\"\" Train the model. \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = create_optimizer(model, args.lr, args.weight_decay)\n",
    "    scheduler = create_scheduler(optimizer, args.warmup_epochs, args.epochs, len(train_loader))\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled=(device == \"cuda\"))\n",
    "\n",
    "    start_epoch = 0\n",
    "    no_improvement_count = 0\n",
    "    best_val_acc = 0.0  # validation accuracy\n",
    "    min_val_loss = float(\"inf\")  # minimal validation loss\n",
    "\n",
    "    if args.resume and os.path.isfile(args.resume):\n",
    "        ckpt = torch.load(args.resume, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "        if ckpt.get(\"optimizer\"):\n",
    "            optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        if ckpt.get(\"scheduler\") and scheduler is not None and ckpt[\"scheduler\"] is not None:\n",
    "            scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
    "        start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
    "        best_val_acc = ckpt.get(\"best_val_acc\")\n",
    "        min_val_loss = ckpt.get(\"min_val_loss\")\n",
    "        print(f\"\\n\" f\"Resumed from '{args.resume}' at epoch {start_epoch}. \"\n",
    "              f\"Accuracy: {best_val_acc:.2f}%. Loss: {min_val_loss:.4f}.\")\n",
    "\n",
    "    if freeze:  # model weights are freezed\n",
    "        pass\n",
    "    else:  # unfreeze model weights\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        if float(f\"{best_val_acc:.2f}\") == 100.0:\n",
    "            print(f\"\\n\" f\"All images classified correctly with {best_val_acc:.2f}% validation accuracy.\")\n",
    "            break  # exit from the training cycle\n",
    "\n",
    "        if float(f\"{min_val_loss:.4f}\") == 0.0:\n",
    "            print(f\"\\n\" f\"Stopping early as loss is zero {min_val_loss:.4f}.\")\n",
    "            break  # exit from the training cycle\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{args.epochs}\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer,\n",
    "                                                scaler, device, criterion)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, device, criterion)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"Train: loss={train_loss:.4f}, accuracy={train_acc:.2f}% | \"\n",
    "              f\"Val: loss={val_loss:.4f}, accuracy={val_acc:.2f}% | {dt/60:.1f} min\")\n",
    "\n",
    "        # Save best\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            no_improvement_count = 0\n",
    "            # torch.save(model.state_dict(), os.path.join(args.out_dir, \"best_model_weights.pt\"))\n",
    "            # Save checkpoint\n",
    "            save_checkpoint(model, optimizer, scheduler, epoch,\n",
    "                            best_val_acc, min_val_loss, ckpt_path)\n",
    "            print(f\"\\t Saved new best model: val accuracy={best_val_acc:.2f}%, \"\n",
    "                  f\"val loss={min_val_loss:.4f}.\")\n",
    "        else:  # no improvement\n",
    "            no_improvement_count += 1\n",
    "            # Exit from training if no improvement for \"patience\" epochs.\n",
    "            if no_improvement_count >= patience:\n",
    "                print(f\"\\n\" f\"Stopping early as no improvement has been observed in {patience} epochs.\")\n",
    "                break  # exit from the training cycle\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "    print(f\"Best Val Acc: {best_val_acc:.2f}%. Minimal Val Loss: {min_val_loss:.4f}\")\n",
    "    print(f\"Saved to: {args.out_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "def create_test_loader(data_dir, batch_size, num_workers, img_size):\n",
    "    _, test_tfms = build_transforms(img_size)\n",
    "\n",
    "    test_dir = Path(data_dir) / \"test\"\n",
    "    test_ds = datasets.ImageFolder(str(test_dir), transform=test_tfms)\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    return test_loader\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # If all arguments have a default value, then adding this to the top of the notebook should be enough\n",
    "    sys.argv = [\"\"]\n",
    "    \n",
    "    # gpu = 3  # for DL4 server GPU can be: 0 (H800), 1 (V100), 2 (V100), 3 (V100), 4 (V100).\n",
    "    # out_dir = \"./outputs_ResNet50\"\n",
    "\n",
    "    # data_dir = \"/share/data/lab225/ViT/img_CT_224_Gray_MF_c1_c2_c3\"\n",
    "    # # data_dir = \"/share/data/lab225/ViT/img_6K_CT_224_Gray_RG\"  # dataset directory\n",
    "    \n",
    "    ckpt_path = os.path.join(out_dir, \"best_checkpoint.pt\")\n",
    "\n",
    "    # NOTE: all input arguments are hardcoded, i.e. have default value\n",
    "    parser = argparse.ArgumentParser(description=\"Fine-tune ResNet50 on your dataset\")\n",
    "    parser.add_argument(\"--data_dir\", type=str, default=data_dir, help=\"Dataset root. Expect data/train[/val] or single folder of classes.\")\n",
    "    parser.add_argument(\"--out_dir\", type=str, default=out_dir, help=\"Where to save checkpoints.\")\n",
    "    parser.add_argument(\"--model_name\", type=str, default=model_name)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)  # 50\n",
    "    parser.add_argument(\"--warmup_epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-5)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--img_size\", type=int, default=224)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=math.ceil(multiprocessing.cpu_count()*2/3))\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--freeze_backbone\", action=\"store_true\", help=\"Only train the classification head.\")\n",
    "    parser.add_argument(\"--val_split\", type=float, default=0.1, help=\"If no val folder, split this fraction from train.\")\n",
    "    parser.add_argument(\"--resume\", type=str, default=ckpt_path, help=\"Path to a checkpoint to resume from.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "    device = f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_loader, val_loader, num_classes, class_names = create_dataloaders(\n",
    "        args.data_dir, args.batch_size, args.num_workers, args.img_size, args.val_split\n",
    "    )\n",
    "    print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "    model = build_model(args.model_name, num_classes, pretrained=True,\n",
    "                        freeze_backbone=args.freeze_backbone)\n",
    "    model.to(device)\n",
    "    \n",
    "    train(model, device, args, train_loader, val_loader, num_classes,\n",
    "          class_names, out_dir, ckpt_path, patience, freeze=True)\n",
    "\n",
    "    # print(f\"\\n\\n-----------\\n\" f\"Unfreeze model weights and train it again\")\n",
    "    # train(model, device, args, train_loader, val_loader, num_classes,\n",
    "    #       class_names, out_dir, ckpt_path, patience=25, freeze=False)\n",
    "\n",
    "    test_dir = Path(args.data_dir) / \"test\"\n",
    "    if os.path.exists(test_dir):\n",
    "        test_loader = create_test_loader(\n",
    "            args.data_dir, args.batch_size, args.num_workers, args.img_size\n",
    "        )\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        test_loss, test_acc = evaluate(model, test_loader, device, criterion)\n",
    "        print(f\"Test: loss={test_loss:.4f}, accuracy={test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d7da7-259d-48e7-b7a1-d1b2a957f04c",
   "metadata": {},
   "source": [
    "## Run Log\n",
    "\n",
    "### Date: 02.09.2025\n",
    "\n",
    "#### Run 1\n",
    "\n",
    "    Best Val Acc: 87.88%. Minimal Val Loss: 0.3622\n",
    "    Epoch 14/50\n",
    "    Train: loss=0.0189, accuracy=100.00% | Val: loss=0.3622, accuracy=87.88% | 0.1 min\n",
    "    \t Saved new best model: val accuracy=87.88%, val loss=0.3622.\n",
    "\n",
    "### Date: 01.09.2025\n",
    "\n",
    "#### Run 1\n",
    "Run for dataset `xray_dataset` with x-rays.\n",
    "\n",
    "Test dataset == train dataset.\n",
    "\n",
    "    Test: loss=0.0456, accuracy=98.79%\n",
    "    Best Val Acc: 87.88%. Minimal Val Loss: 0.3694\n",
    "    Epoch 14/50\n",
    "    Train: loss=0.0190, accuracy=100.00% | Val: loss=0.3694, accuracy=87.88% | 0.1 min\n",
    "    \t Saved new best model: val accuracy=87.88%, val loss=0.3694.\n",
    "\n",
    "### Date: 25.08.2025\n",
    "\n",
    "#### Run 3\n",
    "Final run. Dataset: `/share/data/lab225/ViT/img_CT_224_Gray_MF_c1_c2_c3`.\n",
    "\n",
    "    Test: loss=0.0149, accuracy=99.56%\n",
    "    Best Val Acc: 100.00%. Minimal Val Loss: 0.0036\n",
    "    Epoch 23/50\n",
    "    \t[batch 50/143] loss=0.0053 acc1=100.00%\n",
    "    \t[batch 100/143] loss=0.0056 acc1=100.00%\n",
    "    Train: loss=0.0052, accuracy=100.00% | Val: loss=0.0036, accuracy=100.00% | 1.1 min\n",
    "    \t Saved new best model (val accuracy=100.00%).\n",
    "\n",
    "#### Run 4\n",
    "Final run. Dataset: `/share/data/lab225/ViT/img_6K_CT_224_Gray_RG`.\n",
    "\n",
    "    Test: loss=0.0126, accuracy=100.00%\n",
    "    Best Val Acc: 100.00%. Minimal Val Loss: 0.0125\n",
    "    Epoch 11/50\n",
    "    \t[batch 50/281] loss=0.0259 acc1=99.75%\n",
    "    \t[batch 100/281] loss=0.0251 acc1=99.78%\n",
    "    \t[batch 150/281] loss=0.0236 acc1=99.83%\n",
    "    \t[batch 200/281] loss=0.0230 acc1=99.84%\n",
    "    \t[batch 250/281] loss=0.0217 acc1=99.85%\n",
    "    Train: loss=0.0209, accuracy=99.86% | Val: loss=0.0125, accuracy=100.00% | 1.7 min\n",
    "    \t Saved new best model: val accuracy=100.00%, val loss=0.0125.\n",
    "\n",
    "#### Run 1\n",
    "Run ResNet50 on CT slices. 6 classes: female-male, shoulders-lungs-abdomen.\n",
    "\n",
    "Dataset: `/share/data/lab225/ViT/img_CT_224_Gray_MF_c1_c2_c3`\n",
    "\n",
    "    Best Val Acc: 100.00%. Minimal Val Loss: 0.0036\n",
    "    Epoch 23/50\n",
    "    \t[batch 50/143] loss=0.0054 acc1=100.00%\n",
    "    \t[batch 100/143] loss=0.0057 acc1=100.00%\n",
    "    Train: loss=0.0053, acc1=100.00% | Val: loss=0.0036, acc1=100.00% | 0.5 min\n",
    "    \t Saved new best model (val acc1=100.00%).\n",
    "\n",
    "#### Run 2\n",
    "Run ResNet50 on X-Ray images. 2 classes: real-generated lungs.\n",
    "\n",
    "Dataset: `/share/data/lab225/ViT/img_6K_CT_224_Gray_RG`.\n",
    "\n",
    "    Best Val Acc: 100.00%. Minimal Val Loss: 0.0031\n",
    "    Epoch 16/50\n",
    "    \t[batch 50/281] loss=0.0043 acc1=100.00%\n",
    "    \t[batch 100/281] loss=0.0044 acc1=100.00%\n",
    "    \t[batch 150/281] loss=0.0039 acc1=100.00%\n",
    "    \t[batch 200/281] loss=0.0037 acc1=100.00%\n",
    "    \t[batch 250/281] loss=0.0034 acc1=100.00%\n",
    "    Train: loss=0.0034, acc1=100.00% | Val: loss=0.0031, acc1=100.00% | 0.9 min\n",
    "    \t Saved new best model (val acc1=100.00%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b06cc-603e-4a40-8f2e-e8ad209608e6",
   "metadata": {},
   "source": [
    "## Part 2. Create CSV files with features\n",
    "\n",
    "Open previously saved fine-tuned model and use it to create CVS files with features and corresponding file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57375ab-d981-48a2-b7f2-d99d2b8bca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:3\n",
      "Classes (2): ['norm', 'path']\n",
      "\n",
      "Resumed from './outputs_ResNet50/best_checkpoint.pt' at epoch 14. Accuracy: 87.88%. Loss: 0.3622.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from './xray_dataset/test/norm' directory are saved to file './outputs_ResNet50/FTR_norm_featur.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from './xray_dataset/test/path' directory are saved to file './outputs_ResNet50/FTR_path_featur.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from './xray_dataset/train/norm' directory are saved to file './outputs_ResNet50/FTR_norm_train_featur.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from './xray_dataset/train/path' directory are saved to file './outputs_ResNet50/FTR_path_train_featur.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === Config ===\n",
    "\n",
    "# gpu = 3  # for DL4 server GPU can be: 0 (H800), 1 (V100), 2 (V100), 3 (V100), 4 (V100).\n",
    "# out_dir = \"./outputs_ResNet50\"\n",
    "# model_name = \"wide_resnet50_2.tv2_in1k\"  # ResNet50 for 224x224 images\n",
    "\n",
    "# data_dir = \"/share/data/lab225/ViT/img_CT_224_Gray_MF_c1_c2_c3\"  # folder with JPG or PNG files\n",
    "# # data_dir = \"/share/data/lab225/ViT/img_6K_CT_224_Gray_RG\"\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, \"best_checkpoint.pt\")\n",
    "img_size = 224\n",
    "\n",
    "\n",
    "import timm  # requires: pip install timm\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = False\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    model_name, num_classes,\n",
    "    pretrained=True, freeze_backbone=False\n",
    "):\n",
    "    # global_pool='avg' yields pooled features (B, C) from forward_features\n",
    "    model = timm.create_model(\n",
    "        model_name, pretrained=pretrained,\n",
    "        num_classes=num_classes, global_pool='avg'\n",
    "    )\n",
    "\n",
    "    if freeze_backbone:\n",
    "        stop_words = ['head', 'fc', 'classifier']\n",
    "        for name, p in model.named_parameters():\n",
    "            if all(sw not in name for sw in stop_words):\n",
    "                p.requires_grad = False\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# For timm Vision Transformers, 'forward_features' returns the embeddings\n",
    "def extract_features(img_path):\n",
    "    \"\"\" Extract features from image. \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_t = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feats = model.forward_features(img_t)\n",
    "        # print(feats.shape)  # torch.Size([1, 197, 768])\n",
    "\n",
    "        # Flatten to 1D vector\n",
    "        vec = model.forward_head(feats, pre_logits=True)  # get PyTorch tensor\n",
    "        vec = vec.cpu().numpy()  # copy to CPU and convert PyTorch to NumPy\n",
    "        # print(vec.shape)  # shape: (1, 768)\n",
    "        vec = vec[0].tolist()  # squeeze NumPy and convert to list\n",
    "        # Convert list to string. Left only 4 digits after the decimal points.\n",
    "        vec = \" \".join([f\"{i:.4f}\" for i in vec])\n",
    "        return vec\n",
    "\n",
    "\n",
    "def check_the_same_name(csv_name, csv_files, root):\n",
    "    \"\"\" Check for the same name in `csv_files` list\n",
    "        and change new CSV file name to make it unique. \"\"\"\n",
    "    check = True\n",
    "    while check:\n",
    "        for csv_f in csv_files:\n",
    "            if csv_name in csv_f:\n",
    "                # Add parent directory name to the end of CSV file.\n",
    "                parent_dir = root[:-len(csv_name)-1]  # parent directory\n",
    "                csv_name += \"_\" + os.path.basename(parent_dir)\n",
    "                break  # exit from \"for\" loop\n",
    "        check = False  # stop \"while\" loop\n",
    "    return csv_name\n",
    "\n",
    "\n",
    "def get_csv_dict(data_dir):\n",
    "    \"\"\" Get CSV dictionary of directories with images. \"\"\"\n",
    "    csv_files = {}  # CSV file name --> path to image directory\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        # check for images in the directory\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)  # full path to the file\n",
    "            # Check if the path is a file and ends with the .png extension.\n",
    "            if os.path.isfile(file_path) and file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                csv_name = os.path.basename(root)\n",
    "                csv_name = check_the_same_name(csv_name, csv_files, root)\n",
    "                csv_files[csv_name] = root\n",
    "                break  # stop checking file names\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def save_features(csv_name, dir_path, model, transform):\n",
    "    \"\"\" Save features into a CSV file. \"\"\"\n",
    "    feature_list = []\n",
    "    file_names = []\n",
    "    f = []\n",
    "\n",
    "    for fname in tqdm(os.listdir(dir_path), desc=\"Saving features\", leave=False):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            fpath = os.path.join(dir_path, fname)\n",
    "            vec = extract_features(fpath)\n",
    "            feature_list.append(vec)\n",
    "            file_names.append(fname)\n",
    "\n",
    "    for i in range(len(feature_list)):\n",
    "        feature = feature_list[i]  # get the first row in (197, 768)\n",
    "        f.append(feature)\n",
    "\n",
    "    df = pd.DataFrame({\"file_name\": file_names, \"feature_vector\": f})\n",
    "    csv_out_1 = os.path.join(out_dir, f\"FTR_{csv_name}_fnames.csv\")\n",
    "    csv_out_2 = os.path.join(out_dir, f\"FTR_{csv_name}_featur.csv\")\n",
    "    # Save file names and features in separate CSV. Don't save indices and header line\n",
    "    df.to_csv(csv_out_1, columns=[\"file_name\"], index=False, header=False)\n",
    "    df.to_csv(csv_out_2, columns=[\"feature_vector\"], index=False, header=False)\n",
    "    print(f\"\\r\" f\"Features from '{dir_path}' directory are saved to file '{csv_out_2}'.\")\n",
    "\n",
    "    # # === Check ===\n",
    "    # print(f\"\\n\" f\"Show contents of '{csv_out}' file\")\n",
    "    # print(df[:3]) # display the first 10 rows\n",
    "\n",
    "\n",
    "def get_number_of_classes(path):\n",
    "    \"\"\" Get number of classes. \"\"\"\n",
    "    directories = []\n",
    "    for i in os.listdir(path):\n",
    "        full_path = os.path.join(path, i)\n",
    "        if os.path.isdir(full_path):\n",
    "            directories.append(i)\n",
    "    num_classes = len(directories)\n",
    "    print(f\"Classes ({num_classes}): {directories}\")\n",
    "    return num_classes\n",
    "\n",
    "\n",
    "\n",
    "set_seed()  # set random seed for reproducibility\n",
    "os.makedirs(out_dir, exist_ok=True)  # create output directory if doesn't exist\n",
    "\n",
    "# === Device ===\n",
    "device = f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Load model ===\n",
    "path = f\"{data_dir}/train\"\n",
    "num_classes = get_number_of_classes(path)\n",
    "\n",
    "model = build_model(model_name,\n",
    "                    num_classes=num_classes,\n",
    "                    pretrained=True,\n",
    "                    freeze_backbone=True)  # load dummy model\n",
    "model.to(device)\n",
    "model.eval()  # switch to evaluation mode\n",
    "if os.path.isfile(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "    start_epoch = ckpt.get(\"epoch\", 0) + 1\n",
    "    best_val_acc = ckpt.get(\"best_val_acc\")\n",
    "    min_val_loss = ckpt.get(\"min_val_loss\")\n",
    "    print(f\"\\n\" f\"Resumed from '{ckpt_path}' at epoch {start_epoch}. \"\n",
    "          f\"Accuracy: {best_val_acc:.2f}%. Loss: {min_val_loss:.4f}.\\n\")\n",
    "else:\n",
    "    print(f\"\\n\" f\"No checkpoint was found. Use standard model trained on ImageNet21k.\\n\")\n",
    "\n",
    "# === Iterate through images ===\n",
    "csv_files = get_csv_dict(data_dir)  # get dictionary of CSV files and dir paths\n",
    "\n",
    "# === Preprocessing ===\n",
    "transform = T.Compose([\n",
    "    T.Resize(int(img_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "for csv_name, dir_path in csv_files.items():\n",
    "    save_features(csv_name, dir_path, model, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07d541-11f9-49bb-903e-b7d7eda36b53",
   "metadata": {},
   "source": [
    "## Part 3. Open CSV file with features\n",
    "\n",
    "Open CSV file with file names.\n",
    "\n",
    "Open another CSV file with features.\n",
    "\n",
    "Convert features to to NumPy array (`ndarray` type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e47fd9c-37e0-4ddd-ba52-54b9c9a5bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 336 rows in `./outputs_ResNet50/FTR_path_train_fnames.csv` file.\n",
      "There are 336 rows in `./outputs_ResNet50/FTR_path_train_featur.csv` file.\n",
      "Column names: Index(['file_name', 'feature_vector'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHNCXR_0327_1_boxed.png</td>\n",
       "      <td>0.0791 0.6124 1.3399 0.1139 0.0000 0.0000 1.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHNCXR_0328_1_boxed.png</td>\n",
       "      <td>0.1864 0.5191 0.0777 0.8289 0.5012 0.8916 0.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHNCXR_0329_1_boxed.png</td>\n",
       "      <td>0.0000 0.2007 0.5140 0.4132 0.2312 0.0619 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHNCXR_0330_1_boxed.png</td>\n",
       "      <td>0.0401 0.3747 0.2440 0.1624 0.6557 0.3950 0.48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHNCXR_0331_1_boxed.png</td>\n",
       "      <td>0.0626 0.1962 0.0507 0.4574 0.0178 0.4053 0.33...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file_name                                     feature_vector\n",
       "0  CHNCXR_0327_1_boxed.png  0.0791 0.6124 1.3399 0.1139 0.0000 0.0000 1.38...\n",
       "1  CHNCXR_0328_1_boxed.png  0.1864 0.5191 0.0777 0.8289 0.5012 0.8916 0.47...\n",
       "2  CHNCXR_0329_1_boxed.png  0.0000 0.2007 0.5140 0.4132 0.2312 0.0619 0.21...\n",
       "3  CHNCXR_0330_1_boxed.png  0.0401 0.3747 0.2440 0.1624 0.6557 0.3950 0.48...\n",
       "4  CHNCXR_0331_1_boxed.png  0.0626 0.1962 0.0507 0.4574 0.0178 0.4053 0.33..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0001.\tFeature vector for file 'CHNCXR_0327_1_boxed.png'\n",
      "\t  type ndarray has 2048 of float64 numbers.\n",
      "0002.\tFeature vector for file 'CHNCXR_0328_1_boxed.png'\n",
      "\t  type ndarray has 2048 of float64 numbers.\n",
      "0003.\tFeature vector for file 'CHNCXR_0329_1_boxed.png'\n",
      "\t  type ndarray has 2048 of float64 numbers.\n",
      "0004.\tFeature vector for file 'CHNCXR_0330_1_boxed.png'\n",
      "\t  type ndarray has 2048 of float64 numbers.\n",
      "0005.\tFeature vector for file 'CHNCXR_0331_1_boxed.png'\n",
      "\t  type ndarray has 2048 of float64 numbers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Config ===\n",
    "\n",
    "# out_dir = \"./outputs_ResNet50\"\n",
    "\n",
    "# csv_out_1   = f\"{out_dir}/FTR_G2_F_c1_train_fnames.csv\"  # CVS file with file names\n",
    "# csv_out_2   = f\"{out_dir}/FTR_G2_F_c1_train_featur.csv\"  # CVS file with features\n",
    "\n",
    "# # csv_out_1   = f\"{out_dir}/FTR_Generated_train_fnames.csv\"  # CVS file with file names\n",
    "# # csv_out_2   = f\"{out_dir}/FTR_Generated_train_featur.csv\"  # CVS file with features\n",
    "\n",
    "df1 = pd.read_csv(csv_out_1, header=None)  # load the CSV file into a DataFrame, no header line\n",
    "df2 = pd.read_csv(csv_out_2, header=None)\n",
    "\n",
    "print(f\"There are {len(df1)} rows in `{csv_out_1}` file.\")\n",
    "print(f\"There are {len(df2)} rows in `{csv_out_2}` file.\")\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1, ignore_index=True)  # stack two DataFrames horizontally\n",
    "df.columns = [\"file_name\", \"feature_vector\"]  # rename columns from \"0\" and \"1\"\n",
    "column_names = df.columns  # get the column names\n",
    "print(f\"Column names: {column_names}\")\n",
    "\n",
    "# stop = float(\"inf\")  # do not stop\n",
    "stop = 5  # stop after 5 rows\n",
    "\n",
    "display(df.head(stop))  # show first 5 rows\n",
    "\n",
    "print()\n",
    "# Iterate through rows using iterrows()\n",
    "for index, row in df.iterrows():\n",
    "    # 'index' is the row index\n",
    "    # 'row' is a Pandas Series containing the data for that row\n",
    "    \n",
    "    file_name = row[column_names[0]]\n",
    "    print(f\"{index + 1:04}.\\t\" f\"Feature vector for file '{file_name}'\")\n",
    "    \n",
    "    feature = row[column_names[1]]  # string\n",
    "    feature = [float(x) for x in feature.split()]  # list of float numbers\n",
    "    feature = np.array(feature)  # convert to NumPy format\n",
    "    print(f\"\\t\" f\"  type {type(feature).__name__} has {len(feature)} of {type(feature[0]).__name__} numbers.\")\n",
    "    \n",
    "    if index >= (stop-1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d83f58-4ea6-4252-8925-c6b8cf8e1ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
