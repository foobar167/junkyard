{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295685aa-717e-4be7-8a4e-783decd68e52",
   "metadata": {},
   "source": [
    "# Studying the mechanism of self-attention\n",
    "\n",
    "[GitHub link](https://github.com/foobar167/junkyard/blob/master/fine_tuning/Attention_study.ipynb) and\n",
    "[Colab link](https://colab.research.google.com/drive/1912LC9Tn7lyBzIwlZd2_QuNJqBtZzZ2D) to this Python script.\n",
    "\n",
    "* Video [Understanding the Self-Attention Mechanism in **8 min**](https://youtu.be/W28LfOld44Y) - theory\n",
    "* Video [Multi-head Attention Mechanism Explained](https://youtu.be/W6s9i02EiR0) in **4 min** - theory\n",
    "* Video [Implementing the Self-Attention Mechanism from Scratch in PyTorch](https://youtu.be/ZPLym9rJtM8) - **4 min** to implement + **11 min** testing and playing with code\n",
    "\n",
    "![Self-Attention scheme](./data/Self-Attention_Layer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007c17b-8883-4579-bb41-d034a097936b",
   "metadata": {},
   "source": [
    "## Attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b25d972-8b71-4800-8026-ea3652df2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\" Attention mechanism implementation \"\"\"\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.Q = nn.Linear(d_in, d_out)  # initialize fully connected layer with random values\n",
    "        self.K = nn.Linear(d_in, d_out)\n",
    "        self.V = nn.Linear(d_in, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.Q(x)  # function performs the math operation y=xA^{T}+b\n",
    "        keys = self.K(x)\n",
    "        values = self.V(x)\n",
    "        # torch.bmm  - Batch Matrix-Matrix Product\n",
    "        # Use torch.matmul for Multi-Head Attention\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        # Normalize. Scores should be independent from the number of elements\n",
    "        scores = scores * (self.d_out ** -0.5)\n",
    "        # Apply the softmax so that the sum of the values in a row equals 1.0\n",
    "        attention = F.softmax(scores, dim=-1)  # normalize in the last dimension\n",
    "        hidden_states = torch.bmm(attention, values)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362f6a7-eba5-4ab0-a984-c9cd2e1ea9fb",
   "metadata": {},
   "source": [
    "## Implementation of a very simple tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2800bd3-57dc-42ce-aaf5-d36bf3f6285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'BOS')\n",
      "(1, 'EOS')\n",
      "(2, 'doing')\n",
      "(3, 'are')\n",
      "(4, 'good')\n",
      "(5, 'you')\n",
      "(6, 'and')\n",
      "(7, 'i')\n",
      "(8, 'how')\n",
      "(9, '?')\n",
      "(10, 'am')\n",
      "\n",
      "\n",
      "('BOS', 0)\n",
      "('EOS', 1)\n",
      "('doing', 2)\n",
      "('are', 3)\n",
      "('good', 4)\n",
      "('you', 5)\n",
      "('and', 6)\n",
      "('i', 7)\n",
      "('how', 8)\n",
      "('?', 9)\n",
      "('am', 10)\n"
     ]
    }
   ],
   "source": [
    "BOS_token = 0  # BOS (Beginning of Sequence) the same as SOS (Start of Sequence)\n",
    "EOS_token = 1  # EOS (End of Sequence)\n",
    "\n",
    "index2word = {\n",
    "    BOS_token: \"BOS\",\n",
    "    EOS_token: \"EOS\",\n",
    "}\n",
    "\n",
    "text = \"How are you doing ? I am good and you ?\"\n",
    "vocabulary = set(text.lower().split(\" \"))  # set of unique words\n",
    "\n",
    "for word in vocabulary:\n",
    "    index2word[len(index2word)] = word\n",
    "\n",
    "print(*list(index2word.items()), sep=\"\\n\")\n",
    "\n",
    "word2index = {w: i for i, w in index2word.items()}\n",
    "print(\"\\n\", *list(word2index.items()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d32e3be-3259-48ce-b3c8-95490c2eaeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor: tensor([[8, 3, 5, 2, 9]])\n",
      "Tensor size: torch.Size([1, 5])\n",
      "Output sentence: How are you doing ?\n"
     ]
    }
   ],
   "source": [
    "def convert2tensor(sentence):\n",
    "    \"\"\" Convert sentence to tensor \"\"\"\n",
    "    words_list = sentence.lower().split(\" \")\n",
    "    indices = [word2index[word] for word in words_list]\n",
    "    # Add new dimension for batches using view(1,-1) at the beginning of the tensor\n",
    "    return torch.tensor(indices, dtype=torch.long).view(1, -1)\n",
    "\n",
    "\n",
    "def convert2sentence(tensor):\n",
    "    \"\"\" Convert tensor with tokens to sentence \"\"\"\n",
    "    indices = tensor.tolist()[0]\n",
    "    words_list = [index2word[index] for index in indices]\n",
    "    return \" \".join(words_list).capitalize()\n",
    "\n",
    "\n",
    "sentence = \"How are you doing ?\"\n",
    "\n",
    "input_tensor = convert2tensor(sentence)\n",
    "print(f\"Input tensor: {input_tensor}\")\n",
    "print(f\"Tensor size: {input_tensor.size()}\")\n",
    "\n",
    "output_sentence = convert2sentence(input_tensor)\n",
    "print(f\"Output sentence: {output_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbd1d2-d243-41f7-816a-41fca333a580",
   "metadata": {},
   "source": [
    "## Create a very small neural network with attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabe9c90-008e-463f-b04f-ffe29e1784f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6878,  0.5455, -0.5097,  0.4990, -0.4259, -0.6922, -1.0510,\n",
      "          -0.1118, -0.8900,  1.8558],\n",
      "         [ 0.5680, -0.0979,  1.8615,  1.1312, -1.8843, -1.5381, -2.0612,\n",
      "           1.2283,  0.7979, -0.0315],\n",
      "         [-1.8679, -0.8784,  0.1699,  1.8107,  1.7111,  0.1360, -1.0298,\n",
      "          -0.7877,  0.6809,  0.5554],\n",
      "         [-0.0272, -0.3456, -0.9135,  0.9014, -1.0063,  1.0562, -0.9728,\n",
      "          -0.6862, -1.9597, -0.6360],\n",
      "         [ 0.9884,  1.0415,  0.5122,  0.5511,  0.0531,  0.4898, -0.0100,\n",
      "          -0.7635, -0.0098, -0.3157]]], grad_fn=<EmbeddingBackward0>)\n",
      "Tensor size: torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "VOCAB_SIZE = len(word2index)\n",
    "\n",
    "embedding = nn.Embedding(VOCAB_SIZE, HIDDEN_SIZE)\n",
    "attention = Attention(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "sentence = \"How are you doing ?\"\n",
    "input_tensor = convert2tensor(sentence)\n",
    "embedded = embedding(input_tensor)\n",
    "\n",
    "print(embedded)\n",
    "# size: [batch_size, sentence_length, hidden_size]\n",
    "print(f\"Tensor size: {embedded.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1832c7e-b92e-420d-857b-e8f8034d9e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3834, -0.4076, -0.5102,  0.2269,  0.0488,  0.1977, -0.3881,\n",
      "           0.1375, -0.1205,  0.3651],\n",
      "         [-0.3657, -0.4375, -0.1336,  0.3992,  0.3447,  0.5735, -0.4873,\n",
      "          -0.0157, -0.2402, -0.0249],\n",
      "         [-0.3765, -0.4694, -0.3771,  0.2756,  0.2334,  0.2106, -0.3236,\n",
      "           0.0290, -0.1926,  0.2362],\n",
      "         [-0.3883, -0.5096, -0.2760,  0.3214,  0.3184,  0.3379, -0.3530,\n",
      "          -0.0234, -0.2576,  0.1241],\n",
      "         [-0.3913, -0.5547, -0.2644,  0.3192,  0.3872,  0.2695, -0.2815,\n",
      "          -0.0705, -0.2917,  0.1177]]], grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = attention(embedded)\n",
    "print(hidden_states)\n",
    "print(hidden_states.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958b9eb8-acc9-499a-9f7f-1254b503b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 10])\n",
      "torch.Size([1, 5, 10])\n",
      "torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "d_in = HIDDEN_SIZE\n",
    "d_out = HIDDEN_SIZE\n",
    "\n",
    "Q = nn.Linear(d_in, d_out)  # initialize fully connected layer with random values\n",
    "K = nn.Linear(d_in, d_out)\n",
    "V = nn.Linear(d_in, d_out)\n",
    "\n",
    "queries = Q(embedded)  # function performs the math operation y=xA^{T}+b\n",
    "keys = K(embedded)\n",
    "values = V(embedded)\n",
    "\n",
    "print(queries.size(), keys.size(), values.size(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb4f6f1-c456-4b59-ae4b-46906ee897c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "\n",
      "torch.Size([1, 5, 5])\n",
      "Sum of the rows of the last dimension:\n",
      "\ttensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n",
      "tensor([[[0.1781, 0.3114, 0.1765, 0.1437, 0.1903],\n",
      "         [0.1685, 0.1874, 0.2166, 0.3007, 0.1268],\n",
      "         [0.2280, 0.1492, 0.1531, 0.2761, 0.1937],\n",
      "         [0.1903, 0.1494, 0.1475, 0.3015, 0.2113],\n",
      "         [0.1966, 0.1333, 0.2375, 0.2498, 0.1828]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "torch.Size([1, 5, 10])\n",
      "tensor([[[ 0.0824, -0.0145,  0.0324, -0.1796, -0.4023,  0.3836, -0.6102,\n",
      "          -0.2606, -0.7194,  0.0121],\n",
      "         [-0.1716, -0.0481,  0.0365,  0.1145, -0.3638,  0.2093, -0.8715,\n",
      "          -0.1609, -0.5933, -0.0490],\n",
      "         [-0.2490, -0.0671,  0.0547,  0.1299, -0.3752,  0.2864, -0.8101,\n",
      "          -0.2255, -0.5545, -0.0812],\n",
      "         [-0.3095, -0.0868,  0.0293,  0.1527, -0.3813,  0.2707, -0.7959,\n",
      "          -0.2332, -0.5277, -0.0496],\n",
      "         [-0.1420, -0.0465,  0.0840,  0.1591, -0.3431,  0.2532, -0.8829,\n",
      "          -0.1077, -0.5881, -0.0949]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "scores = torch.bmm(queries, keys.transpose(1, 2))\n",
    "print(scores.size())\n",
    "\n",
    "scores = scores * (d_out ** -0.5)\n",
    "attention_tensor = F.softmax(scores, dim=-1)\n",
    "print(\"\", attention_tensor.size(), sep=\"\\n\")\n",
    "print(f\"Sum of the rows of the last dimension:\\n\\t{attention_tensor.sum(dim=-1)}\")\n",
    "print(attention_tensor)\n",
    "\n",
    "hidden_states = torch.bmm(attention_tensor, values)\n",
    "print(\"\", hidden_states.size(), sep=\"\\n\")\n",
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894c577-42e7-40f2-8ae8-39bf478d43a9",
   "metadata": {},
   "source": [
    "## Multi-head Attention Implementaion\n",
    "\n",
    "![Multi-head Attention scheme](./data/Multihead_Attention.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116ee44f-937e-44cd-b490-166f16a5a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c6308-7f51-479f-99ed-b182fc0ec435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
