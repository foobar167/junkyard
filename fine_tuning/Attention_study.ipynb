{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295685aa-717e-4be7-8a4e-783decd68e52",
   "metadata": {},
   "source": [
    "# Studying the mechanism of self-attention\n",
    "\n",
    "[GitHub link](https://github.com/foobar167/junkyard/blob/master/fine_tuning/Attention_study.ipynb) and\n",
    "[Colab link](https://colab.research.google.com/drive/1912LC9Tn7lyBzIwlZd2_QuNJqBtZzZ2D) to this Python script.\n",
    "\n",
    "* Video [Understanding the Self-Attention Mechanism in **8 min**](https://youtu.be/W28LfOld44Y) - theory\n",
    "* Video [Multi-head Attention Mechanism Explained](https://youtu.be/W6s9i02EiR0) in **4 min** - theory\n",
    "* Video [Implementing the Self-Attention Mechanism from Scratch in PyTorch](https://youtu.be/ZPLym9rJtM8) - **4 min** to implement + **11 min** testing and playing with code\n",
    "\n",
    "![Self-Attention scheme](./data/Self-Attention_Layer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007c17b-8883-4579-bb41-d034a097936b",
   "metadata": {},
   "source": [
    "## Attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b25d972-8b71-4800-8026-ea3652df2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\" Attention mechanism implementation \"\"\"\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.Q = nn.Linear(d_in, d_out)  # initialize fully connected layer with random values\n",
    "        self.K = nn.Linear(d_in, d_out)\n",
    "        self.V = nn.Linear(d_in, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.Q(x)  # function performs the math operation y=xA^{T}+b\n",
    "        keys = self.K(x)\n",
    "        values = self.V(x)\n",
    "        # torch.bmm  - Batch Matrix-Matrix Product\n",
    "        # Use torch.matmul for Multi-Head Attention\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        # Normalize. Scores should be independent from the number of elements\n",
    "        scores = scores * (self.d_out ** -0.5)\n",
    "        # Apply the softmax so that the sum of the values in a row equals 1.0\n",
    "        attention = F.softmax(scores, dim=-1)  # normalize in the last dimension\n",
    "        hidden_states = torch.bmm(attention, values)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362f6a7-eba5-4ab0-a984-c9cd2e1ea9fb",
   "metadata": {},
   "source": [
    "## Implementation of a very simple tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2800bd3-57dc-42ce-aaf5-d36bf3f6285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'BOS')\n",
      "(1, 'EOS')\n",
      "(2, 'doing')\n",
      "(3, '?')\n",
      "(4, 'you')\n",
      "(5, 'am')\n",
      "(6, 'i')\n",
      "(7, 'good')\n",
      "(8, 'are')\n",
      "(9, 'how')\n",
      "(10, 'and')\n",
      "\n",
      "\n",
      "('BOS', 0)\n",
      "('EOS', 1)\n",
      "('doing', 2)\n",
      "('?', 3)\n",
      "('you', 4)\n",
      "('am', 5)\n",
      "('i', 6)\n",
      "('good', 7)\n",
      "('are', 8)\n",
      "('how', 9)\n",
      "('and', 10)\n"
     ]
    }
   ],
   "source": [
    "BOS_token = 0  # BOS (Beginning of Sequence) the same as SOS (Start of Sequence)\n",
    "EOS_token = 1  # EOS (End of Sequence)\n",
    "\n",
    "index2word = {\n",
    "    BOS_token: \"BOS\",\n",
    "    EOS_token: \"EOS\",\n",
    "}\n",
    "\n",
    "text = \"How are you doing ? I am good and you ?\"\n",
    "vocabulary = set(text.lower().split(\" \"))  # set of unique words\n",
    "\n",
    "for word in vocabulary:\n",
    "    index2word[len(index2word)] = word\n",
    "\n",
    "print(*list(index2word.items()), sep=\"\\n\")\n",
    "\n",
    "word2index = {w: i for i, w in index2word.items()}\n",
    "print(\"\\n\", *list(word2index.items()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d32e3be-3259-48ce-b3c8-95490c2eaeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor: tensor([[9, 8, 4, 2, 3]])\n",
      "Tensor size: torch.Size([1, 5])\n",
      "Output sentence: How are you doing ?\n"
     ]
    }
   ],
   "source": [
    "def convert2tensor(sentence):\n",
    "    \"\"\" Convert sentence to tensor \"\"\"\n",
    "    words_list = sentence.lower().split(\" \")\n",
    "    indices = [word2index[word] for word in words_list]\n",
    "    # Add new dimension for batches using view(1,-1) at the beginning of the tensor\n",
    "    return torch.tensor(indices, dtype=torch.long).view(1, -1)\n",
    "\n",
    "\n",
    "def convert2sentence(tensor):\n",
    "    \"\"\" Convert tensor with tokens to sentence \"\"\"\n",
    "    indices = tensor.tolist()[0]\n",
    "    words_list = [index2word[index] for index in indices]\n",
    "    return \" \".join(words_list).capitalize()\n",
    "\n",
    "\n",
    "sentence = \"How are you doing ?\"\n",
    "\n",
    "input_tensor = convert2tensor(sentence)\n",
    "print(f\"Input tensor: {input_tensor}\")\n",
    "print(f\"Tensor size: {input_tensor.size()}\")\n",
    "\n",
    "output_sentence = convert2sentence(input_tensor)\n",
    "print(f\"Output sentence: {output_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbd1d2-d243-41f7-816a-41fca333a580",
   "metadata": {},
   "source": [
    "## Create a very small neural network with attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabe9c90-008e-463f-b04f-ffe29e1784f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2835, -0.1142,  0.7625,  1.8695,  0.7673,  0.8024, -1.4880,\n",
      "           0.3132,  0.6777, -1.2837],\n",
      "         [ 1.4617,  1.5022,  0.7845, -0.5096, -1.3534, -2.0501, -0.5282,\n",
      "           0.7364, -1.1479,  0.9985],\n",
      "         [-0.5725,  1.4598,  1.5003,  1.2356,  0.6263,  0.9765, -2.4509,\n",
      "           0.3613,  0.2789, -0.9566],\n",
      "         [ 0.4424, -0.8964,  0.8295, -0.1787, -0.2392,  0.2189, -0.1659,\n",
      "          -0.4627,  1.8268,  0.1060],\n",
      "         [ 0.2091,  1.3789, -0.0426,  1.7296,  0.2907, -2.0111, -0.9097,\n",
      "          -0.8147,  1.0213,  1.2564]]], grad_fn=<EmbeddingBackward0>)\n",
      "Tensor size: torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "VOCAB_SIZE = len(word2index)\n",
    "\n",
    "embedding = nn.Embedding(VOCAB_SIZE, HIDDEN_SIZE)\n",
    "attention = Attention(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "sentence = \"How are you doing ?\"\n",
    "input_tensor = convert2tensor(sentence)\n",
    "embedded = embedding(input_tensor)\n",
    "\n",
    "print(embedded)\n",
    "# size: [batch_size, sentence_length, hidden_size]\n",
    "print(f\"Tensor size: {embedded.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1832c7e-b92e-420d-857b-e8f8034d9e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5218, -0.4102,  0.7409, -0.1872,  0.2991, -0.8574, -0.2982,\n",
      "           0.2765,  0.7004,  0.0800],\n",
      "         [ 0.3374, -0.1027,  0.5648, -0.0186,  0.0531, -0.3391, -0.1287,\n",
      "           0.0431,  0.2931, -0.1135],\n",
      "         [ 0.4792, -0.3542,  0.7240, -0.1440,  0.2760, -0.7879, -0.2573,\n",
      "           0.2385,  0.6349,  0.0734],\n",
      "         [ 0.6686, -0.6763,  0.8214, -0.4642,  0.1728, -0.8602, -0.4216,\n",
      "           0.4950,  0.7693, -0.0709],\n",
      "         [ 0.3343, -0.0983,  0.6696,  0.0642,  0.2517, -0.6062, -0.1253,\n",
      "           0.0789,  0.4570,  0.0975]]], grad_fn=<BmmBackward0>)\n",
      "torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = attention(embedded)\n",
    "print(hidden_states)\n",
    "print(hidden_states.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958b9eb8-acc9-499a-9f7f-1254b503b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 10])\n",
      "torch.Size([1, 5, 10])\n",
      "torch.Size([1, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "d_in = HIDDEN_SIZE\n",
    "d_out = HIDDEN_SIZE\n",
    "\n",
    "Q = nn.Linear(d_in, d_out)  # initialize fully connected layer with random values\n",
    "K = nn.Linear(d_in, d_out)\n",
    "V = nn.Linear(d_in, d_out)\n",
    "\n",
    "queries = Q(embedded)  # function performs the math operation y=xA^{T}+b\n",
    "keys = K(embedded)\n",
    "values = V(embedded)\n",
    "\n",
    "print(queries.size(), keys.size(), values.size(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb4f6f1-c456-4b59-ae4b-46906ee897c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "\n",
      "torch.Size([1, 5, 5])\n",
      "Sum of the rows of the last dimension:\n",
      "\ttensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n",
      "tensor([[[0.1774, 0.2592, 0.1660, 0.1918, 0.2056],\n",
      "         [0.1930, 0.1687, 0.1423, 0.2866, 0.2094],\n",
      "         [0.1885, 0.1985, 0.2020, 0.1938, 0.2172],\n",
      "         [0.1798, 0.2606, 0.1428, 0.1899, 0.2269],\n",
      "         [0.2162, 0.1744, 0.1309, 0.2362, 0.2423]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "torch.Size([1, 5, 10])\n",
      "tensor([[[-0.0965, -0.2134, -0.0656,  0.3100,  0.1607, -0.1591,  0.1684,\n",
      "           0.1657, -0.1143,  0.0348],\n",
      "         [-0.1321, -0.1620, -0.0675,  0.1672,  0.1138, -0.1034,  0.1976,\n",
      "           0.2082, -0.2740,  0.1266],\n",
      "         [-0.2073, -0.2190, -0.0708,  0.2720,  0.0842, -0.1246,  0.1825,\n",
      "           0.2124, -0.2098,  0.0960],\n",
      "         [-0.0623, -0.2234, -0.0489,  0.3278,  0.1846, -0.1751,  0.1581,\n",
      "           0.1520, -0.1109,  0.0309],\n",
      "         [-0.1480, -0.2043, -0.0438,  0.2239,  0.1240, -0.1276,  0.1825,\n",
      "           0.1977, -0.2565,  0.1197]]], grad_fn=<BmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "scores = torch.bmm(queries, keys.transpose(1, 2))\n",
    "print(scores.size())\n",
    "\n",
    "scores = scores * (d_out ** -0.5)\n",
    "attention_tensor = F.softmax(scores, dim=-1)\n",
    "print(\"\", attention_tensor.size(), sep=\"\\n\")\n",
    "print(f\"Sum of the rows of the last dimension:\\n\\t{attention_tensor.sum(dim=-1)}\")\n",
    "print(attention_tensor)\n",
    "\n",
    "hidden_states = torch.bmm(attention_tensor, values)\n",
    "print(\"\", hidden_states.size(), sep=\"\\n\")\n",
    "print(hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894c577-42e7-40f2-8ae8-39bf478d43a9",
   "metadata": {},
   "source": [
    "## Multi-head Attention Implementaion\n",
    "\n",
    "Multi-head Attention scheme\n",
    "\n",
    "![Multi-head Attention scheme](./data/Multihead_Attention.jpg)\n",
    "\n",
    "Attention head scheme\n",
    "\n",
    "![Attention head scheme](./data/Attention_head.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116ee44f-937e-44cd-b490-166f16a5a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Not implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c6308-7f51-479f-99ed-b182fc0ec435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
