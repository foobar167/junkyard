{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.11-1 Neural Style Transfer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMtImnQW0H/ErQoL6eHQnSK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DBR2Sm904CXr"},"source":["# Neural Style Transfer\r\n","\r\n","[Original video](https://youtu.be/imX4kSKDY7s)\r\n","\r\n","Paper [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)\r\n","\r\n","Lectures by Andrew Ng: [part1](https://youtu.be/R39tWYYKNcI), [part2](https://youtu.be/ChoV5h7tw5A), [part3](https://youtu.be/xY-DMAJpIP4​), [part4](https://youtu.be/b1I5X3UfEYI​), [part5](https://youtu.be/QgkLfjfGul8).\r\n","\r\n","[Neural stype transfer](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/neural_style_transfer) by Yunjey Choi."]},{"cell_type":"code","metadata":{"id":"DMBznGQM3-bG"},"source":["import os\r\n","import torch\r\n","import requests\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","import torchvision.models as models\r\n","import torchvision.datasets as datasets\r\n","import torchvision.transforms as transforms\r\n","\r\n","from PIL import Image\r\n","from torch.utils.data import DataLoader\r\n","from torchvision.utils import save_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tc7infyb_cy0","executionInfo":{"status":"ok","timestamp":1615471354298,"user_tz":-180,"elapsed":3147,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"85b784d1-045f-424b-feb8-a725895d1561"},"source":["model = models.vgg19(pretrained=True).features\r\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU(inplace=True)\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU(inplace=True)\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU(inplace=True)\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (11): ReLU(inplace=True)\n","  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): ReLU(inplace=True)\n","  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (17): ReLU(inplace=True)\n","  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (20): ReLU(inplace=True)\n","  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (22): ReLU(inplace=True)\n","  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (24): ReLU(inplace=True)\n","  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (26): ReLU(inplace=True)\n","  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (29): ReLU(inplace=True)\n","  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (31): ReLU(inplace=True)\n","  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (33): ReLU(inplace=True)\n","  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (35): ReLU(inplace=True)\n","  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLsGA1iL_wpr","executionInfo":{"status":"ok","timestamp":1615475030776,"user_tz":-180,"elapsed":3538126,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"d53c58f6-a9ca-4ded-c288-1cb1008a1907"},"source":["class VGG(nn.Module):\r\n","    def __init__(self):\r\n","        super(VGG, self).__init__()\r\n","        \r\n","        # choose conv layers after max pool\r\n","        self.chosen_features = ['0', '5', '10', '19', '28']\r\n","        \r\n","        # layers higher than 28 will be not used in the loss function\r\n","        self.model = models.vgg19(pretrained=True).features[:29]  # >= 28\r\n","\r\n","    def forward(self, x):\r\n","        features = []\r\n","\r\n","        for layer_num, layer in enumerate(self.model):\r\n","            x = layer(x)\r\n","            if str(layer_num) in self.chosen_features:\r\n","                features.append(x)  # output from chosen conv layer\r\n","        \r\n","        return features\r\n","\r\n","\r\n","def load_image(url):\r\n","    filename = url.split('/')[-1]  # get file name\r\n","    r = requests.get(url, allow_redirects=True)  # download image\r\n","\r\n","    with open(filename, 'wb') as handler:  # save image\r\n","        handler.write(r.content)\r\n","\r\n","    image = Image.open(filename)\r\n","    image = loader(image).unsqueeze(0)\r\n","    return image.to(device)\r\n","\r\n","\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","image_size = 356\r\n","\r\n","loader = transforms.Compose([\r\n","    transforms.Resize((image_size, image_size)),\r\n","    transforms.ToTensor(),\r\n","    # transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\r\n","])\r\n","\r\n","original_img = load_image('https://education.okstate.edu/outreach/fcs/Co-parenting-The-unique-role-of-fathers.jpg')\r\n","style_img = load_image('https://images.genius.com/198d6092a96e55efa4e65f7119fa4ae7.750x400x1.jpg')\r\n","\r\n","# Doing a copy of original image is better than the random noice\r\n","# generated = torch.randn(original_img.shape, device=device, requires_grad=True)\r\n","generated = original_img.clone().requires_grad_(True)  # change image, not model\r\n","\r\n","# Hyperparameters\r\n","total_steps = 6000\r\n","learning_rate = 0.001\r\n","alpha = 1.0  # for content loss, not like in paper\r\n","beta = 0.01  # how much style do we want in the image\r\n","optimizer = optim.Adam([generated], lr=learning_rate)  # optimize generated image\r\n","\r\n","model = VGG().to(device).eval()  # *.eval() - freeze weights, not-training\r\n","\r\n","for step in range(total_steps):\r\n","    generated_features = model(generated)\r\n","    original_img_features = model(original_img)\r\n","    style_features = model(style_img)\r\n","\r\n","    style_loss = content_loss = 0\r\n","\r\n","    # iterate through all the features for the chosen layers\r\n","    for gen_feature, orig_feature, style_feature in zip(\r\n","        generated_features, original_img_features, style_features):\r\n","\r\n","        # batch_size == 1, because there is only 1 image\r\n","        batch_size, channel, height, width = gen_feature.shape\r\n","        content_loss += torch.mean((gen_feature - orig_feature)**2)\r\n","\r\n","        # Compute Gram matrix. mm - matrix multiply\r\n","        G = gen_feature.view(channel, height*width).mm(\r\n","            gen_feature.view(channel, height*width).t())\r\n","        A = style_feature.view(channel, height*width).mm(\r\n","            style_feature.view(channel, height*width).t())\r\n","        style_loss += torch.mean((G - A)**2)\r\n","\r\n","    total_loss = alpha*content_loss + beta*style_loss\r\n","    \r\n","    optimizer.zero_grad()\r\n","    total_loss.backward()\r\n","    optimizer.step()\r\n","\r\n","    if step % 200 == 0:\r\n","        print(step, total_loss)\r\n","        save_image(generated, 'generated.png')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(3532019.5000, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(125943.5781, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(61126.4648, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(43779.5586, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(34992.3242, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(29569.9082, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(25805.4590, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(22964.2168, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(20706.9082, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(18855.8223, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(17334.9551, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(16045.4121, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(14939.1455, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(13982.4199, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(13142.9385, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(12402.8896, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(11733.3252, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(11123.1611, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10564.4014, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10045.4121, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(9564.5146, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(9117.2422, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8698.4971, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8302.0586, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7928.4204, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7576.1670, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7244.1812, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6928.6694, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6628.4707, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6352.2695, device='cuda:0', grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iws9T2IUi9qz"},"source":[""],"execution_count":null,"outputs":[]}]}