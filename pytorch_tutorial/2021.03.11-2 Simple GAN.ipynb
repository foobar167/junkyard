{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.11-2 Simple GAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtHs/hfFMVdLNV8/0S+mff"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BXrVQFMF130j"},"source":["# Simple GAN\n","\n","[Original video](https://youtu.be/OljTVUVzPpM)"]},{"cell_type":"code","metadata":{"id":"NJoPJdH71wMU"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXeUmrQYbfas"},"source":["# A, B, C, D = 3, 3, 2, 2\n","# c = torch.ones(A, B) * 2\n","# v = torch.randn(A, B, C, D)\n","\n","# d = c[:, :, None, None] * v\n","# print(c[:, :, None, None])\n","# # print(c[:, :, None])\n","# print(c[:, :, None, None].shape)\n","# print((d[0, 0] == v[0, 0]* 2).all())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c8vllOY6ppW"},"source":["# Run TensorBoard\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","if os.path.exists('runs'):\n","    !rm -rf runs\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir runs\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5LPGlwhX-nO","executionInfo":{"status":"ok","timestamp":1615640034159,"user_tz":-180,"elapsed":620118,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"f01149ed-5a98-413c-df27-15eef31fb02b"},"source":["class Discriminator(nn.Module):\n","    def __init__(self, img_dim):\n","        super().__init__()\n","        self.disc = nn.Sequential(\n","            nn.Linear(img_dim, 128),\n","            nn.LeakyReLU(0.01),  # a better choice for GANs than ReLU\n","            nn.Linear(128, 1),  # fake (0) or real (1) image\n","            nn.Sigmoid(),  # between (0,1)\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n","\n","class CustomTanh(nn.Module):\n","    # init method takes the parameter\n","    def __init__(self, multiplier):\n","        super().__init__()\n","        self.multiplier = multiplier\n","\n","    # forward calls it\n","    def forward(self, x):\n","        x = self.multiplier * x\n","        return torch.tanh(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, img_dim):\n","        # z_dim - dimension of the latent noise as input\n","        # img_dim == 784 --> (28x28x1)\n","        super().__init__()\n","        self.gen = nn.Sequential(\n","            nn.Linear(z_dim, 256),\n","            nn.LeakyReLU(0.01),\n","            nn.Linear(256, img_dim),\n","            \n","            # normalize inputs to (-1, 1) so make outputs (-1, 1)\n","            nn.Tanh(),\n","            \n","            # normalize inputs to (-2.83, 2.83) so make outputs (-2.83, 2.83)\n","            # CustomTanh(2.83),\n","        )\n","\n","    def forward(self, x):\n","        return self.gen(x)\n","\n","\n","# Hyperparameters. GANs are sensitive to hyperparameters.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","lr = 3e-4\n","z_dim = 64\n","img_dim = 28*28*1  # 784\n","batch_size = 32\n","num_epochs = 50\n","\n","disc = Discriminator(img_dim).to(device)\n","gen = Generator(z_dim, img_dim).to(device)\n","fixed_noise = torch.randn(batch_size, z_dim).to(device)\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","\n","    # convert [0, 1] to [-1, 1]\n","    transforms.Normalize((0.5,), (0.5,)),\n","\n","    # convert [0, 1] to ≈ (-0.42, 2.82)\n","    # transforms.Normalize((0.1307,), (0.3081,)),\n","])\n","\n","\n","# If error:\n","# HTTPError: HTTP Error 503: Service Unavailable\n","# Use this instead\n","data_dir = '/content/dataset/MNIST/raw/'\n","if os.path.exists(data_dir):\n","    !rm -rf $data_dir\n","\n","!mkdir $data_dir\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","\n","# For the error: HTTPError: HTTP Error 403: Forbidden\n","# StackOverflow: https://stackoverflow.com/a/66461122/7550928\n","from six.moves import urllib    \n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)\n","\n","dataset = datasets.MNIST(root='dataset/', transform=transform, download=True)\n","\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","optim_disc = optim.Adam(disc.parameters(), lr=lr)\n","optim_gen = optim.Adam(gen.parameters(), lr=lr)\n","criterion = nn.BCELoss()  # the same loss like in paper GANs\n","writer_fake = SummaryWriter(f'runs/GAN_MNIST/fake')\n","writer_real = SummaryWriter(f'runs/GAN_MNIST/real')\n","step = 0\n","\n","for epoch in range(num_epochs):\n","    for idx, (real, _) in enumerate(loader):\n","        real = real.view(-1, 784).to(device)  # reshape\n","\n","        # Train Discriminator: max log(D(real)) + log(1-D(G(noise)))\n","        noise = torch.randn(batch_size, z_dim).to(device)\n","\n","        # fake.detach() means to save it after loss_disc.backwards()\n","        fake = gen(noise)\n","        \n","        disc_real = disc(real).view(-1)  # flatten everything\n","        # BCELoss == (-1)*(y*log(x)+(1-y)*log(1-x))\n","        # loss_real == log(disc_real)*1\n","        # because (1-1)*log(1-disc_real) == 0\n","        # max log(D(real)) is the same as min (-1)*log(D(real))\n","        loss_real = criterion(disc_real, torch.ones_like(disc_real))\n","\n","        disc_fake = disc(fake.detach()).view(-1)\n","        # BCELoss == (-1)*(y*log(x)+(1-y)*log(1-x))\n","        # loss_fake == 1*log(1-disc_fake)\n","        # because 0*log(disc_fake) == 0\n","        # max log(1-D(fake)) is the same as min (-1)*log(1-D(fake))\n","        loss_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","\n","        loss_disc = (loss_real + loss_fake) / 2.0\n","\n","        disc.zero_grad()\n","        loss_disc.backward()  # or loss_disc.backward(retain_graph=True)\n","        optim_disc.step()\n","\n","        # Train Generator: min log(1-D(G(noise))) - it leads to saturating\n","        # weak gradients, so change loss to:\n","        # max log(D(G(noise))) or the same as min (-1)*log(D(G(noise)))\n","        output = disc(fake).view(-1)\n","        loss_gen = criterion(output, torch.ones_like(output))\n","\n","        gen.zero_grad()\n","        loss_gen.backward()\n","        optim_gen.step()\n","\n","        if idx == 0:\n","            print(f'Epoch [{epoch}/{num_epochs}] '\n","                  f'Loss D {loss_disc:.4f}, '\n","                  f'Loss G {loss_gen:.4f}')\n","            \n","            with torch.no_grad():\n","                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n","                data = real.reshape(-1, 1, 28, 28)\n","                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n","                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n","                writer_fake.add_image('MNIST fake images', img_grid_fake, global_step=step)\n","                writer_real.add_image('MNIST real images', img_grid_real, global_step=step)\n","                step += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-13 12:43:38--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz [following]\n","--2021-03-13 12:43:38--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1648877 (1.6M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’\n","\n","t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.1s    \n","\n","2021-03-13 12:43:38 (16.4 MB/s) - ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n","\n","--2021-03-13 12:43:38--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz [following]\n","--2021-03-13 12:43:39--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4542 (4.4K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’\n","\n","t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n","\n","2021-03-13 12:43:39 (60.5 MB/s) - ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n","\n","--2021-03-13 12:43:39--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz [following]\n","--2021-03-13 12:43:39--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9912422 (9.5M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’\n","\n","train-images-idx3-u 100%[===================>]   9.45M  53.0MB/s    in 0.2s    \n","\n","2021-03-13 12:43:40 (53.0 MB/s) - ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n","\n","--2021-03-13 12:43:40--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz [following]\n","--2021-03-13 12:43:40--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28881 (28K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’\n","\n","train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.001s  \n","\n","2021-03-13 12:43:40 (27.4 MB/s) - ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n","\n","Epoch [0/50] Loss D 0.6947, Loss G 0.7126\n","Epoch [1/50] Loss D 0.7561, Loss G 0.7520\n","Epoch [2/50] Loss D 0.5586, Loss G 0.8933\n","Epoch [3/50] Loss D 0.7147, Loss G 0.8528\n","Epoch [4/50] Loss D 0.7258, Loss G 0.7822\n","Epoch [5/50] Loss D 0.4033, Loss G 1.3842\n","Epoch [6/50] Loss D 0.7067, Loss G 0.9135\n","Epoch [7/50] Loss D 0.5141, Loss G 1.4850\n","Epoch [8/50] Loss D 0.3942, Loss G 1.7204\n","Epoch [9/50] Loss D 1.1602, Loss G 0.5429\n","Epoch [10/50] Loss D 0.5641, Loss G 1.1915\n","Epoch [11/50] Loss D 0.6525, Loss G 1.4551\n","Epoch [12/50] Loss D 0.5823, Loss G 1.2907\n","Epoch [13/50] Loss D 0.8164, Loss G 1.0530\n","Epoch [14/50] Loss D 0.4435, Loss G 1.5052\n","Epoch [15/50] Loss D 0.5751, Loss G 1.4780\n","Epoch [16/50] Loss D 0.5100, Loss G 2.4225\n","Epoch [17/50] Loss D 0.3923, Loss G 1.9684\n","Epoch [18/50] Loss D 0.5425, Loss G 1.3145\n","Epoch [19/50] Loss D 0.5463, Loss G 1.6599\n","Epoch [20/50] Loss D 0.6054, Loss G 1.4506\n","Epoch [21/50] Loss D 0.5849, Loss G 1.6714\n","Epoch [22/50] Loss D 0.3559, Loss G 1.7955\n","Epoch [23/50] Loss D 0.5855, Loss G 1.7226\n","Epoch [24/50] Loss D 0.4888, Loss G 2.1124\n","Epoch [25/50] Loss D 0.8120, Loss G 1.0394\n","Epoch [26/50] Loss D 0.5777, Loss G 1.4041\n","Epoch [27/50] Loss D 0.8919, Loss G 0.8965\n","Epoch [28/50] Loss D 0.4874, Loss G 1.8114\n","Epoch [29/50] Loss D 0.9638, Loss G 0.7610\n","Epoch [30/50] Loss D 0.6631, Loss G 1.3137\n","Epoch [31/50] Loss D 0.6183, Loss G 1.0901\n","Epoch [32/50] Loss D 0.3815, Loss G 2.0620\n","Epoch [33/50] Loss D 0.5368, Loss G 1.5198\n","Epoch [34/50] Loss D 0.6482, Loss G 1.5183\n","Epoch [35/50] Loss D 0.5869, Loss G 1.1629\n","Epoch [36/50] Loss D 0.4789, Loss G 1.9086\n","Epoch [37/50] Loss D 0.6650, Loss G 1.3318\n","Epoch [38/50] Loss D 0.5801, Loss G 1.2126\n","Epoch [39/50] Loss D 0.5644, Loss G 1.2893\n","Epoch [40/50] Loss D 0.5613, Loss G 1.4839\n","Epoch [41/50] Loss D 0.5778, Loss G 1.3983\n","Epoch [42/50] Loss D 0.5279, Loss G 1.3050\n","Epoch [43/50] Loss D 0.6393, Loss G 1.2040\n","Epoch [44/50] Loss D 0.6534, Loss G 1.2824\n","Epoch [45/50] Loss D 0.5276, Loss G 1.3678\n","Epoch [46/50] Loss D 0.6661, Loss G 0.9311\n","Epoch [47/50] Loss D 0.6791, Loss G 0.9454\n","Epoch [48/50] Loss D 0.6238, Loss G 1.2880\n","Epoch [49/50] Loss D 0.6120, Loss G 0.9549\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-hG4rlF6yjT","executionInfo":{"status":"ok","timestamp":1615640034164,"user_tz":-180,"elapsed":620114,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"fd00c674-3633-4b62-8a86-c1740b78c11b"},"source":["def save_checkpoint(state, filename):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","disc_checkpoint = {\n","    'state_dict': disc.state_dict(),\n","    'optimizer': optim_disc.state_dict(),\n","    'step': step,\n","}\n","save_checkpoint(disc_checkpoint, 'discriminator_checkpoint.pth.tar')\n","\n","gen_checkpoint = {\n","    'state_dict': gen.state_dict(),\n","    'optimizer': optim_gen.state_dict(),\n","    'step': step,\n","}\n","save_checkpoint(gen_checkpoint, 'generator_checkpoint.pth.tar')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rysCjtTJNsVZ"},"source":[""],"execution_count":null,"outputs":[]}]}