{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.16 Conditional GAN implementation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNw/7Sv9G/Ohnl+n+sdhbGb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pTk6OizolRh0"},"source":["# Conditional GAN implementation\n","\n","[Original video](https://youtu.be/Hp-jWm2SzR8)\n","\n","[Article](https://arxiv.org/abs/1411.1784)"]},{"cell_type":"markdown","metadata":{"id":"WQHBesBCsTZN"},"source":["## Download and prepare dataset. Import libraries"]},{"cell_type":"code","metadata":{"id":"zBL9uQUqlPw8"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import multiprocessing\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vysOT7MwsfVN"},"source":["IMG_SIZE = 64\n","CHANNELS_IMG = 1\n","\n","transform = transforms.Compose([\n","    transforms.Resize(IMG_SIZE),  # resize proportionally to rectangular image\n","    transforms.RandomCrop(IMG_SIZE),  # crop rectangular image to square\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5 for _ in range(CHANNELS_IMG)],\n","                         [0.5 for _ in range(CHANNELS_IMG)]),\n","])\n","\n","def save_checkpoint(state, filename):\n","    print('=> Saving checkpoint')\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print('=> Loading checkpoint')\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    step = checkpoint['step']\n","    return step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71oAgziW-Ocj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615900249263,"user_tz":-180,"elapsed":3338,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"fae79549-07ce-4a79-e48c-f934d3917665"},"source":["# Get MNIST dataset\n","\n","# For the error: HTTPError: HTTP Error 503: Service Unavailable\n","# Use this instead\n","data_dir = '/content/dataset/MNIST/raw/'\n","if os.path.exists(data_dir):\n","    !rm -rf $data_dir\n","\n","!mkdir $data_dir\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","\n","# For the error: HTTPError: HTTP Error 403: Forbidden\n","# StackOverflow: https://stackoverflow.com/a/66461122/7550928\n","from six.moves import urllib    \n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)\n","\n","dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-16 13:10:47--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz [following]\n","--2021-03-16 13:10:47--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1648877 (1.6M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’\n","\n","t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.03s   \n","\n","2021-03-16 13:10:48 (58.0 MB/s) - ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n","\n","--2021-03-16 13:10:48--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz [following]\n","--2021-03-16 13:10:48--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4542 (4.4K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’\n","\n","t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n","\n","2021-03-16 13:10:48 (67.1 MB/s) - ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n","\n","--2021-03-16 13:10:48--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz [following]\n","--2021-03-16 13:10:48--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9912422 (9.5M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’\n","\n","train-images-idx3-u 100%[===================>]   9.45M  --.-KB/s    in 0.08s   \n","\n","2021-03-16 13:10:48 (126 MB/s) - ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n","\n","--2021-03-16 13:10:48--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz [following]\n","--2021-03-16 13:10:49--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28881 (28K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’\n","\n","train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0s      \n","\n","2021-03-16 13:10:49 (142 MB/s) - ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n","\n","Using downloaded and verified file: dataset/MNIST/raw/train-images-idx3-ubyte.gz\n","Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n","Using downloaded and verified file: dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n","Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","Using downloaded and verified file: dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n","Using downloaded and verified file: dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"EEzaNadiseKU"},"source":["## Set and test the model"]},{"cell_type":"code","metadata":{"id":"uMrP62ohsg8y"},"source":["class Critic(nn.Module):\n","    def __init__(self, channels_img, features_d, num_classes, img_size):\n","        super(Critic, self).__init__()\n","        self.img_size = img_size\n","\n","        self.critic = nn.Sequential(  # Input: N x C+1 x 64 x64\n","            self._block(channels_img+1, features_d,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            self._block(features_d,     features_d*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_d*2,   features_d*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_d*4,   features_d*8, kernel_size=4, stride=2, padding=1),  # N x 512 x 4 x 4\n","            nn.Conv2d(features_d*8,     1,            kernel_size=4, stride=1, padding=0),  # N x 1 x 1 x 1\n","            nn.Flatten(),  # no nn.Sigmoid() anymore, this is why it is Critic, but not Discriminator\n","        )  # Output: N x 1\n","        self.embed = nn.Embedding(num_classes, self.img_size * self.img_size)\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            # bias=False for BatchNorm\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            # Do not normalize across the batches. Normalize only across the layer (instance).\n","            nn.InstanceNorm2d(out_channels, affine=True),  # LayerNorm <--> InstanceNorm\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x, labels):\n","        # add additional channel to the image: N x 1 x H x W\n","        embedding = self.embed(labels).view(labels.shape[0], 1, self.img_size, self.img_size)\n","        x = torch.cat([x, embedding], dim=1)  # N x C+1 x H x W\n","        return self.critic(x)  # N x 1\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, noise_dim, channels_img, features_g, num_classes, img_size, embed_size):\n","        super(Generator, self).__init__()\n","        self.img_size = img_size\n","\n","        self.gen = nn.Sequential(  # Input: N x noise_dim x 1 x 1\n","            self._block(noise_dim+embed_size, features_g*8, kernel_size=4, stride=1, padding=0),  # N x 512 x 4 x 4\n","            self._block(features_g*8,         features_g*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_g*4,         features_g*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_g*2,         features_g,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            nn.ConvTranspose2d(features_g,    channels_img, kernel_size=4, stride=2, padding=1),\n","            # Output: N x C x 64 x 64\n","            nn.Tanh(),  # between (-1, 1)\n","        )\n","        # add embedding to the noise\n","        self.embed = nn.Embedding(num_classes, embed_size)\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),  # like in DCGAN paper\n","        )\n","    \n","    def forward(self, x, labels):\n","        # latent vector x: N x noise_dim x 1 x 1\n","        embedding = self.embed(labels).unsqueeze(2).unsqueeze(3)\n","        x = torch.cat([x, embedding], dim=1)\n","        return self.gen(x)  # N x C x 64 x 64\n","\n","\n","def init_weights(model):\n","    ''' Initialize weights of the model\n","        with mean of 0.0 and standard deviation of 0.02 '''\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, height, width = 8, 1, 64, 64\n","    num_classes = 10\n","    gen_embedding = 100\n","    noise_dim = 128\n","    features_d = features_g = 16\n","    \n","    x = torch.randn((N, in_channels, height, width))\n","    labels = torch.ones((N)).int()  # also can use *.to(torch.int64) or *.long()\n","\n","    critic = Critic(in_channels, features_d, num_classes, height)\n","    init_weights(critic)\n","    assert critic(x, labels).shape == (N, 1)\n","\n","    gen = Generator(noise_dim, in_channels, features_g, num_classes, height, gen_embedding)\n","\n","    init_weights(gen)\n","    z = torch.randn((N, noise_dim, 1, 1))\n","    assert gen(z, labels).shape == (N, in_channels, height, width)\n","    \n","    print('Test is OK')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFkLVUrnsqhc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615983690944,"user_tz":-180,"elapsed":556,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"613e4574-a7ad-4110-adb4-366f5e792d7f"},"source":["test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test is OK\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A7zv7q1sstvc"},"source":["## Run TensorBoard"]},{"cell_type":"code","metadata":{"id":"WSAw1IxCsrKc"},"source":["# Run TensorBoard\n","\n","# Delete previous logs dir\n","logs_dir = 'logs_dir'\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WmqEqM8xszqs"},"source":["## Prepare the model"]},{"cell_type":"code","metadata":{"id":"e0c-0FhosxGk"},"source":["# Hyperparameters etc.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","LEARNING_RATE = 1e-4  # could also use two lrs, one for gen and one for critic\n","BATCH_SIZE = 64  # was 64\n","NUM_CLASSES = 10  # MNIST dataset\n","GEN_EMBEDDING = 100\n","NOISE_DIM = 128  # was 100\n","NUM_EPOCHS = 10\n","FEATURES_CRITIC = FEATURES_GEN = 16\n","CRITIC_ITERATIONS = 5\n","LAMBDA_GP = 10\n","logs_dir = 'logs_dir'\n","\n","loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                    num_workers=multiprocessing.cpu_count(), pin_memory=True)\n","\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GEN_EMBEDDING).to(device)\n","critic = Critic(CHANNELS_IMG, FEATURES_CRITIC, NUM_CLASSES, IMG_SIZE).to(device)\n","init_weights(gen)\n","init_weights(critic)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","\n","writer_real = SummaryWriter(os.path.join(logs_dir, 'real'))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, 'fake'))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_mnist.pth.tar'\n","critic_checkpoint_name = 'critic_mnist.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(critic_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, opt_gen)\n","    step = load_checkpoint(torch.load(critic_checkpoint_name), critic, opt_critic)\n","\n","\n","def gradient_penalty(critic, labels, real, fake, device):\n","    BATCH_SIZE, C, H, W = real.shape\n","    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n","    interpolated_images = epsilon * real + (1 - epsilon) * fake\n","\n","    # calculate critic scores\n","    mixed_scores = critic(interpolated_images, labels)\n","    # calculate gradient\n","    gradient = torch.autograd.grad(inputs=interpolated_images,\n","                                   outputs=mixed_scores,\n","                                   grad_outputs=torch.ones_like(mixed_scores),\n","                                   create_graph=True,\n","                                   retain_graph=True,)[0]  # BATCH_SIZE x 3 x 64 x 64\n","    gradient = gradient.view(gradient.shape[0], -1)  # BATCH_SIZE x 12 288 or 64*64*3\n","    gradient_norm = gradient.norm(2, dim=1)  # L2 norm\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-GDic8is5rs"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"ATppj1kCs8Qs"},"source":["def train(step=step):\n","    gen.train()\n","    critic.train()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        for batch_idx, (real, labels) in enumerate(loader):\n","            real = real.to(device)\n","            curr_batch_size = real.shape[0]\n","            labels = labels.to(device)\n","\n","            # Train Critic: max (E(critic(real)) - E(critic(fake)))\n","            # or min (-1) * (E(critic(real)) - E(critic(fake)))\n","            for _ in range(CRITIC_ITERATIONS):\n","                noise = torch.randn(curr_batch_size, NOISE_DIM, 1, 1).to(device)\n","                fake = gen(noise, labels)\n","                critic_real = critic(real, labels)\n","                critic_fake = critic(fake, labels)\n","                gp = gradient_penalty(critic, labels, real, fake, device)\n","\n","                loss_critic = torch.mean(critic_fake) - torch.mean(critic_real) + LAMBDA_GP*gp\n","\n","                opt_critic.zero_grad()\n","                loss_critic.backward(retain_graph=True)\n","                opt_critic.step()\n","\n","            # Train Generator: min (E(critic(real)) - E(critic(fake)))\n","            # which is the same as: min (-1) * E(critic(fake))\n","            # because generator can not influence on E(critic(real)).\n","            output = critic(fake, labels)\n","            loss_gen = -torch.mean(output)\n","\n","            opt_gen.zero_grad()\n","            loss_gen.backward()\n","            opt_gen.step()\n","\n","            # Print losses occasionally and print to tensorboard\n","            if batch_idx % 100 == 0:\n","                print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] '\n","                    f'Batch {batch_idx}/{len(loader)} '\n","                    f'Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}')\n","\n","                with torch.no_grad():\n","                    fake = gen(noise, labels)\n","                    # take out (up to) 32 examples\n","                    img_grid_real = torchvision.utils.make_grid(\n","                        real[:32], normalize=True\n","                    )\n","                    img_grid_fake = torchvision.utils.make_grid(\n","                        fake[:32], normalize=True\n","                    )\n","\n","                    writer_real.add_image('Real', img_grid_real, global_step=step)\n","                    writer_fake.add_image('Fake', img_grid_fake, global_step=step)\n","\n","                step += 1\n","\n","        # Save models\n","        gen_checkpoint = {\n","            'state_dict': gen.state_dict(),\n","            'optimizer': opt_gen.state_dict(),\n","            'step': step,\n","        }\n","        critic_checkpoint = {\n","            'state_dict': critic.state_dict(),\n","            'optimizer': opt_critic.state_dict(),\n","            'step': step,\n","        }\n","        save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","        save_checkpoint(critic_checkpoint, critic_checkpoint_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgtW_41js_Kt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615903698454,"user_tz":-180,"elapsed":1509433,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"faf251cd-b948-4d8f-e7cd-dd6678464f31"},"source":["train(step=step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/10] Batch 0/938 Loss D: -2.1588, loss G: 42.3064\n","Epoch [1/10] Batch 100/938 Loss D: -2.7083, loss G: 42.9608\n","Epoch [1/10] Batch 200/938 Loss D: -3.9034, loss G: 35.5546\n","Epoch [1/10] Batch 300/938 Loss D: -4.8857, loss G: 26.6659\n","Epoch [1/10] Batch 400/938 Loss D: -2.2113, loss G: 38.4966\n","Epoch [1/10] Batch 500/938 Loss D: -3.8873, loss G: 30.7572\n","Epoch [1/10] Batch 600/938 Loss D: -1.8106, loss G: 32.3862\n","Epoch [1/10] Batch 700/938 Loss D: -2.3506, loss G: 30.3085\n","Epoch [1/10] Batch 800/938 Loss D: -3.4277, loss G: 23.3088\n","Epoch [1/10] Batch 900/938 Loss D: -3.3534, loss G: 30.7002\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/10] Batch 0/938 Loss D: -3.7547, loss G: 24.1971\n","Epoch [2/10] Batch 100/938 Loss D: -2.2234, loss G: 36.9975\n","Epoch [2/10] Batch 200/938 Loss D: -1.3992, loss G: 27.1289\n","Epoch [2/10] Batch 300/938 Loss D: -2.2041, loss G: 18.3049\n","Epoch [2/10] Batch 400/938 Loss D: -2.2271, loss G: 18.0371\n","Epoch [2/10] Batch 500/938 Loss D: -2.6134, loss G: 26.1062\n","Epoch [2/10] Batch 600/938 Loss D: -2.9217, loss G: 35.4533\n","Epoch [2/10] Batch 700/938 Loss D: -2.9100, loss G: 34.5313\n","Epoch [2/10] Batch 800/938 Loss D: -2.2978, loss G: 37.8460\n","Epoch [2/10] Batch 900/938 Loss D: -2.4286, loss G: 13.3800\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/10] Batch 0/938 Loss D: -2.1574, loss G: 24.1110\n","Epoch [3/10] Batch 100/938 Loss D: -3.3859, loss G: 8.3930\n","Epoch [3/10] Batch 200/938 Loss D: -2.2030, loss G: 27.1302\n","Epoch [3/10] Batch 300/938 Loss D: -2.4592, loss G: 25.1664\n","Epoch [3/10] Batch 400/938 Loss D: -1.4080, loss G: 33.4859\n","Epoch [3/10] Batch 500/938 Loss D: -2.7582, loss G: 19.0649\n","Epoch [3/10] Batch 600/938 Loss D: -2.2270, loss G: 27.7287\n","Epoch [3/10] Batch 700/938 Loss D: -2.5955, loss G: 20.5186\n","Epoch [3/10] Batch 800/938 Loss D: -1.1688, loss G: 10.9321\n","Epoch [3/10] Batch 900/938 Loss D: -0.4029, loss G: 21.4569\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/10] Batch 0/938 Loss D: -2.4590, loss G: 21.6432\n","Epoch [4/10] Batch 100/938 Loss D: -3.3855, loss G: 21.9109\n","Epoch [4/10] Batch 200/938 Loss D: -1.7108, loss G: 13.6783\n","Epoch [4/10] Batch 300/938 Loss D: -3.0620, loss G: 12.6032\n","Epoch [4/10] Batch 400/938 Loss D: -3.0034, loss G: 7.7908\n","Epoch [4/10] Batch 500/938 Loss D: -1.2118, loss G: -4.4477\n","Epoch [4/10] Batch 600/938 Loss D: -1.7033, loss G: 14.3718\n","Epoch [4/10] Batch 700/938 Loss D: -3.3847, loss G: 2.2143\n","Epoch [4/10] Batch 800/938 Loss D: -3.0498, loss G: 11.8447\n","Epoch [4/10] Batch 900/938 Loss D: -1.8870, loss G: 16.4247\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [5/10] Batch 0/938 Loss D: -2.1826, loss G: 20.1099\n","Epoch [5/10] Batch 100/938 Loss D: -2.9145, loss G: 6.9542\n","Epoch [5/10] Batch 200/938 Loss D: -2.5194, loss G: 0.9470\n","Epoch [5/10] Batch 300/938 Loss D: -2.2275, loss G: -6.3387\n","Epoch [5/10] Batch 400/938 Loss D: -2.0442, loss G: -10.7972\n","Epoch [5/10] Batch 500/938 Loss D: -2.2500, loss G: 3.5236\n","Epoch [5/10] Batch 600/938 Loss D: -2.7063, loss G: 6.7705\n","Epoch [5/10] Batch 700/938 Loss D: -2.6468, loss G: 5.7276\n","Epoch [5/10] Batch 800/938 Loss D: -2.2301, loss G: -0.9117\n","Epoch [5/10] Batch 900/938 Loss D: -1.1806, loss G: -7.6274\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [6/10] Batch 0/938 Loss D: -1.9769, loss G: 1.7310\n","Epoch [6/10] Batch 100/938 Loss D: -1.0447, loss G: -23.3604\n","Epoch [6/10] Batch 200/938 Loss D: -2.0813, loss G: -2.3449\n","Epoch [6/10] Batch 300/938 Loss D: -1.5870, loss G: -21.2521\n","Epoch [6/10] Batch 400/938 Loss D: -1.3780, loss G: -23.1709\n","Epoch [6/10] Batch 500/938 Loss D: -2.4369, loss G: -14.4911\n","Epoch [6/10] Batch 600/938 Loss D: -1.3921, loss G: -34.1281\n","Epoch [6/10] Batch 700/938 Loss D: -1.6087, loss G: -10.7103\n","Epoch [6/10] Batch 800/938 Loss D: -2.8043, loss G: -11.8028\n","Epoch [6/10] Batch 900/938 Loss D: -2.1893, loss G: -4.4114\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [7/10] Batch 0/938 Loss D: -0.7914, loss G: -4.2811\n","Epoch [7/10] Batch 100/938 Loss D: -0.6140, loss G: -20.7692\n","Epoch [7/10] Batch 200/938 Loss D: -2.4782, loss G: -8.5836\n","Epoch [7/10] Batch 300/938 Loss D: -0.7780, loss G: -3.1176\n","Epoch [7/10] Batch 400/938 Loss D: -1.3159, loss G: -4.6232\n","Epoch [7/10] Batch 500/938 Loss D: -1.9642, loss G: -9.4394\n","Epoch [7/10] Batch 600/938 Loss D: -1.3560, loss G: 6.7210\n","Epoch [7/10] Batch 700/938 Loss D: -1.8466, loss G: -7.7824\n","Epoch [7/10] Batch 800/938 Loss D: -1.1196, loss G: -2.2973\n","Epoch [7/10] Batch 900/938 Loss D: -1.9595, loss G: -14.4916\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [8/10] Batch 0/938 Loss D: -1.5643, loss G: -32.1196\n","Epoch [8/10] Batch 100/938 Loss D: -1.9680, loss G: -36.4855\n","Epoch [8/10] Batch 200/938 Loss D: -1.6858, loss G: -22.8570\n","Epoch [8/10] Batch 300/938 Loss D: -1.5939, loss G: -29.8394\n","Epoch [8/10] Batch 400/938 Loss D: -1.9614, loss G: -20.1811\n","Epoch [8/10] Batch 500/938 Loss D: -2.5450, loss G: -24.2946\n","Epoch [8/10] Batch 600/938 Loss D: -2.2605, loss G: -22.2653\n","Epoch [8/10] Batch 700/938 Loss D: -1.8800, loss G: -1.9496\n","Epoch [8/10] Batch 800/938 Loss D: -2.5707, loss G: -14.9669\n","Epoch [8/10] Batch 900/938 Loss D: -1.6306, loss G: -11.4387\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [9/10] Batch 0/938 Loss D: -2.5494, loss G: 15.5729\n","Epoch [9/10] Batch 100/938 Loss D: -1.7553, loss G: -10.0730\n","Epoch [9/10] Batch 200/938 Loss D: -2.2288, loss G: -22.0482\n","Epoch [9/10] Batch 300/938 Loss D: -1.7754, loss G: -5.7959\n","Epoch [9/10] Batch 400/938 Loss D: -1.9075, loss G: 8.3480\n","Epoch [9/10] Batch 500/938 Loss D: -1.0203, loss G: -2.3071\n","Epoch [9/10] Batch 600/938 Loss D: -0.9265, loss G: -0.6083\n","Epoch [9/10] Batch 700/938 Loss D: -1.0327, loss G: -21.7013\n","Epoch [9/10] Batch 800/938 Loss D: -1.6799, loss G: -23.6767\n","Epoch [9/10] Batch 900/938 Loss D: -1.9891, loss G: -26.6361\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [10/10] Batch 0/938 Loss D: -0.2008, loss G: -18.0746\n","Epoch [10/10] Batch 100/938 Loss D: -1.8623, loss G: -23.1054\n","Epoch [10/10] Batch 200/938 Loss D: -0.4717, loss G: -11.8806\n","Epoch [10/10] Batch 300/938 Loss D: -0.3094, loss G: 8.9659\n","Epoch [10/10] Batch 400/938 Loss D: -1.7986, loss G: 7.2995\n","Epoch [10/10] Batch 500/938 Loss D: -1.7203, loss G: 6.2722\n","Epoch [10/10] Batch 600/938 Loss D: -2.2433, loss G: -3.2427\n","Epoch [10/10] Batch 700/938 Loss D: -1.8746, loss G: -7.9186\n","Epoch [10/10] Batch 800/938 Loss D: -3.1844, loss G: -4.2186\n","Epoch [10/10] Batch 900/938 Loss D: -1.9464, loss G: -33.0111\n","=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w4NF0J5TtNPE"},"source":["## Save models if necessary"]},{"cell_type":"code","metadata":{"id":"YsQt8Cuis_6G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615903935856,"user_tz":-180,"elapsed":1154,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"27bcd6ec-816c-46f7-9cac-ec8b7b0d2d6c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp $gen_checkpoint_name    '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp $critic_checkpoint_name '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","total 217M\n","-rw------- 1 root root   32K Mar  1 12:56 '2021.02.26 basics.ipynb'\n","-rw------- 1 root root   33K Mar  1 12:59 '2021.03.01-1 Pytorch Neural Network example.ipynb'\n","-rw------- 1 root root   33K Mar  5 08:04 '2021.03.01-2 Convolutional Neural Network example.ipynb'\n","-rw------- 1 root root   20K Mar 10 10:20 '2021.03.01-3 Recurrent Neural Network example.ipynb'\n","-rw------- 1 root root   34K Mar  4 22:21 '2021.03.01-4 Bidirectional LSTM example.ipynb'\n","-rw------- 1 root root   11K Mar  5 14:30 '2021.03.02-1 How to save and load models in Pytorch.ipynb'\n","-rw------- 1 root root   16K Mar  2 14:21 '2021.03.02-2 Transfer Learning and Fine Tuning.ipynb'\n","-rw------- 1 root root   49K Mar  5 08:09 '2021.03.02-3 Build custom dataset.ipynb'\n","-rw------- 1 root root  1.5M Mar 10 08:06 '2021.03.03-1 How to build custom Datasets for Text in Pytorch.ipynb'\n","-rw------- 1 root root 1013K Mar  4 17:47 '2021.03.03-2 Data Augmentation using Torchvision.ipynb'\n","-rw------- 1 root root  3.3M Mar  4 17:01 '2021.03.03-3 Albumentations library for data augmentation.ipynb'\n","-rw------- 1 root root  7.4K Mar  4 19:53 '2021.03.04 How to deal with imbalanced datasets.ipynb'\n","-rw------- 1 root root   50M Mar  5 13:27 '2021.03.05-1 Pytorch TensorBoard.ipynb'\n","-rw------- 1 root root   13K Mar  5 14:49 '2021.03.05-2 LeNet implementation.ipynb'\n","-rw------- 1 root root   11K Mar  9 19:55 '2021.03.09-1 VGG implementation.ipynb'\n","-rw------- 1 root root   39K Mar  9 19:59 '2021.03.09-2 GoogLeNet implementation.ipynb'\n","-rw------- 1 root root   13K Mar  9 20:06 '2021.03.09-3 ResNet implementation.ipynb'\n","-rw------- 1 root root   17K Mar  9 20:55 '2021.03.09-4 EfficientNet implementation.ipynb'\n","-rw------- 1 root root   25M Mar 13 10:24 '2021.03.10-1 Image Captioning.ipynb'\n","-rw------- 1 root root   11K Mar 13 10:41 '2021.03.11-1 Neural Style Transfer.ipynb'\n","-rw------- 1 root root   24M Mar 13 12:55 '2021.03.11-2 Simple GAN.ipynb'\n","-rw------- 1 root root   31M Mar 15 11:51 '2021.03.15-1 DCGAN implementation.ipynb'\n","-rw------- 1 root root   31M Mar 16 11:34 '2021.03.15-2 WGAN implementation.ipynb'\n","-rw------- 1 root root   29M Mar 16 12:34 '2021.03.15-3 WGAN-GP implementation.ipynb'\n","-rw------- 1 root root   24M Mar 16 14:11 '2021.03.16-1 Conditional GAN implementation.ipynb'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dQ2A6Nv-Kxdn"},"source":["## Conditional GAN for cats vs. dogs dataset - DIDN'T CONVERGED for cats-dogs dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxSiApdTJowh","executionInfo":{"status":"ok","timestamp":1615967360338,"user_tz":-180,"elapsed":22180,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"82fac005-1e5d-4a5f-dc6a-b57c4dae7a13"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# !ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial/generator_cats-dogs.pth.tar' '.'\n","!cp $critic_checkpoint_name '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial/critic_cats-dogs.pth.tar' '.'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXLDBBCVtQ_2","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"status":"ok","timestamp":1615967383190,"user_tz":-180,"elapsed":19066,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"9256a647-a208-4413-9074-4747293ca37c"},"source":["# Download dataset from Kaggle\n","\n","# Info on how to get your api key (kaggle.json) here:\n","# https://github.com/Kaggle/kaggle-api#api-credentials\n","\n","# Install kaggle packages if necessary. Not necessary for CoLab\n","# !pip install -q kaggle\n","# !pip install -q kaggle-cli\n","\n","# Colab's file access feature\n","from google.colab import files\n","\n","# Upload `kaggle.json` file\n","uploaded = files.upload()\n","\n","# Retrieve uploaded file and print results\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then copy kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","\n","# Download the dataset\n","!kaggle competitions download -c dogs-vs-cats\n","#!kaggle datasets download -d aladdinpersson/cats-dogs-example-with-csv  # private? not visible\n","#!kaggle datasets list -s aladdinpersson  # show all visible datasets"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-b040a2a0-3c73-4cfd-82ad-ada860400bd8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b040a2a0-3c73-4cfd-82ad-ada860400bd8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 65 bytes\n","kaggle.json\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n","Downloading train.zip to /content\n"," 96% 519M/543M [00:03<00:00, 99.1MB/s]\n","100% 543M/543M [00:03<00:00, 156MB/s] \n","Downloading test1.zip to /content\n"," 94% 254M/271M [00:02<00:00, 132MB/s]\n","100% 271M/271M [00:02<00:00, 102MB/s]\n","Downloading sampleSubmission.csv to /content\n","  0% 0.00/86.8k [00:00<?, ?B/s]\n","100% 86.8k/86.8k [00:00<00:00, 90.2MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjzOB9zhLWHZ","executionInfo":{"status":"ok","timestamp":1615967389271,"user_tz":-180,"elapsed":11924,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"522546f6-9653-4acb-c3ba-54e6664e21a5"},"source":["# Unzip\n","import zipfile\n","\n","with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n","    zip_ref.extractall('.')\n","\n","\n","# Check it\n","source_dir = './train'\n","train_files = os.listdir(source_dir)\n","print(f'images number: {len(train_files)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["images number: 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"mQUv7pi3LrjX","executionInfo":{"status":"ok","timestamp":1615967389273,"user_tz":-180,"elapsed":8907,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"8b10e145-a05e-4867-d3d1-9c3a621adbc5"},"source":["# Create CSV file for labels\n","import pandas as pd\n","\n","csv_file = 'cats_dogs.csv'\n","\n","l = []\n","for f in train_files:\n","    s = f.split('.')\n","    if s[0] == 'cat':\n","        l.append([f, 0])\n","    elif s[0] == 'dog':\n","        l.append([f, 1])\n","    else:\n","        print('Error: wrong file name')\n","\n","cats_dogs = pd.DataFrame(l, columns=['Filename', 'Label'])\n","cats_dogs.to_csv(csv_file, index=False)\n","\n","print(cats_dogs.shape)\n","print(cats_dogs.groupby(by='Label').count())\n","cats_dogs.head(n=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(25000, 2)\n","       Filename\n","Label          \n","0         12500\n","1         12500\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Filename</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cat.10160.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat.10499.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dog.65.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dog.3247.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dog.9660.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>dog.7944.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>cat.6223.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>dog.921.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>cat.9374.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>cat.3559.jpg</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Filename  Label\n","0  cat.10160.jpg      0\n","1  cat.10499.jpg      0\n","2     dog.65.jpg      1\n","3   dog.3247.jpg      1\n","4   dog.9660.jpg      1\n","5   dog.7944.jpg      1\n","6   cat.6223.jpg      0\n","7    dog.921.jpg      1\n","8   cat.9374.jpg      0\n","9   cat.3559.jpg      0"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"8MqhFlySL1GM"},"source":["# Hyperparameters etc.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","LEARNING_RATE = 1e-4  # could also use two lrs, one for gen and one for critic\n","BATCH_SIZE = 64  # was 64\n","GEN_EMBEDDING = 100\n","NOISE_DIM = 128  # was 100\n","CRITIC_ITERATIONS = 5\n","LAMBDA_GP = 10\n","\n","# Change some hyperparameters\n","IMG_SIZE = 64\n","CHANNELS_IMG = 3  # RGB image\n","NUM_CLASSES = 2  # Cats vs. Dogs dataset\n","NUM_EPOCHS = 5\n","FEATURES_CRITIC = FEATURES_GEN = 64\n","\n","# Delete previous logs dir\n","logs_dir = 'logs_animals'\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","transform = transforms.Compose([\n","    transforms.Resize(IMG_SIZE),  # resize proportionally to rectangular image\n","    transforms.RandomCrop(IMG_SIZE),  # crop rectangular image to square\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5 for _ in range(CHANNELS_IMG)],\n","                         [0.5 for _ in range(CHANNELS_IMG)]),\n","])\n","\n","\n","# Create dataset class\n","class CatsAndDogsDataset(Dataset):\n","    def __init__(self, csv_file, root, transform):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.root = root\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)  # 25 000 images\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.root, self.annotations.iloc[index, 0])\n","        image = Image.open(img_path)\n","        label = torch.tensor(int(self.annotations.iloc[index, 1]))\n","        image = self.transform(image)\n","        return (image, label)\n","\n","\n","# Load data\n","dataset = CatsAndDogsDataset(csv_file=csv_file, root=source_dir, transform=transform)\n","\n","loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                    num_workers=multiprocessing.cpu_count(), pin_memory=True)\n","\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN, NUM_CLASSES, IMG_SIZE, GEN_EMBEDDING).to(device)\n","critic = Critic(CHANNELS_IMG, FEATURES_CRITIC, NUM_CLASSES, IMG_SIZE).to(device)\n","init_weights(gen)\n","init_weights(critic)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","\n","writer_real = SummaryWriter(os.path.join(logs_dir, 'real'))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, 'fake'))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_cats-dogs.pth.tar'\n","critic_checkpoint_name = 'critic_cats-dogs.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(critic_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, opt_gen)\n","    step = load_checkpoint(torch.load(critic_checkpoint_name), critic, opt_critic)\n","\n","\n","def gradient_penalty(critic, labels, real, fake, device):\n","    BATCH_SIZE, C, H, W = real.shape\n","    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n","    interpolated_images = epsilon * real + (1 - epsilon) * fake\n","\n","    # calculate critic scores\n","    mixed_scores = critic(interpolated_images, labels)\n","    # calculate gradient\n","    gradient = torch.autograd.grad(inputs=interpolated_images,\n","                                   outputs=mixed_scores,\n","                                   grad_outputs=torch.ones_like(mixed_scores),\n","                                   create_graph=True,\n","                                   retain_graph=True,)[0]  # BATCH_SIZE x 3 x 64 x 64\n","    gradient = gradient.view(gradient.shape[0], -1)  # BATCH_SIZE x 12 288 or 64*64*3\n","    gradient_norm = gradient.norm(2, dim=1)  # L2 norm\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty\n","\n","\n","def train(step=step):\n","    gen.train()\n","    critic.train()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        for batch_idx, (real, labels) in enumerate(loader):\n","            real = real.to(device)\n","            curr_batch_size = real.shape[0]\n","            labels = labels.to(device)\n","\n","            # Train Critic: max (E(critic(real)) - E(critic(fake)))\n","            # or min (-1) * (E(critic(real)) - E(critic(fake)))\n","            for _ in range(CRITIC_ITERATIONS):\n","                noise = torch.randn(curr_batch_size, NOISE_DIM, 1, 1).to(device)\n","                fake = gen(noise, labels)\n","                critic_real = critic(real, labels)\n","                critic_fake = critic(fake, labels)\n","                gp = gradient_penalty(critic, labels, real, fake, device)\n","\n","                loss_critic = torch.mean(critic_fake) - torch.mean(critic_real) + LAMBDA_GP*gp\n","\n","                opt_critic.zero_grad()\n","                loss_critic.backward(retain_graph=True)\n","                opt_critic.step()\n","\n","            # Train Generator: min (E(critic(real)) - E(critic(fake)))\n","            # which is the same as: min (-1) * E(critic(fake))\n","            # because generator can not influence on E(critic(real)).\n","            output = critic(fake, labels)\n","            loss_gen = -torch.mean(output)\n","\n","            opt_gen.zero_grad()\n","            loss_gen.backward()\n","            opt_gen.step()\n","\n","            # Print losses occasionally and print to tensorboard\n","            if batch_idx % 100 == 0:\n","                print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] '\n","                    f'Batch {batch_idx}/{len(loader)} '\n","                    f'Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}')\n","\n","                with torch.no_grad():\n","                    fake = gen(noise, labels)\n","                    # take out (up to) 32 examples\n","                    img_grid_real = torchvision.utils.make_grid(\n","                        real[:32], normalize=True\n","                    )\n","                    img_grid_fake = torchvision.utils.make_grid(\n","                        fake[:32], normalize=True\n","                    )\n","\n","                    writer_real.add_image('Real', img_grid_real, global_step=step)\n","                    writer_fake.add_image('Fake', img_grid_fake, global_step=step)\n","\n","                step += 1\n","\n","        # Save models\n","        gen_checkpoint = {\n","            'state_dict': gen.state_dict(),\n","            'optimizer': opt_gen.state_dict(),\n","            'step': step,\n","        }\n","        critic_checkpoint = {\n","            'state_dict': critic.state_dict(),\n","            'optimizer': opt_critic.state_dict(),\n","            'step': step,\n","        }\n","        save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","        save_checkpoint(critic_checkpoint, critic_checkpoint_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zwBFhW2ZN0E"},"source":["# Run TensorBoard\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KyHTQLRWfyy","outputId":"4543a376-c043-4e71-b443-bde779028f05"},"source":["train(step=step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/20] Batch 0/391 Loss D: -12.4652, loss G: 189.9851\n","Epoch [1/20] Batch 100/391 Loss D: -13.3562, loss G: 196.8530\n","Epoch [1/20] Batch 200/391 Loss D: -11.8560, loss G: 190.7151\n","Epoch [1/20] Batch 300/391 Loss D: -11.9301, loss G: 207.8896\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/20] Batch 0/391 Loss D: -11.2401, loss G: 185.9312\n","Epoch [2/20] Batch 100/391 Loss D: -12.6043, loss G: 182.5322\n","Epoch [2/20] Batch 200/391 Loss D: -11.4958, loss G: 184.7975\n","Epoch [2/20] Batch 300/391 Loss D: -6.3614, loss G: 191.2304\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/20] Batch 0/391 Loss D: -7.5468, loss G: 194.0101\n","Epoch [3/20] Batch 100/391 Loss D: -14.1988, loss G: 193.7846\n","Epoch [3/20] Batch 200/391 Loss D: -10.7508, loss G: 181.9749\n","Epoch [3/20] Batch 300/391 Loss D: -7.2492, loss G: 195.2432\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/20] Batch 0/391 Loss D: -10.1171, loss G: 186.9228\n","Epoch [4/20] Batch 100/391 Loss D: -11.9274, loss G: 197.6188\n","Epoch [4/20] Batch 200/391 Loss D: -7.0592, loss G: 200.9016\n","Epoch [4/20] Batch 300/391 Loss D: -11.7806, loss G: 185.5041\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [5/20] Batch 0/391 Loss D: -8.1308, loss G: 196.2355\n","Epoch [5/20] Batch 100/391 Loss D: -10.5100, loss G: 190.3661\n","Epoch [5/20] Batch 200/391 Loss D: -11.1097, loss G: 199.7760\n","Epoch [5/20] Batch 300/391 Loss D: -12.9621, loss G: 186.0485\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [6/20] Batch 0/391 Loss D: -9.5524, loss G: 210.3819\n","Epoch [6/20] Batch 100/391 Loss D: -11.4039, loss G: 181.6757\n","Epoch [6/20] Batch 200/391 Loss D: -10.6636, loss G: 203.8376\n","Epoch [6/20] Batch 300/391 Loss D: -8.5557, loss G: 190.4333\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [7/20] Batch 0/391 Loss D: -12.9448, loss G: 189.2382\n","Epoch [7/20] Batch 100/391 Loss D: -12.4552, loss G: 187.8415\n","Epoch [7/20] Batch 200/391 Loss D: -11.4775, loss G: 202.8240\n","Epoch [7/20] Batch 300/391 Loss D: -9.8031, loss G: 190.2688\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [8/20] Batch 0/391 Loss D: -11.3777, loss G: 205.3294\n","Epoch [8/20] Batch 100/391 Loss D: -10.1285, loss G: 198.6243\n","Epoch [8/20] Batch 200/391 Loss D: -10.1353, loss G: 195.3977\n","Epoch [8/20] Batch 300/391 Loss D: -15.1649, loss G: 181.0493\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [9/20] Batch 0/391 Loss D: -8.2098, loss G: 204.5220\n","Epoch [9/20] Batch 100/391 Loss D: -9.3642, loss G: 206.6378\n","Epoch [9/20] Batch 200/391 Loss D: -9.6776, loss G: 183.2399\n","Epoch [9/20] Batch 300/391 Loss D: -9.4196, loss G: 196.7508\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [10/20] Batch 0/391 Loss D: -7.6457, loss G: 189.6092\n","Epoch [10/20] Batch 100/391 Loss D: -14.2452, loss G: 183.6849\n","Epoch [10/20] Batch 200/391 Loss D: -10.3183, loss G: 196.4293\n","Epoch [10/20] Batch 300/391 Loss D: -11.1116, loss G: 185.2677\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [11/20] Batch 0/391 Loss D: -11.4961, loss G: 194.2302\n","Epoch [11/20] Batch 100/391 Loss D: -8.2287, loss G: 192.4791\n","Epoch [11/20] Batch 200/391 Loss D: -10.6007, loss G: 182.2011\n","Epoch [11/20] Batch 300/391 Loss D: -10.7295, loss G: 191.1859\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [12/20] Batch 0/391 Loss D: -12.9316, loss G: 192.7502\n","Epoch [12/20] Batch 100/391 Loss D: -14.7436, loss G: 197.9806\n","Epoch [12/20] Batch 200/391 Loss D: -11.0208, loss G: 184.2127\n","Epoch [12/20] Batch 300/391 Loss D: -10.8271, loss G: 184.6754\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [13/20] Batch 0/391 Loss D: -11.0267, loss G: 200.7284\n","Epoch [13/20] Batch 100/391 Loss D: -11.9021, loss G: 186.9326\n","Epoch [13/20] Batch 200/391 Loss D: -12.6418, loss G: 203.7171\n","Epoch [13/20] Batch 300/391 Loss D: -14.5805, loss G: 174.9335\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [14/20] Batch 0/391 Loss D: -11.8993, loss G: 182.2554\n","Epoch [14/20] Batch 100/391 Loss D: -10.1696, loss G: 190.0345\n","Epoch [14/20] Batch 200/391 Loss D: -6.3044, loss G: 200.5273\n","Epoch [14/20] Batch 300/391 Loss D: -12.5114, loss G: 176.0332\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [15/20] Batch 0/391 Loss D: -11.8369, loss G: 176.4012\n","Epoch [15/20] Batch 100/391 Loss D: -9.2534, loss G: 181.9510\n","Epoch [15/20] Batch 200/391 Loss D: -10.8738, loss G: 177.9922\n","Epoch [15/20] Batch 300/391 Loss D: -8.8908, loss G: 194.4221\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1GDpmAM6WxSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615983732602,"user_tz":-180,"elapsed":1080,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"f3d0fe2b-f244-4f19-e92f-91637b80e58f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# gen_checkpoint_name = 'generator_cats-dogs.pth.tar'\n","# critic_checkpoint_name = 'critic_cats-dogs.pth.tar'\n","\n","!ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp $gen_checkpoint_name    '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp $critic_checkpoint_name '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","total 243M\n","-rw------- 1 root root   32K Mar  1 12:56 '2021.02.26 basics.ipynb'\n","-rw------- 1 root root   33K Mar  1 12:59 '2021.03.01-1 Pytorch Neural Network example.ipynb'\n","-rw------- 1 root root   33K Mar  5 08:04 '2021.03.01-2 Convolutional Neural Network example.ipynb'\n","-rw------- 1 root root   20K Mar 10 10:20 '2021.03.01-3 Recurrent Neural Network example.ipynb'\n","-rw------- 1 root root   34K Mar  4 22:21 '2021.03.01-4 Bidirectional LSTM example.ipynb'\n","-rw------- 1 root root   11K Mar  5 14:30 '2021.03.02-1 How to save and load models in Pytorch.ipynb'\n","-rw------- 1 root root   16K Mar  2 14:21 '2021.03.02-2 Transfer Learning and Fine Tuning.ipynb'\n","-rw------- 1 root root   49K Mar  5 08:09 '2021.03.02-3 Build custom dataset.ipynb'\n","-rw------- 1 root root  1.5M Mar 10 08:06 '2021.03.03-1 How to build custom Datasets for Text in Pytorch.ipynb'\n","-rw------- 1 root root 1013K Mar  4 17:47 '2021.03.03-2 Data Augmentation using Torchvision.ipynb'\n","-rw------- 1 root root  3.3M Mar 17 11:34 '2021.03.03-3 Albumentations library for data augmentation.ipynb'\n","-rw------- 1 root root  7.4K Mar  4 19:53 '2021.03.04 How to deal with imbalanced datasets.ipynb'\n","-rw------- 1 root root   50M Mar  5 13:27 '2021.03.05-1 Pytorch TensorBoard.ipynb'\n","-rw------- 1 root root   13K Mar  5 14:49 '2021.03.05-2 LeNet implementation.ipynb'\n","-rw------- 1 root root   11K Mar  9 19:55 '2021.03.09-1 VGG implementation.ipynb'\n","-rw------- 1 root root   39K Mar  9 19:59 '2021.03.09-2 GoogLeNet implementation.ipynb'\n","-rw------- 1 root root   13K Mar  9 20:06 '2021.03.09-3 ResNet implementation.ipynb'\n","-rw------- 1 root root   17K Mar  9 20:55 '2021.03.09-4 EfficientNet implementation.ipynb'\n","-rw------- 1 root root   25M Mar 13 10:24 '2021.03.10-1 Image Captioning.ipynb'\n","-rw------- 1 root root   11K Mar 13 10:41 '2021.03.11-1 Neural Style Transfer.ipynb'\n","-rw------- 1 root root   24M Mar 13 12:55 '2021.03.11-2 Simple GAN.ipynb'\n","-rw------- 1 root root   31M Mar 15 11:51 '2021.03.15-1 DCGAN implementation.ipynb'\n","-rw------- 1 root root   31M Mar 16 11:34 '2021.03.15-2 WGAN implementation.ipynb'\n","-rw------- 1 root root   29M Mar 16 12:34 '2021.03.15-3 WGAN-GP implementation.ipynb'\n","-rw------- 1 root root   50M Mar 17 12:21 '2021.03.16-1 Conditional GAN implementation.ipynb'\n","-rw------- 1 root root   18K Mar 17 12:15 '2021.03.17-1 Pix2Pix GAN implementation.ipynb'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WMQGA5ZbHxyk"},"source":[""],"execution_count":null,"outputs":[]}]}