{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.15-3 WGAN-GP implementation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QkEk_qlTqJKc"},"source":["# Wasserstein GAN with gradient penalty implementation\n","\n","[Original video](https://youtu.be/pG0QZ7OddX4)\n","\n","[Read-through: Wasserstein GAN](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)\n","\n","[Wasserstein GAN paper](https://arxiv.org/abs/1701.07875)\n","\n","[Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) paper"]},{"cell_type":"markdown","metadata":{"id":"BXTZVrN_EtXA"},"source":["## Download and prepare dataset. Import libraries"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":157},"id":"_ReQZUD00QYW","executionInfo":{"status":"ok","timestamp":1615888857742,"user_tz":-180,"elapsed":36302,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"12e30908-3af8-4578-d611-af6f69f83932"},"source":["# Get dataset from Kaggle\n","\n","# Colab's file access feature\n","from google.colab import files\n","\n","# Upload `kaggle.json` file\n","uploaded = files.upload()\n","\n","# Retrieve uploaded file and print results\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then copy kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","\n","# Download the dataset\n","# !kaggle datasets list -s celeba\n","!kaggle datasets download -d jessicali9530/celeba-dataset"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-11045512-53b3-432e-b2a2-dfcfac3ff4be\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-11045512-53b3-432e-b2a2-dfcfac3ff4be\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 65 bytes\n","kaggle.json\n","Downloading celeba-dataset.zip to /content\n"," 99% 1.32G/1.33G [00:25<00:00, 77.5MB/s]\n","100% 1.33G/1.33G [00:26<00:00, 54.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gz0x2Bda0Ty2"},"source":["# Unzip\n","import zipfile\n","\n","with zipfile.ZipFile('celeba-dataset.zip', 'r') as zip_ref:\n","    zip_ref.extractall('.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh0ZGgnwp1Pk"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import multiprocessing\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbNCflKA0nY2"},"source":["class MyDataset(Dataset):\n","    def __init__(self, root, transform):\n","        self.root = root\n","        self.transform = transform\n","        \n","        self.img_name = {}\n","        for idx, name in enumerate(os.listdir(self.root)):\n","            self.img_name[idx] = name\n","\n","    def __len__(self):\n","        return len(self.img_name)  # 202 599 images\n","\n","    def __getitem__(self, index):\n","        filepath = os.path.join(self.root, self.img_name[index])\n","        image = Image.open(filepath)\n","        image = self.transform(image)\n","        return image\n","\n","\n","image_folder = './img_align_celeba/img_align_celeba'\n","IMAGE_SIZE = 64\n","\n","transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),  # resize proportionally to rectangular image\n","    transforms.RandomCrop(IMAGE_SIZE),  # crop rectangular image to square\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5),\n","                         (0.5, 0.5, 0.5)),\n","])\n","\n","dataset = MyDataset(root=image_folder, transform=transform)\n","\n","\n","def save_checkpoint(state, filename):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    step = checkpoint[\"step\"]\n","    return step"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pKL28RjE3xb"},"source":["## Set and test the model"]},{"cell_type":"code","metadata":{"id":"MHV9OY45sNj2"},"source":["class Critic(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Critic, self).__init__()\n","        self.critic = nn.Sequential(  # Input: N x 3 x 64 x64\n","            self._block(channels_img, features_d,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            self._block(features_d,   features_d*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1),  # N x 512 x 4 x 4\n","            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=1, padding=0),  # N x 1 x 1 x 1\n","            nn.Flatten(),  # no nn.Sigmoid() anymore, this is why it is Critic, but not Discriminator\n","        )  # Output: N x 1\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            # bias=False for BatchNorm\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            # Do not normalize across the batches. Normalize only across the layer (instance).\n","            nn.InstanceNorm2d(out_channels, affine=True),  # LayerNorm <--> InstanceNorm\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.critic(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(  # Input: N x z_dim x 1 x 1\n","            self._block(z_dim,        features_g*8, kernel_size=4, stride=1, padding=0),  # N x 512 x 4 x 4\n","            self._block(features_g*8, features_g*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_g*4, features_g*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_g*2, features_g,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=1),\n","            # Output: N x 3 x 64 x 64\n","            nn.Tanh(),  # between (-1, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),  # like in DCGAN paper\n","        )\n","    \n","    def forward(self, x):\n","        return self.gen(x)\n","\n","\n","def init_weights(model):\n","    ''' Initialize weights of the model\n","        with mean of 0.0 and standard deviation of 0.02 '''\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, height, width = 8, 3, 64, 64\n","    z_dim = 100\n","    features_d = features_g = 64\n","    \n","    x = torch.randn((N, in_channels, height, width))\n","    critic = Critic(in_channels, features_d)\n","    init_weights(critic)\n","    assert critic(x).shape == (N, 1)\n","\n","    gen = Generator(z_dim, in_channels, features_g)\n","    init_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, height, width)\n","    \n","    print('Test is OK')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttVq_cb4CtxG","executionInfo":{"status":"ok","timestamp":1615888897024,"user_tz":-180,"elapsed":75563,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"9ae420db-4f56-46ba-b695-076056eb1088"},"source":["test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test is OK\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H4x94oaz1Htm"},"source":["## Run TensorBoard"]},{"cell_type":"code","metadata":{"id":"D8kXVPw41Kn9"},"source":["# Run TensorBoard\n","\n","# Delete previous logs dir\n","logs_dir = 'logs_dir'\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9N2_WWJofS6u"},"source":["## Prepare the model"]},{"cell_type":"code","metadata":{"id":"wabZt_YLEFnJ"},"source":["# Hyperparameters etc.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 1e-4  # could also use two lrs, one for gen and one for critic\n","BATCH_SIZE = 64  # was 64\n","CHANNELS_IMG = 3\n","NOISE_DIM = 128  # was 100\n","NUM_EPOCHS = 5\n","FEATURES_CRITIC = FEATURES_GEN = 64\n","CRITIC_ITERATIONS = 5\n","LAMBDA_GP = 10\n","\n","loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                    num_workers=multiprocessing.cpu_count(), pin_memory=True)\n","\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","critic = Critic(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n","init_weights(gen)\n","init_weights(critic)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n","\n","fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n","writer_real = SummaryWriter(os.path.join(logs_dir, \"real\"))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, \"fake\"))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_celeb.pth.tar'\n","critic_checkpoint_name = 'critic_celeb.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(critic_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, opt_gen)\n","    step = load_checkpoint(torch.load(critic_checkpoint_name), critic, opt_critic)\n","\n","\n","def gradient_penalty(critic, real, fake, device):\n","    BATCH_SIZE, C, H, W = real.shape\n","    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n","    interpolated_images = epsilon * real + (1 - epsilon) * fake\n","\n","    # calculate critic scores\n","    mixed_scores = critic(interpolated_images)\n","    # calculate gradient\n","    gradient = torch.autograd.grad(inputs=interpolated_images,\n","                                   outputs=mixed_scores,\n","                                   grad_outputs=torch.ones_like(mixed_scores),\n","                                   create_graph=True,\n","                                   retain_graph=True,)[0]  # BATCH_SIZE x 3 x 64 x 64\n","    gradient = gradient.view(gradient.shape[0], -1)  # BATCH_SIZE x 12 288 or 64*64*3\n","    gradient_norm = gradient.norm(2, dim=1)  # L2 norm\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IL-OR_myD6p"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"zb2GAj1xhr7r"},"source":["def train(step=step):\n","    gen.train()\n","    critic.train()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        # Target labels not needed! <3 unsupervised\n","        for batch_idx, real in enumerate(loader):\n","            real = real.to(device)\n","\n","            # Train Critic: max (E(critic(real)) - E(critic(fake)))\n","            # or min (-1) * (E(critic(real)) - E(critic(fake)))\n","            for _ in range(CRITIC_ITERATIONS):\n","                noise = torch.randn(real.shape[0], NOISE_DIM, 1, 1).to(device)\n","                fake = gen(noise)\n","                critic_real = critic(real)\n","                critic_fake = critic(fake)\n","                gp = gradient_penalty(critic, real, fake, device)\n","\n","                loss_critic = torch.mean(critic_fake) - torch.mean(critic_real) + LAMBDA_GP*gp\n","\n","                opt_critic.zero_grad()\n","                loss_critic.backward(retain_graph=True)\n","                opt_critic.step()\n","\n","            # Train Generator: min (E(critic(real)) - E(critic(fake)))\n","            # which is the same as: min (-1) * E(critic(fake))\n","            # because generator can not influence on E(critic(real)).\n","            output = critic(fake)\n","            loss_gen = -torch.mean(output)\n","\n","            opt_gen.zero_grad()\n","            loss_gen.backward()\n","            opt_gen.step()\n","\n","            # Print losses occasionally and print to tensorboard\n","            if batch_idx % 100 == 0:\n","                print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n","                    f\"Batch {batch_idx}/{len(loader)} \"\n","                    f\"Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\")\n","\n","                with torch.no_grad():\n","                    fake = gen(fixed_noise)\n","                    # take out (up to) 32 examples\n","                    img_grid_real = torchvision.utils.make_grid(\n","                        real[:32], normalize=True\n","                    )\n","                    img_grid_fake = torchvision.utils.make_grid(\n","                        fake[:32], normalize=True\n","                    )\n","\n","                    writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                    writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","                step += 1\n","\n","        # Save models\n","        gen_checkpoint = {\n","            'state_dict': gen.state_dict(),\n","            'optimizer': opt_gen.state_dict(),\n","            'step': step,\n","        }\n","        critic_checkpoint = {\n","            'state_dict': critic.state_dict(),\n","            'optimizer': opt_critic.state_dict(),\n","            'step': step,\n","        }\n","        save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","        save_checkpoint(critic_checkpoint, critic_checkpoint_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FvBUVqpx86R","executionInfo":{"status":"ok","timestamp":1615897628819,"user_tz":-180,"elapsed":8807336,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"a517bd2f-89a5-412f-c639-e5095127ad89"},"source":["train(step=step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/5] Batch 0/3166 Loss D: 7935.7070, loss G: -0.1983\n","Epoch [1/5] Batch 100/3166 Loss D: -26.8365, loss G: 32.4119\n","Epoch [1/5] Batch 200/3166 Loss D: -20.4779, loss G: 29.1151\n","Epoch [1/5] Batch 300/3166 Loss D: -28.7844, loss G: 42.3356\n","Epoch [1/5] Batch 400/3166 Loss D: -46.5882, loss G: 59.1718\n","Epoch [1/5] Batch 500/3166 Loss D: -38.3854, loss G: 66.0575\n","Epoch [1/5] Batch 600/3166 Loss D: -30.5604, loss G: 73.1024\n","Epoch [1/5] Batch 700/3166 Loss D: -28.6866, loss G: 52.6345\n","Epoch [1/5] Batch 800/3166 Loss D: -14.9460, loss G: 72.3076\n","Epoch [1/5] Batch 900/3166 Loss D: -20.1652, loss G: 69.6176\n","Epoch [1/5] Batch 1000/3166 Loss D: -17.4340, loss G: 69.3884\n","Epoch [1/5] Batch 1100/3166 Loss D: -17.2508, loss G: 68.5212\n","Epoch [1/5] Batch 1200/3166 Loss D: -15.9447, loss G: 72.8945\n","Epoch [1/5] Batch 1300/3166 Loss D: -16.1062, loss G: 68.3909\n","Epoch [1/5] Batch 1400/3166 Loss D: -17.9006, loss G: 70.9348\n","Epoch [1/5] Batch 1500/3166 Loss D: -18.3491, loss G: 72.8673\n","Epoch [1/5] Batch 1600/3166 Loss D: -16.1547, loss G: 70.9437\n","Epoch [1/5] Batch 1700/3166 Loss D: -16.4186, loss G: 78.2201\n","Epoch [1/5] Batch 1800/3166 Loss D: -14.5456, loss G: 70.1008\n","Epoch [1/5] Batch 1900/3166 Loss D: -16.6273, loss G: 71.8767\n","Epoch [1/5] Batch 2000/3166 Loss D: -14.8181, loss G: 78.6621\n","Epoch [1/5] Batch 2100/3166 Loss D: -16.1131, loss G: 76.8907\n","Epoch [1/5] Batch 2200/3166 Loss D: -16.9045, loss G: 77.9178\n","Epoch [1/5] Batch 2300/3166 Loss D: -14.9592, loss G: 77.9307\n","Epoch [1/5] Batch 2400/3166 Loss D: -14.8768, loss G: 82.9492\n","Epoch [1/5] Batch 2500/3166 Loss D: -12.5217, loss G: 79.2337\n","Epoch [1/5] Batch 2600/3166 Loss D: -13.0082, loss G: 78.0697\n","Epoch [1/5] Batch 2700/3166 Loss D: -13.2404, loss G: 80.3814\n","Epoch [1/5] Batch 2800/3166 Loss D: -13.1309, loss G: 88.1310\n","Epoch [1/5] Batch 2900/3166 Loss D: -17.1344, loss G: 75.0123\n","Epoch [1/5] Batch 3000/3166 Loss D: -14.7922, loss G: 85.2968\n","Epoch [1/5] Batch 3100/3166 Loss D: -13.6141, loss G: 80.9627\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/5] Batch 0/3166 Loss D: -14.8002, loss G: 83.1310\n","Epoch [2/5] Batch 100/3166 Loss D: -10.5348, loss G: 84.1674\n","Epoch [2/5] Batch 200/3166 Loss D: -11.6476, loss G: 83.4578\n","Epoch [2/5] Batch 300/3166 Loss D: -13.6874, loss G: 83.1590\n","Epoch [2/5] Batch 400/3166 Loss D: -10.6095, loss G: 92.1084\n","Epoch [2/5] Batch 500/3166 Loss D: -12.1779, loss G: 84.6675\n","Epoch [2/5] Batch 600/3166 Loss D: -14.5539, loss G: 85.6555\n","Epoch [2/5] Batch 700/3166 Loss D: -14.4141, loss G: 87.6237\n","Epoch [2/5] Batch 800/3166 Loss D: -12.3075, loss G: 85.1673\n","Epoch [2/5] Batch 900/3166 Loss D: -12.4648, loss G: 88.3055\n","Epoch [2/5] Batch 1000/3166 Loss D: -14.0203, loss G: 85.6701\n","Epoch [2/5] Batch 1100/3166 Loss D: -17.1192, loss G: 90.0104\n","Epoch [2/5] Batch 1200/3166 Loss D: -8.5149, loss G: 84.4898\n","Epoch [2/5] Batch 1300/3166 Loss D: -10.4990, loss G: 91.3552\n","Epoch [2/5] Batch 1400/3166 Loss D: -10.0101, loss G: 94.1708\n","Epoch [2/5] Batch 1500/3166 Loss D: -12.7908, loss G: 104.3260\n","Epoch [2/5] Batch 1600/3166 Loss D: -11.2687, loss G: 86.0721\n","Epoch [2/5] Batch 1700/3166 Loss D: -12.3901, loss G: 92.2363\n","Epoch [2/5] Batch 1800/3166 Loss D: -11.2212, loss G: 91.3070\n","Epoch [2/5] Batch 1900/3166 Loss D: -9.2792, loss G: 96.6208\n","Epoch [2/5] Batch 2000/3166 Loss D: -12.5692, loss G: 92.8408\n","Epoch [2/5] Batch 2100/3166 Loss D: -11.0058, loss G: 91.9083\n","Epoch [2/5] Batch 2200/3166 Loss D: -10.5142, loss G: 88.0692\n","Epoch [2/5] Batch 2300/3166 Loss D: -12.8643, loss G: 84.0143\n","Epoch [2/5] Batch 2400/3166 Loss D: -10.8143, loss G: 90.2458\n","Epoch [2/5] Batch 2500/3166 Loss D: -13.0113, loss G: 91.4726\n","Epoch [2/5] Batch 2600/3166 Loss D: -12.0047, loss G: 89.1279\n","Epoch [2/5] Batch 2700/3166 Loss D: -7.6641, loss G: 92.1334\n","Epoch [2/5] Batch 2800/3166 Loss D: -10.6730, loss G: 87.5760\n","Epoch [2/5] Batch 2900/3166 Loss D: -9.2023, loss G: 87.1731\n","Epoch [2/5] Batch 3000/3166 Loss D: -9.6172, loss G: 91.4747\n","Epoch [2/5] Batch 3100/3166 Loss D: -9.4245, loss G: 91.8847\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/5] Batch 0/3166 Loss D: -10.3627, loss G: 91.5297\n","Epoch [3/5] Batch 100/3166 Loss D: -9.8843, loss G: 90.9965\n","Epoch [3/5] Batch 200/3166 Loss D: -11.8467, loss G: 95.1397\n","Epoch [3/5] Batch 300/3166 Loss D: -10.6623, loss G: 91.1813\n","Epoch [3/5] Batch 400/3166 Loss D: -11.5219, loss G: 89.2586\n","Epoch [3/5] Batch 500/3166 Loss D: -10.3376, loss G: 92.2690\n","Epoch [3/5] Batch 600/3166 Loss D: -10.0456, loss G: 92.0456\n","Epoch [3/5] Batch 700/3166 Loss D: -10.6486, loss G: 90.0605\n","Epoch [3/5] Batch 800/3166 Loss D: -10.8037, loss G: 97.5542\n","Epoch [3/5] Batch 900/3166 Loss D: -10.6895, loss G: 93.2615\n","Epoch [3/5] Batch 1000/3166 Loss D: -9.5496, loss G: 73.6054\n","Epoch [3/5] Batch 1100/3166 Loss D: -9.8352, loss G: 88.2912\n","Epoch [3/5] Batch 1200/3166 Loss D: -8.6220, loss G: 94.9000\n","Epoch [3/5] Batch 1300/3166 Loss D: -11.7777, loss G: 91.4610\n","Epoch [3/5] Batch 1400/3166 Loss D: -8.6481, loss G: 95.3120\n","Epoch [3/5] Batch 1500/3166 Loss D: -8.2387, loss G: 77.8136\n","Epoch [3/5] Batch 1600/3166 Loss D: -9.8699, loss G: 97.6324\n","Epoch [3/5] Batch 1700/3166 Loss D: -6.4578, loss G: 88.9516\n","Epoch [3/5] Batch 1800/3166 Loss D: -11.1474, loss G: 101.0358\n","Epoch [3/5] Batch 1900/3166 Loss D: -13.2681, loss G: 101.3523\n","Epoch [3/5] Batch 2000/3166 Loss D: -11.0734, loss G: 87.2304\n","Epoch [3/5] Batch 2100/3166 Loss D: -9.1122, loss G: 97.2837\n","Epoch [3/5] Batch 2200/3166 Loss D: -8.2612, loss G: 93.8397\n","Epoch [3/5] Batch 2300/3166 Loss D: -8.6680, loss G: 92.2924\n","Epoch [3/5] Batch 2400/3166 Loss D: -5.7316, loss G: 92.6845\n","Epoch [3/5] Batch 2500/3166 Loss D: -7.5979, loss G: 101.5230\n","Epoch [3/5] Batch 2600/3166 Loss D: -9.2722, loss G: 85.3475\n","Epoch [3/5] Batch 2700/3166 Loss D: -10.1724, loss G: 89.1421\n","Epoch [3/5] Batch 2800/3166 Loss D: -11.2498, loss G: 92.5405\n","Epoch [3/5] Batch 2900/3166 Loss D: -9.0643, loss G: 80.8750\n","Epoch [3/5] Batch 3000/3166 Loss D: -8.8017, loss G: 84.9953\n","Epoch [3/5] Batch 3100/3166 Loss D: -9.6880, loss G: 88.3876\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/5] Batch 0/3166 Loss D: -10.2443, loss G: 94.6751\n","Epoch [4/5] Batch 100/3166 Loss D: -7.4575, loss G: 96.6821\n","Epoch [4/5] Batch 200/3166 Loss D: -10.3412, loss G: 92.3214\n","Epoch [4/5] Batch 300/3166 Loss D: -10.4453, loss G: 95.6342\n","Epoch [4/5] Batch 400/3166 Loss D: -11.1119, loss G: 85.2481\n","Epoch [4/5] Batch 500/3166 Loss D: -9.1441, loss G: 89.6891\n","Epoch [4/5] Batch 600/3166 Loss D: -12.7443, loss G: 96.2928\n","Epoch [4/5] Batch 700/3166 Loss D: -9.3100, loss G: 91.0282\n","Epoch [4/5] Batch 800/3166 Loss D: -10.9807, loss G: 91.2944\n","Epoch [4/5] Batch 900/3166 Loss D: -10.8209, loss G: 96.8927\n","Epoch [4/5] Batch 1000/3166 Loss D: -9.7582, loss G: 98.9517\n","Epoch [4/5] Batch 1100/3166 Loss D: -7.2653, loss G: 90.0660\n","Epoch [4/5] Batch 1200/3166 Loss D: -7.8911, loss G: 91.3434\n","Epoch [4/5] Batch 1300/3166 Loss D: -9.1700, loss G: 89.6126\n","Epoch [4/5] Batch 1400/3166 Loss D: -15.7047, loss G: 94.9847\n","Epoch [4/5] Batch 1500/3166 Loss D: -9.1287, loss G: 87.7244\n","Epoch [4/5] Batch 1600/3166 Loss D: -6.5099, loss G: 89.4050\n","Epoch [4/5] Batch 1700/3166 Loss D: -8.8292, loss G: 83.6894\n","Epoch [4/5] Batch 1800/3166 Loss D: -5.9962, loss G: 87.6883\n","Epoch [4/5] Batch 1900/3166 Loss D: -11.5186, loss G: 91.2977\n","Epoch [4/5] Batch 2000/3166 Loss D: -7.1715, loss G: 86.1952\n","Epoch [4/5] Batch 2100/3166 Loss D: -7.8749, loss G: 90.9899\n","Epoch [4/5] Batch 2200/3166 Loss D: -6.6645, loss G: 94.1621\n","Epoch [4/5] Batch 2300/3166 Loss D: -7.1570, loss G: 80.1181\n","Epoch [4/5] Batch 2400/3166 Loss D: -11.2332, loss G: 84.8864\n","Epoch [4/5] Batch 2500/3166 Loss D: -11.4995, loss G: 90.7179\n","Epoch [4/5] Batch 2600/3166 Loss D: -9.3769, loss G: 88.1635\n","Epoch [4/5] Batch 2700/3166 Loss D: -9.8983, loss G: 101.8901\n","Epoch [4/5] Batch 2800/3166 Loss D: -7.4558, loss G: 85.6068\n","Epoch [4/5] Batch 2900/3166 Loss D: -6.9289, loss G: 84.2703\n","Epoch [4/5] Batch 3000/3166 Loss D: -7.6255, loss G: 88.3122\n","Epoch [4/5] Batch 3100/3166 Loss D: -12.9522, loss G: 98.6518\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [5/5] Batch 0/3166 Loss D: -9.9320, loss G: 87.7344\n","Epoch [5/5] Batch 100/3166 Loss D: -10.3547, loss G: 78.6788\n","Epoch [5/5] Batch 200/3166 Loss D: -12.8879, loss G: 92.0387\n","Epoch [5/5] Batch 300/3166 Loss D: -9.2989, loss G: 77.7722\n","Epoch [5/5] Batch 400/3166 Loss D: -5.3930, loss G: 88.4805\n","Epoch [5/5] Batch 500/3166 Loss D: -8.5611, loss G: 82.2623\n","Epoch [5/5] Batch 600/3166 Loss D: -8.4408, loss G: 85.4606\n","Epoch [5/5] Batch 700/3166 Loss D: -7.2877, loss G: 84.2816\n","Epoch [5/5] Batch 800/3166 Loss D: -6.7738, loss G: 83.2731\n","Epoch [5/5] Batch 900/3166 Loss D: -9.3219, loss G: 79.7109\n","Epoch [5/5] Batch 1000/3166 Loss D: -7.9133, loss G: 83.4649\n","Epoch [5/5] Batch 1100/3166 Loss D: -8.6056, loss G: 95.0920\n","Epoch [5/5] Batch 1200/3166 Loss D: -7.7029, loss G: 80.1396\n","Epoch [5/5] Batch 1300/3166 Loss D: -7.6368, loss G: 81.5576\n","Epoch [5/5] Batch 1400/3166 Loss D: -7.9977, loss G: 80.4363\n","Epoch [5/5] Batch 1500/3166 Loss D: -11.8051, loss G: 69.5179\n","Epoch [5/5] Batch 1600/3166 Loss D: -6.8512, loss G: 87.3525\n","Epoch [5/5] Batch 1700/3166 Loss D: -7.7070, loss G: 80.0911\n","Epoch [5/5] Batch 1800/3166 Loss D: -9.1504, loss G: 87.9713\n","Epoch [5/5] Batch 1900/3166 Loss D: -9.7314, loss G: 82.2488\n","Epoch [5/5] Batch 2000/3166 Loss D: -7.2676, loss G: 77.4032\n","Epoch [5/5] Batch 2100/3166 Loss D: -8.4474, loss G: 77.0552\n","Epoch [5/5] Batch 2200/3166 Loss D: -8.4470, loss G: 81.8962\n","Epoch [5/5] Batch 2300/3166 Loss D: -8.1400, loss G: 82.7573\n","Epoch [5/5] Batch 2400/3166 Loss D: -9.0590, loss G: 80.1490\n","Epoch [5/5] Batch 2500/3166 Loss D: -10.2543, loss G: 88.8159\n","Epoch [5/5] Batch 2600/3166 Loss D: -12.4918, loss G: 80.6205\n","Epoch [5/5] Batch 2700/3166 Loss D: -12.0815, loss G: 85.4173\n","Epoch [5/5] Batch 2800/3166 Loss D: -7.3731, loss G: 89.4734\n","Epoch [5/5] Batch 2900/3166 Loss D: -7.8651, loss G: 80.1275\n","Epoch [5/5] Batch 3000/3166 Loss D: -5.9189, loss G: 76.8994\n","Epoch [5/5] Batch 3100/3166 Loss D: -8.7806, loss G: 82.1895\n","=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sNbDOavm3Qfv"},"source":["## Save models if necessary"]},{"cell_type":"code","metadata":{"id":"J5v5jbdBIFcd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615898013159,"user_tz":-180,"elapsed":9191673,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"8dfee554-d92a-4b7e-e975-80b2fb5606a9"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp critic_celeb.pth.tar '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp generator_celeb.pth.tar     '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","total 193M\n","-rw------- 1 root root   32K Mar  1 12:56 '2021.02.26 basics.ipynb'\n","-rw------- 1 root root   33K Mar  1 12:59 '2021.03.01-1 Pytorch Neural Network example.ipynb'\n","-rw------- 1 root root   33K Mar  5 08:04 '2021.03.01-2 Convolutional Neural Network example.ipynb'\n","-rw------- 1 root root   20K Mar 10 10:20 '2021.03.01-3 Recurrent Neural Network example.ipynb'\n","-rw------- 1 root root   34K Mar  4 22:21 '2021.03.01-4 Bidirectional LSTM example.ipynb'\n","-rw------- 1 root root   11K Mar  5 14:30 '2021.03.02-1 How to save and load models in Pytorch.ipynb'\n","-rw------- 1 root root   16K Mar  2 14:21 '2021.03.02-2 Transfer Learning and Fine Tuning.ipynb'\n","-rw------- 1 root root   49K Mar  5 08:09 '2021.03.02-3 Build custom dataset.ipynb'\n","-rw------- 1 root root  1.5M Mar 10 08:06 '2021.03.03-1 How to build custom Datasets for Text in Pytorch.ipynb'\n","-rw------- 1 root root 1013K Mar  4 17:47 '2021.03.03-2 Data Augmentation using Torchvision.ipynb'\n","-rw------- 1 root root  3.3M Mar  4 17:01 '2021.03.03-3 Albumentations library for data augmentation.ipynb'\n","-rw------- 1 root root  7.4K Mar  4 19:53 '2021.03.04 How to deal with imbalanced datasets.ipynb'\n","-rw------- 1 root root   50M Mar  5 13:27 '2021.03.05-1 Pytorch TensorBoard.ipynb'\n","-rw------- 1 root root   13K Mar  5 14:49 '2021.03.05-2 LeNet implementation.ipynb'\n","-rw------- 1 root root   11K Mar  9 19:55 '2021.03.09-1 VGG implementation.ipynb'\n","-rw------- 1 root root   39K Mar  9 19:59 '2021.03.09-2 GoogLeNet implementation.ipynb'\n","-rw------- 1 root root   13K Mar  9 20:06 '2021.03.09-3 ResNet implementation.ipynb'\n","-rw------- 1 root root   17K Mar  9 20:55 '2021.03.09-4 EfficientNet implementation.ipynb'\n","-rw------- 1 root root   25M Mar 13 10:24 '2021.03.10-1 Image Captioning.ipynb'\n","-rw------- 1 root root   11K Mar 13 10:41 '2021.03.11-1 Neural Style Transfer.ipynb'\n","-rw------- 1 root root   24M Mar 13 12:55 '2021.03.11-2 Simple GAN.ipynb'\n","-rw------- 1 root root   31M Mar 15 11:51 '2021.03.15-1 DCGAN implementation.ipynb'\n","-rw------- 1 root root   31M Mar 16 11:34 '2021.03.15-2 WGAN implementation.ipynb'\n","-rw------- 1 root root   29M Mar 16 12:28 '2021.03.15-3 WGAN-GP implementation.ipynb'\n","-rw------- 1 root root   16K Mar 16 12:33 '2021.03.16-1 Conditional GAN implementation.ipynb'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blG7TNNCTAez"},"source":[""],"execution_count":null,"outputs":[]}]}