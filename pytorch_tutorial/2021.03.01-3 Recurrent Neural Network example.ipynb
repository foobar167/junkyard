{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.01-3 Recurrent Neural Network example.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4R5Gh+2qtIDG5tpASQvZ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2GQhgRH-3gON"},"source":["# Recurrent Neural Network example\r\n","\r\n","[Original video](https://youtu.be/Gl2WXLIMvKA)\r\n","\r\n","Input of RNN is Nx28x28 --> 28 time sequences with 28 features each.\r\n","\r\n","N x time_sequence x features"]},{"cell_type":"code","metadata":{"id":"0ZeICOD63YaO"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","import torch.nn.functional as F\r\n","import torchvision.datasets as datasets\r\n","import torchvision.transforms as transforms\r\n","\r\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUMoPf7YPAb8"},"source":["# Set deterministic\r\n","seed = 0\r\n","torch.backends.cudnn.deterministic = True\r\n","torch.backends.cudnn.benchmark = False\r\n","torch.manual_seed(seed)\r\n","torch.cuda.manual_seed_all(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VII6ioBo8cO5"},"source":["# Set device\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wm4BD9nj98QB"},"source":["# Hyperparameters\r\n","input_size = 28  # number of features for each time step\r\n","sequence_length = 28\r\n","num_layers = 2\r\n","hidden_size = 256  # number of nodes in each time step\r\n","num_classes = 10\r\n","learning_rate = 0.001\r\n","batch_size = 64\r\n","num_epochs = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KbhgV7OKMMmF"},"source":["## RNN"]},{"cell_type":"code","metadata":{"id":"DFK7cjw8518b"},"source":["# Create a RNN\r\n","class RNN(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n","        super(RNN, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.num_layers = num_layers\r\n","        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\r\n","        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\r\n","\r\n","    def forward(self, x):\r\n","        # init hidden state\r\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        \r\n","        # forward propagation\r\n","        out, _ = self.rnn(x, h0)  # \"_\" => ignore the hidden state output\r\n","        out = out.reshape(out.shape[0], -1)\r\n","        out = self.fc(out)\r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-72LpCcH8QB6","executionInfo":{"status":"ok","timestamp":1614895129752,"user_tz":-180,"elapsed":539,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"deb040aa-26d4-4c55-8322-502abf2bdccf"},"source":["# Check if it runs correctly\r\n","# MNIST 28x28=784, output classes = 10\r\n","model = RNN(input_size=input_size, hidden_size=hidden_size,\r\n","            num_layers=num_layers, num_classes=num_classes).to(device)\r\n","\r\n","x = torch.randn(batch_size, 28, 28).to(device)\r\n","\r\n","# Run model on the input and print the shape\r\n","print(model(x).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([64, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1mxVg-29v-C"},"source":["# For the error: HTTPError: HTTP Error 403: Forbidden\r\n","# StackOverflow: https://stackoverflow.com/a/66461122/7550928\r\n","from six.moves import urllib    \r\n","opener = urllib.request.build_opener()\r\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\r\n","urllib.request.install_opener(opener)\r\n","\r\n","# Load data\r\n","train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\r\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n","\r\n","test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\r\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rI3LnI7A_n2M"},"source":["# Initialize network\r\n","model = RNN(input_size=input_size, hidden_size=hidden_size,\r\n","           num_layers=num_layers, num_classes=num_classes).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEpI4LtxA2Qy"},"source":["# Loss function and optimizer\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EuzV_GYBhpE"},"source":["# Train network\r\n","for epoch in range(num_epochs):\r\n","    for batch_idx, (data, targets) in enumerate(train_loader):\r\n","        # Get data to Cuda if possible\r\n","        data = data.to(device=device).squeeze(1)\r\n","        targets = targets.to(device=device)\r\n","\r\n","        # Forward\r\n","        scores = model(data)  # shape 64x10\r\n","        loss = criterion(scores, targets)\r\n","\r\n","        # Backward\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n","\r\n","        # Gradient descent or adam step\r\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBhvPk_lCcQE"},"source":["# Check accuracy on training and test to see how good our model\r\n","def check_accuracy(loader, model):\r\n","    if loader.dataset.train:\r\n","        print('Checking accuracy on training data')\r\n","    else:\r\n","        print('Checking accuracy on test data')\r\n","    num_correct = 0\r\n","    num_samples = 0\r\n","    model.eval()  # set model into evaluation mode\r\n","\r\n","    with torch.no_grad():\r\n","        for x, y in loader:\r\n","            x = x.to(device=device).squeeze(1)\r\n","            y = y.to(device=device)\r\n","\r\n","            scores = model(x)  # shape = 64x10\r\n","            _, predictions = scores.max(dim=1)  # get index of max value\r\n","            num_correct += (predictions == y).sum()\r\n","            num_samples += predictions.size(0)\r\n","\r\n","    acc = float(num_correct) / float(num_samples) * 100\r\n","    print(f'Got {num_correct} / {num_samples} with accuracy {acc:.2f}')\r\n","\r\n","    model.train()  # set model into train mode\r\n","    #return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WguA6V4DJH90","executionInfo":{"status":"ok","timestamp":1614896161000,"user_tz":-180,"elapsed":23328,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"a2696e64-b414-4200-b164-e550909fa1d7"},"source":["check_accuracy(train_loader, model)\r\n","check_accuracy(test_loader, model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Checking accuracy on training data\n","Got 58295 / 60000 with accuracy 97.16\n","Checking accuracy on test data\n","Got 9717 / 10000 with accuracy 97.17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thO2iZ3PKI18"},"source":["# Without gradient clipping (a little bit lower accuracy)\r\n","#   Checking accuracy on training data\r\n","#   Got 57072 / 60000 with accuracy 95.12\r\n","#   Checking accuracy on test data\r\n","#   Got 9517 / 10000 with accuracy 95.17\r\n","\r\n","# Gradient clipping ( a little bit better)\r\n","#   Checking accuracy on training data\r\n","#   Got 58295 / 60000 with accuracy 97.16\r\n","#   Checking accuracy on test data\r\n","#   Got 9717 / 10000 with accuracy 97.17"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e_9_rK7cMIev"},"source":["## GRU"]},{"cell_type":"code","metadata":{"id":"zr28jk_s8cSj"},"source":["# Create a GRU\r\n","class GRU(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n","        super(GRU, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.num_layers = num_layers\r\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\r\n","        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\r\n","\r\n","    def forward(self, x):\r\n","        # init hidden state\r\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        \r\n","        # forward propagation\r\n","        out, _ = self.gru(x, h0)  # \"_\" => ignore the hidden state output\r\n","        out = out.reshape(out.shape[0], -1)\r\n","        out = self.fc(out)\r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT8U4OZC8kqT","executionInfo":{"status":"ok","timestamp":1614606839050,"user_tz":-180,"elapsed":74376,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"325193df-e63a-449b-e287-d1521f2322b9"},"source":["# Initialize network\r\n","model = GRU(input_size=input_size, hidden_size=hidden_size,\r\n","           num_layers=num_layers, num_classes=num_classes).to(device)\r\n","\r\n","# Loss function and optimizer\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\r\n","\r\n","# Train network\r\n","for epoch in range(num_epochs):\r\n","    for batch_idx, (data, targets) in enumerate(train_loader):\r\n","        # Get data to Cuda if possible\r\n","        data = data.to(device=device).squeeze(1)\r\n","        targets = targets.to(device=device)\r\n","\r\n","        # Forward\r\n","        scores = model(data)  # shape 64x10\r\n","        loss = criterion(scores, targets)\r\n","\r\n","        # Backward\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n","\r\n","        # Gradient descent or adam step\r\n","        optimizer.step()\r\n","\r\n","# Check accuracy on training and test to see how good our model\r\n","def check_accuracy(loader, model):\r\n","    if loader.dataset.train:\r\n","        print('Checking accuracy on training data')\r\n","    else:\r\n","        print('Checking accuracy on test data')\r\n","    num_correct = 0\r\n","    num_samples = 0\r\n","    model.eval()  # set model into evaluation mode\r\n","\r\n","    with torch.no_grad():\r\n","        for x, y in loader:\r\n","            x = x.to(device=device).squeeze(1)\r\n","            y = y.to(device=device)\r\n","\r\n","            scores = model(x)  # shape = 64x10\r\n","            _, predictions = scores.max(dim=1)  # get index of max value\r\n","            num_correct += (predictions == y).sum()\r\n","            num_samples += predictions.size(0)\r\n","\r\n","    acc = float(num_correct) / float(num_samples) * 100\r\n","    print(f'Got {num_correct} / {num_samples} with accuracy {acc:.2f}')\r\n","\r\n","    model.train()  # set model into train mode\r\n","    #return acc\r\n","\r\n","check_accuracy(train_loader, model)\r\n","check_accuracy(test_loader, model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Checking accuracy on training data\n","Got 59210 / 60000 with accuracy 98.68\n","Checking accuracy on test data\n","Got 9857 / 10000 with accuracy 98.57\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nZJboWqw860y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32QWLsSRMSmQ"},"source":["## LSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzC4CA_--AO6","executionInfo":{"status":"ok","timestamp":1614606875621,"user_tz":-180,"elapsed":110933,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"592fc905-6d39-413a-a410-55c3dd4b99c7"},"source":["# Create a LSTM\r\n","class LSTM(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n","        super(LSTM, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.num_layers = num_layers\r\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\r\n","        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\r\n","\r\n","    def forward(self, x):\r\n","        # init hidden state\r\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        # init serapate cell state\r\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        \r\n","        # forward propagation\r\n","        out, _ = self.lstm(x, (h0, c0))  # \"_\" => ignore the hidden state output\r\n","        out = out.reshape(out.shape[0], -1)\r\n","        out = self.fc(out)\r\n","        return out\r\n","\r\n","# Initialize network\r\n","model = LSTM(input_size=input_size, hidden_size=hidden_size,\r\n","           num_layers=num_layers, num_classes=num_classes).to(device)\r\n","\r\n","# Loss function and optimizer\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\r\n","\r\n","# Train network\r\n","for epoch in range(num_epochs):\r\n","    for batch_idx, (data, targets) in enumerate(train_loader):\r\n","        # Get data to Cuda if possible\r\n","        data = data.to(device=device).squeeze(1)\r\n","        targets = targets.to(device=device)\r\n","\r\n","        # Forward\r\n","        scores = model(data)  # shape 64x10\r\n","        loss = criterion(scores, targets)\r\n","\r\n","        # Backward\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n","\r\n","        # Gradient descent or adam step\r\n","        optimizer.step()\r\n","\r\n","# Check accuracy on training and test to see how good our model\r\n","def check_accuracy(loader, model):\r\n","    if loader.dataset.train:\r\n","        print('Checking accuracy on training data')\r\n","    else:\r\n","        print('Checking accuracy on test data')\r\n","    num_correct = 0\r\n","    num_samples = 0\r\n","    model.eval()  # set model into evaluation mode\r\n","\r\n","    with torch.no_grad():\r\n","        for x, y in loader:\r\n","            x = x.to(device=device).squeeze(1)\r\n","            y = y.to(device=device)\r\n","\r\n","            scores = model(x)  # shape = 64x10\r\n","            _, predictions = scores.max(dim=1)  # get index of max value\r\n","            num_correct += (predictions == y).sum()\r\n","            num_samples += predictions.size(0)\r\n","\r\n","    acc = float(num_correct) / float(num_samples) * 100\r\n","    print(f'Got {num_correct} / {num_samples} with accuracy {acc:.2f}')\r\n","\r\n","    model.train()  # set model into train mode\r\n","    #return acc\r\n","\r\n","check_accuracy(train_loader, model)\r\n","check_accuracy(test_loader, model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Checking accuracy on training data\n","Got 59182 / 60000 with accuracy 98.64\n","Checking accuracy on test data\n","Got 9841 / 10000 with accuracy 98.41\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5WvjPWq-vg9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Y6PVL5eMXkY"},"source":["## LSTM with only the last hidden state"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtI4r1XmBDdU","executionInfo":{"status":"ok","timestamp":1614606912507,"user_tz":-180,"elapsed":147806,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"101c6d2b-b3a9-4ac9-cc0d-92fa1ba212e1"},"source":["# Use information only from the last hidden state and ignore other hidden states.\r\n","\r\n","# Create a LSTM\r\n","class LSTM(nn.Module):\r\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n","        super(LSTM, self).__init__()\r\n","        self.hidden_size = hidden_size\r\n","        self.num_layers = num_layers\r\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\r\n","        #self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\r\n","        self.fc = nn.Linear(hidden_size, num_classes)\r\n","\r\n","    def forward(self, x):\r\n","        # init hidden state\r\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        # init serapate cell state\r\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\r\n","        \r\n","        # forward propagation\r\n","        out, _ = self.lstm(x, (h0, c0))  # \"_\" => ignore the hidden state output\r\n","        #out = out.reshape(out.shape[0], -1)\r\n","        #print(out.shape)  # torch.Size([64, 28, 256])\r\n","        #print(out[:,-1,:].shape)  # torch.Size([64, 256])\r\n","        out = self.fc(out[:,-1,:])\r\n","        return out\r\n","\r\n","# Initialize network\r\n","model = LSTM(input_size=input_size, hidden_size=hidden_size,\r\n","           num_layers=num_layers, num_classes=num_classes).to(device)\r\n","\r\n","# Loss function and optimizer\r\n","criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\r\n","\r\n","# Train network\r\n","for epoch in range(num_epochs):\r\n","    for batch_idx, (data, targets) in enumerate(train_loader):\r\n","        # Get data to Cuda if possible\r\n","        data = data.to(device=device).squeeze(1)\r\n","        targets = targets.to(device=device)\r\n","\r\n","        # Forward\r\n","        scores = model(data)  # shape 64x10\r\n","        loss = criterion(scores, targets)\r\n","\r\n","        # Backward\r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\r\n","\r\n","        # Gradient descent or adam step\r\n","        optimizer.step()\r\n","\r\n","# Check accuracy on training and test to see how good our model\r\n","def check_accuracy(loader, model):\r\n","    if loader.dataset.train:\r\n","        print('Checking accuracy on training data')\r\n","    else:\r\n","        print('Checking accuracy on test data')\r\n","    num_correct = 0\r\n","    num_samples = 0\r\n","    model.eval()  # set model into evaluation mode\r\n","\r\n","    with torch.no_grad():\r\n","        for x, y in loader:\r\n","            x = x.to(device=device).squeeze(1)\r\n","            y = y.to(device=device)\r\n","\r\n","            scores = model(x)  # shape = 64x10\r\n","            _, predictions = scores.max(dim=1)  # get index of max value\r\n","            num_correct += (predictions == y).sum()\r\n","            num_samples += predictions.size(0)\r\n","\r\n","    acc = float(num_correct) / float(num_samples) * 100\r\n","    print(f'Got {num_correct} / {num_samples} with accuracy {acc:.2f}')\r\n","\r\n","    model.train()  # set model into train mode\r\n","    #return acc\r\n","\r\n","check_accuracy(train_loader, model)\r\n","check_accuracy(test_loader, model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Checking accuracy on training data\n","Got 58950 / 60000 with accuracy 98.25\n","Checking accuracy on test data\n","Got 9785 / 10000 with accuracy 97.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BfEuxwojB-y1"},"source":[""],"execution_count":null,"outputs":[]}]}