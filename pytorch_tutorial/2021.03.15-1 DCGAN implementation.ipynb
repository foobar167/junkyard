{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.15-1 DCGAN implementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QkEk_qlTqJKc"},"source":["# DCGAN implementation\n","\n","[Original video](https://youtu.be/IZtv9s_Wx9I)\n","\n","[DCGAN paper](https://arxiv.org/abs/1511.06434)\n","\n","[CelebA dataset](https://www.kaggle.com/dataset/504743cb487a5aed565ce14238c6343b7d650ffd28c071f03f2fd9b25819e6c9) used in video"]},{"cell_type":"markdown","metadata":{"id":"BXTZVrN_EtXA"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"nh0ZGgnwp1Pk"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import multiprocessing\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pKL28RjE3xb"},"source":["## Set and test the model"]},{"cell_type":"code","metadata":{"id":"MHV9OY45sNj2"},"source":["class Discriminator(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            # Input: N x channels_img x 64 x64\n","            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n","            # N x features_d x 32 x 32\n","            nn.LeakyReLU(0.2),\n","            self._block(features_d,   features_d*2, kernel_size=4, stride=2, padding=1),\n","            # N x features_d*2 x 16 x 16\n","            self._block(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1),\n","            # N x features_d*4 x 8 x 8\n","            self._block(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1),\n","            # N x features_d*8 x 4 x 4\n","            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=1, padding=0),\n","            # Output: N x 1 x 1 x 1 - False or True image?\n","            nn.Sigmoid(),  # between (0, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            # bias=False for BatchNorm\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2),\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(\n","            # Input: N x z_dim x 1 x 1\n","            self._block(z_dim,         features_g*16, kernel_size=4, stride=1, padding=0),\n","            # N x features_g*16 x 4 x 4\n","            self._block(features_g*16, features_g*8,  kernel_size=4, stride=2, padding=1),\n","            # N x features_g*8 x 8 x 8\n","            self._block(features_g*8,  features_g*4,  kernel_size=4, stride=2, padding=1),\n","            # N x features_g*4 x 16 x 16\n","            self._block(features_g*4,  features_g*2,  kernel_size=4, stride=2, padding=1),\n","            # N x features_g*2 x 32 x 32\n","            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1),\n","            # Output: N x channels_img x 64 x 64\n","            nn.Tanh(),  # between (-1, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),  # like in DCGAN paper\n","        )\n","    \n","    def forward(self, x):\n","        return self.gen(x)\n","\n","\n","def init_weights(model):\n","    ''' Initialize weights of the model\n","        with mean of 0.0 and standard deviation of 0.02 '''\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, height, width = 8, 3, 64, 64\n","    z_dim = 100\n","    features_d = features_g = 64\n","    \n","    x = torch.randn((N, in_channels, height, width))\n","    disc = Discriminator(in_channels, features_d)\n","    init_weights(disc)\n","    assert disc(x).shape == (N, 1, 1, 1)\n","    \n","    gen = Generator(z_dim, in_channels, features_g)\n","    init_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, height, width)\n","    \n","    print('Test is OK')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttVq_cb4CtxG","outputId":"7c1ef87b-1d9e-4d89-e449-1282db8608f6"},"source":["test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test is OK\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9N2_WWJofS6u"},"source":["## Prepare the model"]},{"cell_type":"code","metadata":{"id":"wabZt_YLEFnJ"},"source":["# Hyperparameters\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","learning_rate = 2e-4\n","batch_size = 128\n","image_size = 64\n","channels_img = 1  # MNIST dataset\n","z_dim = 100\n","num_epochs = 5\n","features_d = features_g = 64\n","\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5 for _ in range(channels_img)],\n","                         [0.5 for _ in range(channels_img)]),\n","])\n","\n","\n","def save_checkpoint(state, filename):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    step = checkpoint[\"step\"]\n","    return step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCep1I0ahanM","outputId":"c586186b-26fe-4f86-cd1b-8c80c35795b8"},"source":["# Get MNIST dataset\n","\n","# For the error: HTTPError: HTTP Error 503: Service Unavailable\n","# Use this instead\n","data_dir = '/content/dataset/MNIST/raw/'\n","if os.path.exists(data_dir):\n","    !rm -rf $data_dir\n","\n","!mkdir $data_dir\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","!wget --directory-prefix=$data_dir https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","\n","# For the error: HTTPError: HTTP Error 403: Forbidden\n","# StackOverflow: https://stackoverflow.com/a/66461122/7550928\n","from six.moves import urllib    \n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)\n","\n","dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-14 00:08:36--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz [following]\n","--2021-03-14 00:08:37--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1648877 (1.6M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’\n","\n","t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.1s    \n","\n","2021-03-14 00:08:37 (15.9 MB/s) - ‘/content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n","\n","--2021-03-14 00:08:37--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz [following]\n","--2021-03-14 00:08:37--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/t10k-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4542 (4.4K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’\n","\n","t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n","\n","2021-03-14 00:08:38 (65.5 MB/s) - ‘/content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n","\n","--2021-03-14 00:08:38--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz [following]\n","--2021-03-14 00:08:38--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-images-idx3-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9912422 (9.5M) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’\n","\n","train-images-idx3-u 100%[===================>]   9.45M  --.-KB/s    in 0.1s    \n","\n","2021-03-14 00:08:38 (95.1 MB/s) - ‘/content/dataset/MNIST/raw/train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n","\n","--2021-03-14 00:08:38--  https://github.com/golbin/TensorFlow-MNIST/raw/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz [following]\n","--2021-03-14 00:08:39--  https://raw.githubusercontent.com/golbin/TensorFlow-MNIST/master/mnist/data/train-labels-idx1-ubyte.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28881 (28K) [application/octet-stream]\n","Saving to: ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’\n","\n","train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.002s  \n","\n","2021-03-14 00:08:39 (18.0 MB/s) - ‘/content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz’ saved [28881/28881]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9IL-OR_myD6p"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zb2GAj1xhr7r","outputId":"6f65fdff-e1c5-41ce-d547-e924b95240f6"},"source":["# Initialize generator and discriminator\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","gen = Generator(z_dim, channels_img, features_g).to(device)\n","disc = Discriminator(channels_img, features_d).to(device)\n","init_weights(gen)\n","init_weights(disc)\n","\n","optim_gen = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n","optim_disc = optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(32, z_dim, 1, 1).to(device)\n","\n","# Set writer for TensorBoard\n","logs_dir = 'logs'\n","writer_real = SummaryWriter(os.path.join(logs_dir, 'real'))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, 'fake'))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_checkpoint.pth.tar'\n","disc_checkpoint_name = 'discriminator_checkpoint.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(disc_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, optim_gen)\n","    step = load_checkpoint(torch.load(disc_checkpoint_name), disc, optim_disc)\n","\n","\n","def train(step=step):\n","    gen.train()  # set the training mode\n","    disc.train()\n","\n","    for epoch in range(num_epochs):\n","        for batch_idx, (real, _) in enumerate(loader):\n","            real = real.to(device)\n","            noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n","            fake = gen(noise)\n","            \n","            # train Discriminator: max log(D(real)) + log(1-D(G(noise)))\n","            disc_real = disc(real).reshape(-1)  # convert (N,1,1,1) to (N)\n","            disc_fake = disc(fake).reshape(-1)\n","            loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n","            loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","            loss_disc = (loss_disc_real + loss_disc_fake) / 2.0\n","\n","            optim_disc.zero_grad()\n","            loss_disc.backward(retain_graph=True)\n","            optim_disc.step()\n","\n","            # train Generator: min log(1-D(G(noise))) or max log(D(G(noise)))\n","            disc_fake = disc(fake).reshape(-1)\n","            loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n","\n","            optim_gen.zero_grad()\n","            loss_gen.backward()\n","            optim_gen.step()\n","\n","            if batch_idx % 100 == 0:\n","                print(f'Epoch [{epoch+1}/{num_epochs}] '\n","                    f'Batch {batch_idx}/{len(loader)} '\n","                    f'Loss D {loss_disc:.4f}, '\n","                    f'Loss G {loss_gen:.4f}')\n","                \n","                with torch.no_grad():\n","                    fake = gen(fixed_noise)\n","                    # take out up to 32 examples\n","                    img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n","                    img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n","                    writer_fake.add_image('Fake', img_grid_fake, global_step=step)\n","                    writer_real.add_image('Real', img_grid_real, global_step=step)\n","                    step += 1\n","\n","        # Save models\n","        gen_checkpoint = {\n","            'state_dict': gen.state_dict(),\n","            'optimizer': optim_gen.state_dict(),\n","            'step': step,\n","        }\n","        disc_checkpoint = {\n","            'state_dict': disc.state_dict(),\n","            'optimizer': optim_disc.state_dict(),\n","            'step': step,\n","        }\n","        save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","        save_checkpoint(disc_checkpoint, disc_checkpoint_name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> Loading checkpoint\n","=> Loading checkpoint\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d2_dBgXhhKEl"},"source":["# Run TensorBoard\n","\n","# Delete previous logs dir\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FvBUVqpx86R","outputId":"b1dd869f-aab0-40c4-f21d-d33be783f8f1"},"source":["train(step=step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [0/5] Batch 0/469 Loss D 0.5832, Loss G 1.1512\n","Epoch [0/5] Batch 100/469 Loss D 0.5149, Loss G 1.3437\n","Epoch [0/5] Batch 200/469 Loss D 0.4812, Loss G 1.2768\n","Epoch [0/5] Batch 300/469 Loss D 0.6104, Loss G 2.8872\n","Epoch [0/5] Batch 400/469 Loss D 0.4146, Loss G 1.4031\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [1/5] Batch 0/469 Loss D 0.2906, Loss G 1.4812\n","Epoch [1/5] Batch 100/469 Loss D 0.1946, Loss G 1.8088\n","Epoch [1/5] Batch 200/469 Loss D 0.3059, Loss G 2.0534\n","Epoch [1/5] Batch 300/469 Loss D 0.4694, Loss G 0.7740\n","Epoch [1/5] Batch 400/469 Loss D 0.1517, Loss G 2.9533\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/5] Batch 0/469 Loss D 0.4461, Loss G 3.5786\n","Epoch [2/5] Batch 100/469 Loss D 0.3672, Loss G 1.3996\n","Epoch [2/5] Batch 200/469 Loss D 0.2524, Loss G 2.4544\n","Epoch [2/5] Batch 300/469 Loss D 0.5304, Loss G 1.4475\n","Epoch [2/5] Batch 400/469 Loss D 1.3871, Loss G 0.9206\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/5] Batch 0/469 Loss D 0.3246, Loss G 2.0569\n","Epoch [3/5] Batch 100/469 Loss D 1.0707, Loss G 0.5028\n","Epoch [3/5] Batch 200/469 Loss D 0.1145, Loss G 2.2998\n","Epoch [3/5] Batch 300/469 Loss D 0.4109, Loss G 2.7552\n","Epoch [3/5] Batch 400/469 Loss D 0.2061, Loss G 2.4604\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/5] Batch 0/469 Loss D 0.0770, Loss G 3.3117\n","Epoch [4/5] Batch 100/469 Loss D 0.0751, Loss G 3.3893\n","Epoch [4/5] Batch 200/469 Loss D 0.1405, Loss G 2.5140\n","Epoch [4/5] Batch 300/469 Loss D 0.1766, Loss G 5.3350\n","Epoch [4/5] Batch 400/469 Loss D 0.0700, Loss G 5.2047\n","=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sNbDOavm3Qfv"},"source":["## Train celebrity CelebA dataset"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":157},"id":"HXOQ-6t137G2","executionInfo":{"status":"ok","timestamp":1615805363103,"user_tz":-180,"elapsed":19863,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"4f4af01c-e004-4281-d2cf-908f084f9864"},"source":["# Get dataset from Kaggle\n","\n","# Colab's file access feature\n","from google.colab import files\n","\n","# Upload `kaggle.json` file\n","uploaded = files.upload()\n","\n","# Retrieve uploaded file and print results\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then copy kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","\n","# Download the dataset\n","# !kaggle datasets list -s celeba\n","!kaggle datasets download -d jessicali9530/celeba-dataset"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-c70946ad-c4e5-49c7-b5cd-dfcfdab9c515\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c70946ad-c4e5-49c7-b5cd-dfcfdab9c515\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 65 bytes\n","kaggle.json\n","Downloading celeba-dataset.zip to /content\n"," 99% 1.32G/1.33G [00:10<00:00, 173MB/s]\n","100% 1.33G/1.33G [00:10<00:00, 131MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1dv-XHuJHcON"},"source":["# Unzip\n","import zipfile\n","\n","with zipfile.ZipFile('celeba-dataset.zip', 'r') as zip_ref:\n","    zip_ref.extractall('.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mr5xEpRvW30s","executionInfo":{"status":"ok","timestamp":1615806307880,"user_tz":-180,"elapsed":490,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"3c572816-081d-431c-e362-6109bbbb0863"},"source":["image_folder = './img_align_celeba/img_align_celeba'\n","img_name = {}\n","\n","for idx, name in enumerate(os.listdir(image_folder)):\n","    img_name[idx] = name\n","\n","print('length:', len(img_name))\n","print('shape:', Image.open(os.path.join(image_folder, img_name[55])).size)\n","\n","for i in range(5):\n","    print(img_name[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["length: 202599\n","shape: (178, 218)\n","092713.jpg\n","047232.jpg\n","146925.jpg\n","187628.jpg\n","066996.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JOcKQy9iUZpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615806309186,"user_tz":-180,"elapsed":616,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"245513ac-1c0f-49e8-aebb-7b2aedb2c235"},"source":["class MyDataset(Dataset):\n","    def __init__(self, root, transform):\n","        self.root = root\n","        self.transform = transform\n","        \n","        self.img_name = {}\n","        for idx, name in enumerate(os.listdir(self.root)):\n","            self.img_name[idx] = name\n","\n","    def __len__(self):\n","        return len(self.img_name)  # 202 599 images\n","\n","    def __getitem__(self, index):\n","        filepath = os.path.join(self.root, self.img_name[index])\n","        image = Image.open(filepath)\n","        image = self.transform(image)\n","        return image\n","\n","\n","image_folder = './img_align_celeba/img_align_celeba'\n","IMAGE_SIZE = 64\n","\n","transform = transforms.Compose([\n","    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5),\n","                         (0.5, 0.5, 0.5)),\n","])\n","\n","dataset = MyDataset(root=image_folder, transform=transform)\n","print(dataset.__len__())\n","print(dataset.__getitem__(55).shape)\n","# print(dataset.__getitem__(55))\n","\n","\n","def save_checkpoint(state, filename):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    step = checkpoint[\"step\"]\n","    return step"],"execution_count":null,"outputs":[{"output_type":"stream","text":["202599\n","torch.Size([3, 64, 64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kDbPi_TVySCb"},"source":["# Run TensorBoard\n","\n","# Delete previous logs dir\n","logs_dir = 'logs_dir'\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bfdHXn1R5wnq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615808134155,"user_tz":-180,"elapsed":30067,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"c64a54e3-fe16-461f-bcad-5a021a2cab45"},"source":["class Discriminator(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(  # Input: N x 3 x 64 x64\n","            self._block(channels_img, features_d,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            self._block(features_d,   features_d*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1),  # N x 512 x 4 x 4\n","            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=1, padding=0),\n","            # Output: N x 1 x 1 x 1 - False or True image?\n","            nn.Flatten(),\n","            nn.Sigmoid(),  # between (0, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            # bias=False for BatchNorm\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(  # Input: N x z_dim x 1 x 1\n","            self._block(z_dim,        features_g*8, kernel_size=4, stride=1, padding=0),  # N x 512 x 4 x 4\n","            self._block(features_g*8, features_g*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_g*4, features_g*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_g*2, features_g,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=1),\n","            # Output: N x 3 x 64 x 64\n","            nn.Tanh(),  # between (-1, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),  # like in DCGAN paper\n","        )\n","    \n","    def forward(self, x):\n","        return self.gen(x)\n","\n","\n","def init_weights(model):\n","    ''' Initialize weights of the model\n","        with mean of 0.0 and standard deviation of 0.02 '''\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, height, width = 8, 3, 64, 64\n","    z_dim = 100\n","    features_d = features_g = 64\n","    \n","    x = torch.randn((N, in_channels, height, width))\n","    disc = Discriminator(in_channels, features_d)\n","    init_weights(disc)\n","    assert disc(x).shape == (N, 1)\n","    \n","    gen = Generator(z_dim, in_channels, features_g)\n","    init_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, height, width)\n","    \n","    print('Test is OK')\n","\n","test()\n","\n","# Hyperparameters etc.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 2e-4  # could also use two lrs, one for gen and one for disc\n","BATCH_SIZE = 128\n","CHANNELS_IMG = 3\n","NOISE_DIM = 100\n","NUM_EPOCHS = 5\n","FEATURES_DISC = 64\n","FEATURES_GEN = 64\n","\n","loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                    num_workers=multiprocessing.cpu_count(), pin_memory=True)\n","\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","disc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)\n","init_weights(gen)\n","init_weights(disc)\n","\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n","criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n","writer_real = SummaryWriter(os.path.join(logs_dir, \"real\"))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, \"fake\"))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_celeb.pth.tar'\n","disc_checkpoint_name = 'discriminator_celeb.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(disc_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, optim_gen)\n","    step = load_checkpoint(torch.load(disc_checkpoint_name), disc, optim_disc)\n","\n","gen.train()\n","disc.train()\n","\n","for epoch in range(NUM_EPOCHS):\n","    # Target labels not needed! <3 unsupervised\n","    for batch_idx, real in enumerate(loader):\n","        real = real.to(device)\n","        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n","        fake = gen(noise)\n","\n","        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","        disc_real = disc(real)\n","        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n","        disc_fake = disc(fake.detach())\n","        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","        \n","        loss_disc = loss_disc_real + loss_disc_fake\n","        \n","        opt_disc.zero_grad()\n","        loss_disc.backward()\n","        opt_disc.step()\n","\n","        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","        output = disc(fake)\n","        loss_gen = criterion(output, torch.ones_like(output))\n","        \n","        opt_gen.zero_grad()\n","        loss_gen.backward()\n","        opt_gen.step()\n","\n","        # Print losses occasionally and print to tensorboard\n","        if batch_idx % 100 == 0:\n","            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n","                  f\"Batch {batch_idx}/{len(loader)} \"\n","                  f\"Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\")\n","\n","            with torch.no_grad():\n","                fake = gen(fixed_noise)\n","                # take out (up to) 32 examples\n","                img_grid_real = torchvision.utils.make_grid(\n","                    real[:32], normalize=True\n","                )\n","                img_grid_fake = torchvision.utils.make_grid(\n","                    fake[:32], normalize=True\n","                )\n","\n","                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","            step += 1\n","\n","    # Save models\n","    gen_checkpoint = {\n","        'state_dict': gen.state_dict(),\n","        'optimizer': opt_gen.state_dict(),\n","        'step': step,\n","    }\n","    disc_checkpoint = {\n","        'state_dict': disc.state_dict(),\n","        'optimizer': opt_disc.state_dict(),\n","        'step': step,\n","    }\n","    save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","    save_checkpoint(disc_checkpoint, disc_checkpoint_name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test is OK\n","Epoch [1/5] Batch 0/1583 Loss D: 1.3909, loss G: 0.7418\n","Epoch [1/5] Batch 100/1583 Loss D: 0.0347, loss G: 4.1388\n","Epoch [1/5] Batch 200/1583 Loss D: 0.4415, loss G: 2.5115\n","Epoch [1/5] Batch 300/1583 Loss D: 0.4582, loss G: 2.2732\n","Epoch [1/5] Batch 400/1583 Loss D: 0.6630, loss G: 2.1436\n","Epoch [1/5] Batch 500/1583 Loss D: 0.6139, loss G: 2.8500\n","Epoch [1/5] Batch 600/1583 Loss D: 0.8207, loss G: 1.1185\n","Epoch [1/5] Batch 700/1583 Loss D: 0.6927, loss G: 2.4549\n","Epoch [1/5] Batch 800/1583 Loss D: 1.2504, loss G: 1.7137\n","Epoch [1/5] Batch 900/1583 Loss D: 1.3080, loss G: 3.2823\n","Epoch [1/5] Batch 1000/1583 Loss D: 0.9044, loss G: 1.5430\n","Epoch [1/5] Batch 1100/1583 Loss D: 1.6140, loss G: 0.9749\n","Epoch [1/5] Batch 1200/1583 Loss D: 0.8431, loss G: 2.1921\n","Epoch [1/5] Batch 1300/1583 Loss D: 0.8315, loss G: 2.9330\n","Epoch [1/5] Batch 1400/1583 Loss D: 0.8569, loss G: 2.1451\n","Epoch [1/5] Batch 1500/1583 Loss D: 0.8410, loss G: 3.0667\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/5] Batch 0/1583 Loss D: 0.7384, loss G: 2.5105\n","Epoch [2/5] Batch 100/1583 Loss D: 1.5488, loss G: 4.6160\n","Epoch [2/5] Batch 200/1583 Loss D: 0.5686, loss G: 2.7753\n","Epoch [2/5] Batch 300/1583 Loss D: 1.0286, loss G: 3.1768\n","Epoch [2/5] Batch 400/1583 Loss D: 0.5811, loss G: 3.2654\n","Epoch [2/5] Batch 500/1583 Loss D: 0.9419, loss G: 4.0085\n","Epoch [2/5] Batch 600/1583 Loss D: 0.4204, loss G: 3.2522\n","Epoch [2/5] Batch 700/1583 Loss D: 0.9254, loss G: 1.9568\n","Epoch [2/5] Batch 800/1583 Loss D: 0.6963, loss G: 2.9475\n","Epoch [2/5] Batch 900/1583 Loss D: 0.5521, loss G: 1.9972\n","Epoch [2/5] Batch 1000/1583 Loss D: 0.6294, loss G: 3.6211\n","Epoch [2/5] Batch 1100/1583 Loss D: 0.5066, loss G: 2.5406\n","Epoch [2/5] Batch 1200/1583 Loss D: 0.8472, loss G: 4.0932\n","Epoch [2/5] Batch 1300/1583 Loss D: 0.5437, loss G: 3.4605\n","Epoch [2/5] Batch 1400/1583 Loss D: 0.6633, loss G: 1.7217\n","Epoch [2/5] Batch 1500/1583 Loss D: 0.5753, loss G: 2.4254\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/5] Batch 0/1583 Loss D: 0.7496, loss G: 1.5690\n","Epoch [3/5] Batch 100/1583 Loss D: 0.5556, loss G: 2.4168\n","Epoch [3/5] Batch 200/1583 Loss D: 0.9398, loss G: 5.7623\n","Epoch [3/5] Batch 300/1583 Loss D: 1.8830, loss G: 0.9545\n","Epoch [3/5] Batch 400/1583 Loss D: 0.6610, loss G: 1.1231\n","Epoch [3/5] Batch 500/1583 Loss D: 0.5045, loss G: 2.2274\n","Epoch [3/5] Batch 600/1583 Loss D: 0.7356, loss G: 1.5274\n","Epoch [3/5] Batch 700/1583 Loss D: 0.6011, loss G: 2.7917\n","Epoch [3/5] Batch 800/1583 Loss D: 0.6387, loss G: 3.3734\n","Epoch [3/5] Batch 900/1583 Loss D: 0.4531, loss G: 2.7010\n","Epoch [3/5] Batch 1000/1583 Loss D: 0.7651, loss G: 1.5306\n","Epoch [3/5] Batch 1100/1583 Loss D: 0.4238, loss G: 2.6426\n","Epoch [3/5] Batch 1200/1583 Loss D: 0.5294, loss G: 2.7539\n","Epoch [3/5] Batch 1300/1583 Loss D: 1.1090, loss G: 4.2555\n","Epoch [3/5] Batch 1400/1583 Loss D: 0.9163, loss G: 1.1258\n","Epoch [3/5] Batch 1500/1583 Loss D: 0.7483, loss G: 1.4249\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/5] Batch 0/1583 Loss D: 0.5665, loss G: 2.8284\n","Epoch [4/5] Batch 100/1583 Loss D: 0.6238, loss G: 1.7190\n","Epoch [4/5] Batch 200/1583 Loss D: 0.7718, loss G: 2.1286\n","Epoch [4/5] Batch 300/1583 Loss D: 0.6067, loss G: 2.8374\n","Epoch [4/5] Batch 400/1583 Loss D: 0.6678, loss G: 1.6156\n","Epoch [4/5] Batch 500/1583 Loss D: 0.7846, loss G: 2.9831\n","Epoch [4/5] Batch 600/1583 Loss D: 0.7100, loss G: 1.6544\n","Epoch [4/5] Batch 700/1583 Loss D: 0.6183, loss G: 3.1799\n","Epoch [4/5] Batch 800/1583 Loss D: 0.7178, loss G: 1.5031\n","Epoch [4/5] Batch 900/1583 Loss D: 0.6591, loss G: 2.0691\n","Epoch [4/5] Batch 1000/1583 Loss D: 2.2739, loss G: 0.4569\n","Epoch [4/5] Batch 1100/1583 Loss D: 0.5375, loss G: 1.8664\n","Epoch [4/5] Batch 1200/1583 Loss D: 0.8320, loss G: 1.1319\n","Epoch [4/5] Batch 1300/1583 Loss D: 0.8282, loss G: 1.3332\n","Epoch [4/5] Batch 1400/1583 Loss D: 0.9491, loss G: 2.7719\n","Epoch [4/5] Batch 1500/1583 Loss D: 0.7289, loss G: 1.8169\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [5/5] Batch 0/1583 Loss D: 1.0322, loss G: 1.3757\n","Epoch [5/5] Batch 100/1583 Loss D: 0.9789, loss G: 3.2073\n","Epoch [5/5] Batch 200/1583 Loss D: 0.4676, loss G: 2.2591\n","Epoch [5/5] Batch 300/1583 Loss D: 0.5352, loss G: 2.0666\n","Epoch [5/5] Batch 400/1583 Loss D: 0.7273, loss G: 2.1923\n","Epoch [5/5] Batch 500/1583 Loss D: 0.7048, loss G: 1.4980\n","Epoch [5/5] Batch 600/1583 Loss D: 0.6998, loss G: 1.3820\n","Epoch [5/5] Batch 700/1583 Loss D: 0.8407, loss G: 2.7068\n","Epoch [5/5] Batch 800/1583 Loss D: 0.6780, loss G: 1.6843\n","Epoch [5/5] Batch 900/1583 Loss D: 0.6820, loss G: 3.6030\n","Epoch [5/5] Batch 1000/1583 Loss D: 0.6701, loss G: 1.8600\n","Epoch [5/5] Batch 1100/1583 Loss D: 0.5584, loss G: 2.1235\n","Epoch [5/5] Batch 1200/1583 Loss D: 1.6749, loss G: 4.7824\n","Epoch [5/5] Batch 1300/1583 Loss D: 0.8259, loss G: 2.3113\n","Epoch [5/5] Batch 1400/1583 Loss D: 0.5638, loss G: 1.8924\n","Epoch [5/5] Batch 1500/1583 Loss D: 1.5325, loss G: 3.7568\n","=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J5v5jbdBIFcd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615808836528,"user_tz":-180,"elapsed":30762,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"825a24a1-90d0-4866-bfc6-1ab135c0b733"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgLeUrk1tbsZ","executionInfo":{"status":"ok","timestamp":1615809016090,"user_tz":-180,"elapsed":1480,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"d2aecdf0-c241-4bfe-e93d-9d464638939e"},"source":["!ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp generator_celeb.pth.tar '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 184M\n","-rw------- 1 root root   32K Mar  1 12:56 '2021.02.26 basics.ipynb'\n","-rw------- 1 root root   33K Mar  1 12:59 '2021.03.01-1 Pytorch Neural Network example.ipynb'\n","-rw------- 1 root root   33K Mar  5 08:04 '2021.03.01-2 Convolutional Neural Network example.ipynb'\n","-rw------- 1 root root   20K Mar 10 10:20 '2021.03.01-3 Recurrent Neural Network example.ipynb'\n","-rw------- 1 root root   34K Mar  4 22:21 '2021.03.01-4 Bidirectional LSTM example.ipynb'\n","-rw------- 1 root root   11K Mar  5 14:30 '2021.03.02-1 How to save and load models in Pytorch.ipynb'\n","-rw------- 1 root root   16K Mar  2 14:21 '2021.03.02-2 Transfer Learning and Fine Tuning.ipynb'\n","-rw------- 1 root root   49K Mar  5 08:09 '2021.03.02-3 Build custom dataset.ipynb'\n","-rw------- 1 root root  1.5M Mar 10 08:06 '2021.03.03-1 How to build custom Datasets for Text in Pytorch.ipynb'\n","-rw------- 1 root root 1013K Mar  4 17:47 '2021.03.03-2 Data Augmentation using Torchvision.ipynb'\n","-rw------- 1 root root  3.3M Mar  4 17:01 '2021.03.03-3 Albumentations library for data augmentation.ipynb'\n","-rw------- 1 root root  7.4K Mar  4 19:53 '2021.03.04 How to deal with imbalanced datasets.ipynb'\n","-rw------- 1 root root   50M Mar  5 13:27 '2021.03.05-1 Pytorch TensorBoard.ipynb'\n","-rw------- 1 root root   13K Mar  5 14:49 '2021.03.05-2 LeNet implementation.ipynb'\n","-rw------- 1 root root   11K Mar  9 19:55 '2021.03.09-1 VGG implementation.ipynb'\n","-rw------- 1 root root   39K Mar  9 19:59 '2021.03.09-2 GoogLeNet implementation.ipynb'\n","-rw------- 1 root root   13K Mar  9 20:06 '2021.03.09-3 ResNet implementation.ipynb'\n","-rw------- 1 root root   17K Mar  9 20:55 '2021.03.09-4 EfficientNet implementation.ipynb'\n","-rw------- 1 root root   25M Mar 13 10:24 '2021.03.10-1 Image Captioning.ipynb'\n","-rw------- 1 root root   11K Mar 13 10:41 '2021.03.11-1 Neural Style Transfer.ipynb'\n","-rw------- 1 root root   24M Mar 13 12:55 '2021.03.11-2 Simple GAN.ipynb'\n","-rw------- 1 root root   31M Mar 15 11:49  2021.03.15-1_DCGAN_implementation.ipynb\n","-rw------- 1 root root   50M Mar 15 09:21 '2021.03.15-2 WGAN implementation.ipynb'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6t33gPaXto5U"},"source":[""],"execution_count":null,"outputs":[]}]}