{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.15-2 WGAN implementation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QkEk_qlTqJKc"},"source":["# Wasserstein GAN implementation\n","\n","[Original video](https://youtu.be/pG0QZ7OddX4)\n","\n","[Read-through: Wasserstein GAN](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)\n","\n","[Wasserstein GAN paper](https://arxiv.org/abs/1701.07875)\n","\n","[Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) paper"]},{"cell_type":"markdown","metadata":{"id":"BXTZVrN_EtXA"},"source":["## Download and prepare dataset. Import libraries"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":164},"id":"_ReQZUD00QYW","executionInfo":{"status":"ok","timestamp":1615839901239,"user_tz":-180,"elapsed":37742,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"e1f2097a-c231-4b63-bdcb-7f3ccc6b8af0"},"source":["# Get dataset from Kaggle\n","\n","# Colab's file access feature\n","from google.colab import files\n","\n","# Upload `kaggle.json` file\n","uploaded = files.upload()\n","\n","# Retrieve uploaded file and print results\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then copy kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","\n","# Download the dataset\n","# !kaggle datasets list -s celeba\n","!kaggle datasets download -d jessicali9530/celeba-dataset"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-aace2f1d-1c14-4bd3-ae14-7ed428ac4d51\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-aace2f1d-1c14-4bd3-ae14-7ed428ac4d51\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 65 bytes\n","kaggle.json\n","Downloading celeba-dataset.zip to /content\n","100% 1.33G/1.33G [00:18<00:00, 88.8MB/s]\n","100% 1.33G/1.33G [00:18<00:00, 78.6MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gz0x2Bda0Ty2"},"source":["# Unzip\n","import zipfile\n","\n","with zipfile.ZipFile('celeba-dataset.zip', 'r') as zip_ref:\n","    zip_ref.extractall('.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nh0ZGgnwp1Pk"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import multiprocessing\n","\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbNCflKA0nY2"},"source":["class MyDataset(Dataset):\n","    def __init__(self, root, transform):\n","        self.root = root\n","        self.transform = transform\n","        \n","        self.img_name = {}\n","        for idx, name in enumerate(os.listdir(self.root)):\n","            self.img_name[idx] = name\n","\n","    def __len__(self):\n","        return len(self.img_name)  # 202 599 images\n","\n","    def __getitem__(self, index):\n","        filepath = os.path.join(self.root, self.img_name[index])\n","        image = Image.open(filepath)\n","        image = self.transform(image)\n","        return image\n","\n","\n","image_folder = './img_align_celeba/img_align_celeba'\n","IMAGE_SIZE = 64\n","\n","transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),  # resize proportionally to rectangular image\n","    transforms.RandomCrop(IMAGE_SIZE),  # crop rectangular image to square\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5),\n","                         (0.5, 0.5, 0.5)),\n","])\n","\n","dataset = MyDataset(root=image_folder, transform=transform)\n","\n","\n","def save_checkpoint(state, filename):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    step = checkpoint[\"step\"]\n","    return step"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0pKL28RjE3xb"},"source":["## Set and test the model"]},{"cell_type":"code","metadata":{"id":"MHV9OY45sNj2"},"source":["class Critic(nn.Module):\n","    def __init__(self, channels_img, features_d):\n","        super(Critic, self).__init__()\n","        self.critic = nn.Sequential(  # Input: N x 3 x 64 x64\n","            self._block(channels_img, features_d,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            self._block(features_d,   features_d*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_d*2, features_d*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_d*4, features_d*8, kernel_size=4, stride=2, padding=1),  # N x 512 x 4 x 4\n","            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=1, padding=0),  # N x 1 x 1 x 1\n","            nn.Flatten(),  # no nn.Sigmoid() anymore, this is why it is Critic, but not Discriminator\n","        )  # Output: N x 1\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            # bias=False for BatchNorm\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.critic(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, z_dim, channels_img, features_g):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(  # Input: N x z_dim x 1 x 1\n","            self._block(z_dim,        features_g*8, kernel_size=4, stride=1, padding=0),  # N x 512 x 4 x 4\n","            self._block(features_g*8, features_g*4, kernel_size=4, stride=2, padding=1),  # N x 256 x 8 x 8\n","            self._block(features_g*4, features_g*2, kernel_size=4, stride=2, padding=1),  # N x 128 x 16 x 16\n","            self._block(features_g*2, features_g,   kernel_size=4, stride=2, padding=1),  # N x 64 x 32 x 32\n","            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=1),\n","            # Output: N x 3 x 64 x 64\n","            nn.Tanh(),  # between (-1, 1)\n","        )\n","\n","    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n","        return nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),  # like in DCGAN paper\n","        )\n","    \n","    def forward(self, x):\n","        return self.gen(x)\n","\n","\n","def init_weights(model):\n","    ''' Initialize weights of the model\n","        with mean of 0.0 and standard deviation of 0.02 '''\n","    for m in model.modules():\n","        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","            nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def test():\n","    N, in_channels, height, width = 8, 3, 64, 64\n","    z_dim = 100\n","    features_d = features_g = 64\n","    \n","    x = torch.randn((N, in_channels, height, width))\n","    critic = Critic(in_channels, features_d)\n","    init_weights(critic)\n","    assert critic(x).shape == (N, 1)\n","\n","    gen = Generator(z_dim, in_channels, features_g)\n","    init_weights(gen)\n","    z = torch.randn((N, z_dim, 1, 1))\n","    assert gen(z).shape == (N, in_channels, height, width)\n","    \n","    print('Test is OK')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttVq_cb4CtxG","executionInfo":{"status":"ok","timestamp":1615839945795,"user_tz":-180,"elapsed":82262,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"564b234a-f551-4477-9e16-400f79ad3b9d"},"source":["test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test is OK\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H4x94oaz1Htm"},"source":["## Run TensorBoard"]},{"cell_type":"code","metadata":{"id":"D8kXVPw41Kn9"},"source":["# Run TensorBoard\n","\n","# Delete previous logs dir\n","logs_dir = 'logs_dir'\n","if os.path.exists(logs_dir):\n","    !rm -rf $logs_dir\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $logs_dir\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9N2_WWJofS6u"},"source":["## Prepare the model"]},{"cell_type":"code","metadata":{"id":"wabZt_YLEFnJ"},"source":["# Hyperparameters etc.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 5e-5  # could also use two lrs, one for gen and one for critic\n","BATCH_SIZE = 128  # was 64\n","CHANNELS_IMG = 3\n","NOISE_DIM = 128  # was 100\n","NUM_EPOCHS = 5\n","FEATURES_CRITIC = FEATURES_GEN = 64\n","CRITIC_ITERATIONS = 5\n","WEIGHT_CLIP = 0.01\n","\n","loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                    num_workers=multiprocessing.cpu_count(), pin_memory=True)\n","\n","gen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n","critic = Critic(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n","init_weights(gen)\n","init_weights(critic)\n","\n","opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n","opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n","\n","fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n","writer_real = SummaryWriter(os.path.join(logs_dir, \"real\"))\n","writer_fake = SummaryWriter(os.path.join(logs_dir, \"fake\"))\n","step = 0\n","\n","# Load models\n","gen_checkpoint_name = 'generator_celeb.pth.tar'\n","critic_checkpoint_name = 'critic_celeb.pth.tar'\n","\n","if os.path.exists(gen_checkpoint_name) and os.path.exists(critic_checkpoint_name):\n","    step = load_checkpoint(torch.load(gen_checkpoint_name), gen, opt_gen)\n","    step = load_checkpoint(torch.load(critic_checkpoint_name), critic, opt_critic)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IL-OR_myD6p"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"zb2GAj1xhr7r"},"source":["def train(step=step):\n","    gen.train()\n","    critic.train()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        # Target labels not needed! <3 unsupervised\n","        for batch_idx, real in enumerate(loader):\n","            real = real.to(device)\n","\n","            # Train Critic: max (E(critic(real)) - E(critic(fake)))\n","            # or min (-1) * (E(critic(real)) - E(critic(fake)))\n","            for _ in range(CRITIC_ITERATIONS):\n","                noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n","                fake = gen(noise)\n","                critic_real = critic(real)\n","                critic_fake = critic(fake.detach())\n","                loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n","\n","                opt_critic.zero_grad()\n","                loss_critic.backward()\n","                opt_critic.step()\n","\n","                for p in critic.parameters():\n","                    p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n","\n","            # Train Generator: min (E(critic(real)) - E(critic(fake)))\n","            # which is the same as: min (-1) * E(critic(fake))\n","            # because generator can not influence on E(critic(real)).\n","            output = critic(fake)\n","            loss_gen = -torch.mean(output)\n","\n","            opt_gen.zero_grad()\n","            loss_gen.backward()\n","            opt_gen.step()\n","\n","            # Print losses occasionally and print to tensorboard\n","            if batch_idx % 100 == 0:\n","                print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] \"\n","                    f\"Batch {batch_idx}/{len(loader)} \"\n","                    f\"Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\")\n","\n","                with torch.no_grad():\n","                    fake = gen(fixed_noise)\n","                    # take out (up to) 32 examples\n","                    img_grid_real = torchvision.utils.make_grid(\n","                        real[:32], normalize=True\n","                    )\n","                    img_grid_fake = torchvision.utils.make_grid(\n","                        fake[:32], normalize=True\n","                    )\n","\n","                    writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n","                    writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n","\n","                step += 1\n","\n","        # Save models\n","        gen_checkpoint = {\n","            'state_dict': gen.state_dict(),\n","            'optimizer': opt_gen.state_dict(),\n","            'step': step,\n","        }\n","        critic_checkpoint = {\n","            'state_dict': critic.state_dict(),\n","            'optimizer': opt_critic.state_dict(),\n","            'step': step,\n","        }\n","        save_checkpoint(gen_checkpoint, gen_checkpoint_name)\n","        save_checkpoint(critic_checkpoint, critic_checkpoint_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FvBUVqpx86R","executionInfo":{"status":"ok","timestamp":1615845613600,"user_tz":-180,"elapsed":5750020,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"71531286-0f28-4d86-9e71-d207296ecc92"},"source":["train(step=step)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [1/5] Batch 0/1583 Loss D: -0.0536, loss G: 0.0225\n","Epoch [1/5] Batch 100/1583 Loss D: -1.5367, loss G: 0.7315\n","Epoch [1/5] Batch 200/1583 Loss D: -1.5440, loss G: 0.7353\n","Epoch [1/5] Batch 300/1583 Loss D: -1.5323, loss G: 0.7311\n","Epoch [1/5] Batch 400/1583 Loss D: -1.4836, loss G: 0.7097\n","Epoch [1/5] Batch 500/1583 Loss D: -1.5324, loss G: 0.7310\n","Epoch [1/5] Batch 600/1583 Loss D: -1.5417, loss G: 0.7342\n","Epoch [1/5] Batch 700/1583 Loss D: -1.5442, loss G: 0.7356\n","Epoch [1/5] Batch 800/1583 Loss D: -1.5446, loss G: 0.7355\n","Epoch [1/5] Batch 900/1583 Loss D: -1.4284, loss G: 0.7187\n","Epoch [1/5] Batch 1000/1583 Loss D: -1.5462, loss G: 0.7364\n","Epoch [1/5] Batch 1100/1583 Loss D: -1.5414, loss G: 0.7341\n","Epoch [1/5] Batch 1200/1583 Loss D: -1.5472, loss G: 0.7365\n","Epoch [1/5] Batch 1300/1583 Loss D: -1.5482, loss G: 0.7366\n","Epoch [1/5] Batch 1400/1583 Loss D: -1.5456, loss G: 0.7355\n","Epoch [1/5] Batch 1500/1583 Loss D: -1.5451, loss G: 0.7350\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [2/5] Batch 0/1583 Loss D: -1.5452, loss G: 0.7352\n","Epoch [2/5] Batch 100/1583 Loss D: -1.5460, loss G: 0.7359\n","Epoch [2/5] Batch 200/1583 Loss D: -1.5496, loss G: 0.7371\n","Epoch [2/5] Batch 300/1583 Loss D: -1.5408, loss G: 0.7337\n","Epoch [2/5] Batch 400/1583 Loss D: -1.5462, loss G: 0.7360\n","Epoch [2/5] Batch 500/1583 Loss D: -1.5450, loss G: 0.7359\n","Epoch [2/5] Batch 600/1583 Loss D: -1.5497, loss G: 0.7373\n","Epoch [2/5] Batch 700/1583 Loss D: -1.5461, loss G: 0.7342\n","Epoch [2/5] Batch 800/1583 Loss D: -1.5480, loss G: 0.7363\n","Epoch [2/5] Batch 900/1583 Loss D: -1.5483, loss G: 0.7366\n","Epoch [2/5] Batch 1000/1583 Loss D: -1.5490, loss G: 0.7371\n","Epoch [2/5] Batch 1100/1583 Loss D: -1.5489, loss G: 0.7368\n","Epoch [2/5] Batch 1200/1583 Loss D: -1.5495, loss G: 0.7371\n","Epoch [2/5] Batch 1300/1583 Loss D: -1.5493, loss G: 0.7370\n","Epoch [2/5] Batch 1400/1583 Loss D: -1.5217, loss G: 0.7260\n","Epoch [2/5] Batch 1500/1583 Loss D: -1.5468, loss G: 0.7361\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [3/5] Batch 0/1583 Loss D: -1.5470, loss G: 0.7362\n","Epoch [3/5] Batch 100/1583 Loss D: -1.5466, loss G: 0.7362\n","Epoch [3/5] Batch 200/1583 Loss D: -1.5483, loss G: 0.7366\n","Epoch [3/5] Batch 300/1583 Loss D: -1.5416, loss G: 0.7340\n","Epoch [3/5] Batch 400/1583 Loss D: -1.5488, loss G: 0.7376\n","Epoch [3/5] Batch 500/1583 Loss D: -1.5373, loss G: 0.7332\n","Epoch [3/5] Batch 600/1583 Loss D: -1.5441, loss G: 0.7345\n","Epoch [3/5] Batch 700/1583 Loss D: -1.5470, loss G: 0.7366\n","Epoch [3/5] Batch 800/1583 Loss D: -1.5315, loss G: 0.7301\n","Epoch [3/5] Batch 900/1583 Loss D: -1.5348, loss G: 0.7310\n","Epoch [3/5] Batch 1000/1583 Loss D: -1.3888, loss G: 0.7064\n","Epoch [3/5] Batch 1100/1583 Loss D: -1.5447, loss G: 0.7353\n","Epoch [3/5] Batch 1200/1583 Loss D: -1.5438, loss G: 0.7348\n","Epoch [3/5] Batch 1300/1583 Loss D: -1.5424, loss G: 0.7338\n","Epoch [3/5] Batch 1400/1583 Loss D: -1.4332, loss G: 0.6923\n","Epoch [3/5] Batch 1500/1583 Loss D: -1.5199, loss G: 0.7258\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [4/5] Batch 0/1583 Loss D: -1.5377, loss G: 0.7326\n","Epoch [4/5] Batch 100/1583 Loss D: -1.5328, loss G: 0.7295\n","Epoch [4/5] Batch 200/1583 Loss D: -1.5270, loss G: 0.7287\n","Epoch [4/5] Batch 300/1583 Loss D: -1.5330, loss G: 0.7302\n","Epoch [4/5] Batch 400/1583 Loss D: -1.5248, loss G: 0.7275\n","Epoch [4/5] Batch 500/1583 Loss D: -1.5244, loss G: 0.7276\n","Epoch [4/5] Batch 600/1583 Loss D: -0.8359, loss G: 0.6012\n","Epoch [4/5] Batch 700/1583 Loss D: -1.5088, loss G: 0.7214\n","Epoch [4/5] Batch 800/1583 Loss D: -1.5077, loss G: 0.7206\n","Epoch [4/5] Batch 900/1583 Loss D: -1.4939, loss G: 0.7155\n","Epoch [4/5] Batch 1000/1583 Loss D: -1.2052, loss G: 0.6849\n","Epoch [4/5] Batch 1100/1583 Loss D: -1.4635, loss G: 0.6880\n","Epoch [4/5] Batch 1200/1583 Loss D: -1.3846, loss G: 0.6835\n","Epoch [4/5] Batch 1300/1583 Loss D: -1.1565, loss G: 0.3101\n","Epoch [4/5] Batch 1400/1583 Loss D: -1.2524, loss G: 0.6348\n","Epoch [4/5] Batch 1500/1583 Loss D: -1.3699, loss G: 0.6639\n","=> Saving checkpoint\n","=> Saving checkpoint\n","Epoch [5/5] Batch 0/1583 Loss D: -1.3617, loss G: 0.6556\n","Epoch [5/5] Batch 100/1583 Loss D: -1.3289, loss G: 0.6485\n","Epoch [5/5] Batch 200/1583 Loss D: -1.3620, loss G: 0.6654\n","Epoch [5/5] Batch 300/1583 Loss D: -1.3458, loss G: 0.6592\n","Epoch [5/5] Batch 400/1583 Loss D: -1.3676, loss G: 0.6514\n","Epoch [5/5] Batch 500/1583 Loss D: -1.3239, loss G: 0.6446\n","Epoch [5/5] Batch 600/1583 Loss D: -1.2841, loss G: 0.6236\n","Epoch [5/5] Batch 700/1583 Loss D: -1.2702, loss G: 0.6441\n","Epoch [5/5] Batch 800/1583 Loss D: -1.2739, loss G: 0.5998\n","Epoch [5/5] Batch 900/1583 Loss D: -1.2367, loss G: 0.6606\n","Epoch [5/5] Batch 1000/1583 Loss D: -1.2807, loss G: 0.6149\n","Epoch [5/5] Batch 1100/1583 Loss D: -1.2577, loss G: 0.6131\n","Epoch [5/5] Batch 1200/1583 Loss D: -1.2213, loss G: 0.5842\n","Epoch [5/5] Batch 1300/1583 Loss D: -1.2733, loss G: 0.6199\n","Epoch [5/5] Batch 1400/1583 Loss D: -1.2156, loss G: 0.6104\n","Epoch [5/5] Batch 1500/1583 Loss D: -1.2502, loss G: 0.6026\n","=> Saving checkpoint\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sNbDOavm3Qfv"},"source":["## Save models if necessary"]},{"cell_type":"code","metadata":{"id":"J5v5jbdBIFcd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615845645885,"user_tz":-180,"elapsed":5782298,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"44831d7a-66bb-46b8-e50f-143f9595b43d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!ls -hal '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp critic_celeb.pth.tar '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","!cp generator_celeb.pth.tar     '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","total 165M\n","-rw------- 1 root root   32K Mar  1 12:56 '2021.02.26 basics.ipynb'\n","-rw------- 1 root root   33K Mar  1 12:59 '2021.03.01-1 Pytorch Neural Network example.ipynb'\n","-rw------- 1 root root   33K Mar  5 08:04 '2021.03.01-2 Convolutional Neural Network example.ipynb'\n","-rw------- 1 root root   20K Mar 10 10:20 '2021.03.01-3 Recurrent Neural Network example.ipynb'\n","-rw------- 1 root root   34K Mar  4 22:21 '2021.03.01-4 Bidirectional LSTM example.ipynb'\n","-rw------- 1 root root   11K Mar  5 14:30 '2021.03.02-1 How to save and load models in Pytorch.ipynb'\n","-rw------- 1 root root   16K Mar  2 14:21 '2021.03.02-2 Transfer Learning and Fine Tuning.ipynb'\n","-rw------- 1 root root   49K Mar  5 08:09 '2021.03.02-3 Build custom dataset.ipynb'\n","-rw------- 1 root root  1.5M Mar 10 08:06 '2021.03.03-1 How to build custom Datasets for Text in Pytorch.ipynb'\n","-rw------- 1 root root 1013K Mar  4 17:47 '2021.03.03-2 Data Augmentation using Torchvision.ipynb'\n","-rw------- 1 root root  3.3M Mar  4 17:01 '2021.03.03-3 Albumentations library for data augmentation.ipynb'\n","-rw------- 1 root root  7.4K Mar  4 19:53 '2021.03.04 How to deal with imbalanced datasets.ipynb'\n","-rw------- 1 root root   50M Mar  5 13:27 '2021.03.05-1 Pytorch TensorBoard.ipynb'\n","-rw------- 1 root root   13K Mar  5 14:49 '2021.03.05-2 LeNet implementation.ipynb'\n","-rw------- 1 root root   11K Mar  9 19:55 '2021.03.09-1 VGG implementation.ipynb'\n","-rw------- 1 root root   39K Mar  9 19:59 '2021.03.09-2 GoogLeNet implementation.ipynb'\n","-rw------- 1 root root   13K Mar  9 20:06 '2021.03.09-3 ResNet implementation.ipynb'\n","-rw------- 1 root root   17K Mar  9 20:55 '2021.03.09-4 EfficientNet implementation.ipynb'\n","-rw------- 1 root root   25M Mar 13 10:24 '2021.03.10-1 Image Captioning.ipynb'\n","-rw------- 1 root root   11K Mar 13 10:41 '2021.03.11-1 Neural Style Transfer.ipynb'\n","-rw------- 1 root root   24M Mar 13 12:55 '2021.03.11-2 Simple GAN.ipynb'\n","-rw------- 1 root root   31M Mar 15 11:51 '2021.03.15-1 DCGAN implementation.ipynb'\n","-rw------- 1 root root   31M Mar 15 21:57 '2021.03.15-2 WGAN implementation.ipynb'\n","-rw------- 1 root root   24K Mar 15 22:00 '2021.03.15-3 WGAN-GP implementation.ipynb'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blG7TNNCTAez"},"source":[""],"execution_count":null,"outputs":[]}]}