{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.05-1 Pytorch TensorBoard.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCld8sHIPALKrKlhGml2dy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2GQhgRH-3gON"},"source":["# Pytorch TensorBoard\n","\n","[Original video](https://youtu.be/RLqsxWaQdHE)"]},{"cell_type":"code","metadata":{"id":"0ZeICOD63YaO"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G222JB2zNAnB"},"source":["# Create convolutional neural network (CNN)\n","class CNN(nn.Module):\n","    def __init__(self, in_channels=1, num_classes=10, size=28):\n","        super(CNN, self).__init__()\n","        out_channels=16\n","        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8,\n","                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=out_channels,\n","                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n","        self.fc1 = nn.Linear(int(out_channels*(size/4)*(size/4)), num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fc1(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wm4BD9nj98QB"},"source":["# Hyperparameters\n","in_channel = 1\n","num_classes = 10\n","# learning_rate = 1e-4\n","# batch_size = 1024\n","num_epochs = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tE5pa5_scXh","executionInfo":{"status":"ok","timestamp":1614950700987,"user_tz":-180,"elapsed":1290,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"5def9a07-f752-4f2a-8b3c-2d2981ae306e"},"source":["# Check if it runs correctly\n","model = CNN()\n","x = torch.randn(32, 1, 28, 28)\n","\n","# Run model on the input and print the shape\n","print(model(x).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VII6ioBo8cO5"},"source":["# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1mxVg-29v-C"},"source":["# For the error: HTTPError: HTTP Error 403: Forbidden\n","# StackOverflow: https://stackoverflow.com/a/66461122/7550928\n","from six.moves import urllib    \n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)\n","\n","# Load data\n","train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n","\n","test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBhvPk_lCcQE"},"source":["# Check accuracy on training and test to see how good our model\n","def check_accuracy(loader, model, test=True):\n","    if test:\n","        print('Checking accuracy on test data', end='')\n","    else:\n","        print('Checking accuracy on training data', end='')\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device)\n","            y = y.to(device=device)\n","\n","            scores = model(x)  # shape = 64x10\n","            _, predictions = scores.max(dim=1)  # get index of max value\n","            num_correct += (predictions == y).sum()\n","            num_samples += predictions.size(0)\n","\n","    acc = float(num_correct) / float(num_samples) * 100\n","    #print(f'Got {num_correct} / {num_samples} with accuracy {acc:.2f}')\n","\n","    model.train()\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aNgu1H1s2xBP"},"source":["# Train network\n","def train():\n","    # Initialize network\n","    model = CNN().to(device)\n","\n","    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n","    \n","    # TensorBoard writer\n","    writer = SummaryWriter(f'runs/MNIST/MiniBatchSize {batch_size} LR {learning_rate}')\n","\n","    # Loss function and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","\n","    step = 0\n","    model.train()\n","    for epoch in range(num_epochs):\n","        losses = []\n","\n","        for batch_idx, (data, targets) in enumerate(train_loader):\n","            # Get data to Cuda if possible\n","            data = data.to(device=device)\n","            targets = targets.to(device=device)\n","\n","            # Forward\n","            scores = model(data)  # shape 64x10\n","            loss = criterion(scores, targets)\n","            losses.append(loss.item())\n","\n","            # Backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()  # gradient descent or adam step\n","\n","            # Calculate running training accuracy\n","            _, predictions = scores.max(dim=1)\n","            num_correct = (predictions == targets).sum()\n","            train_acc = float(num_correct / float(data.shape[0]))\n","\n","            # Plot things to TensorBoard\n","            img_grid = torchvision.utils.make_grid(data)\n","            writer.add_image('mnist_images', img_grid)\n","            writer.add_histogram('fc1', model.fc1.weight)\n","            writer.add_scalar('Training loss', loss, global_step=step)\n","            writer.add_scalar('Training accuracy', train_acc, global_step=step)\n","            # if batch_idx % 10 == 0:\n","            #     print(batch_idx)\n","            if batch_idx == 230:\n","                features = data.reshape(data.shape[0], -1)\n","                class_labels = [classes[label] for label in predictions]\n","                writer.add_embedding(features,\n","                                     metadata=class_labels,\n","                                     label_img=data,\n","                                     global_step=batch_idx)\n","            step += 1\n","        \n","        mean_loss = sum(losses)/len(losses)\n","        acc = check_accuracy(test_loader, model)\n","        msg = (f'\\rLoss at epoch {epoch} is {mean_loss:.5f}. '\n","               f'bs {batch_size} lr {learning_rate} '\n","               f'Accuracy is {acc:.2f}')\n","        print(msg)\n","\n","        writer.add_hparams(\n","                {\"lr\": learning_rate, \"bsize\": batch_size},\n","                {\n","                    \"accuracy\": acc,\n","                    \"loss\": sum(losses) / len(losses),\n","                },\n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNUAaAVhzcBy"},"source":["[TensorBoard in notebooks](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb#scrollTo=IlDz2oXBgnZ9)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOOTo_DUy7-z","executionInfo":{"status":"ok","timestamp":1614950700994,"user_tz":-180,"elapsed":1264,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"3808e464-5487-4537-b7f5-d224602582bb"},"source":["# Remove previous runs if necessary\n","if os.path.exists('runs'):\n","    !rm -rf runs\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thO2iZ3PKI18"},"source":["# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir runs\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAZYLdCte6zc"},"source":["# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EuzV_GYBhpE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614950726667,"user_tz":-180,"elapsed":26877,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"3fb1c4db-4855-486e-c9fe-d97211778d23"},"source":["# Check various hyperparameters\n","# batch_sizes = [4, 64, 1024]\n","batch_sizes = [256]\n","# learning_rates = [0.1, 0.01, 0.001, 0.0001]\n","learning_rates = [0.001]\n","classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","\n","for batch_size in batch_sizes:\n","    for learning_rate in learning_rates:\n","        train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss at epoch 0 is 0.69204. bs 256 lr 0.001 Accuracy is 93.39\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bWnNiHdTywlb"},"source":[""],"execution_count":null,"outputs":[]}]}