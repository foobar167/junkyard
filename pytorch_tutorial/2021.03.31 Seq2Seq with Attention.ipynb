{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021.03.31 Seq2Seq with Attention.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMogfMdDeapVT28qBfoeTvP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3338fd028d924ca98db3ea7de29f575c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a3415114b73447297d98233b2c3583e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ff1202b9a2045f0a887c75edcd0b357","IPY_MODEL_050678498da7496cb68f5622b64d71a1"]}},"4a3415114b73447297d98233b2c3583e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ff1202b9a2045f0a887c75edcd0b357":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6758a08774c24a88bfb061667804f029","_dom_classes":[],"description":"Epoch [1/5]: 100%","_model_name":"FloatProgressModel","bar_style":"","max":454,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f93b5997e6846209648253deedf7874"}},"050678498da7496cb68f5622b64d71a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f97e41ab1b014cd49c4c1cc541a0308a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454/454 [00:46&lt;00:00,  9.01it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6d7b6f923704469b3422cec22100369"}},"6758a08774c24a88bfb061667804f029":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6f93b5997e6846209648253deedf7874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f97e41ab1b014cd49c4c1cc541a0308a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f6d7b6f923704469b3422cec22100369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8290308d011446ca82f391b179c39782":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b43cba7c6287465c84bd59867d697fef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a01645f02c5b443989a1c9e01bc0894c","IPY_MODEL_122b859ba9a3478da97ffea45f1528e7"]}},"b43cba7c6287465c84bd59867d697fef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a01645f02c5b443989a1c9e01bc0894c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_964bf897fadc43aca0bf47fc8c960a99","_dom_classes":[],"description":"Epoch [2/5]: 100%","_model_name":"FloatProgressModel","bar_style":"","max":454,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c7fe9c5e08241b3a6b11dbdd0e6b8f2"}},"122b859ba9a3478da97ffea45f1528e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_649d88763f094ed3ab0792f2252f18c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454/454 [00:46&lt;00:00,  8.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bec561cd14404fe39c95a9d62de5f193"}},"964bf897fadc43aca0bf47fc8c960a99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5c7fe9c5e08241b3a6b11dbdd0e6b8f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"649d88763f094ed3ab0792f2252f18c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bec561cd14404fe39c95a9d62de5f193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f52a66fffb34628b73a679e86e600ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a3459ceff8d64ffbbd17593de5779f00","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5dbe36deafd549589ccf532cd4af4318","IPY_MODEL_8f234372ec2c4807ac0db5229156eb3c"]}},"a3459ceff8d64ffbbd17593de5779f00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5dbe36deafd549589ccf532cd4af4318":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b0974953c7dd4a759be573b73dcdb5d7","_dom_classes":[],"description":"Epoch [3/5]: 100%","_model_name":"FloatProgressModel","bar_style":"","max":454,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35d79ba8d2b6483e9b172e3843549228"}},"8f234372ec2c4807ac0db5229156eb3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_07a12117b8bb4448a3f7e85d18d70ade","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454/454 [00:45&lt;00:00,  8.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3313436d788948dc906f8fff9c3c7bd8"}},"b0974953c7dd4a759be573b73dcdb5d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"35d79ba8d2b6483e9b172e3843549228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07a12117b8bb4448a3f7e85d18d70ade":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3313436d788948dc906f8fff9c3c7bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d667ad28afb3477ea50e84285e4e1650":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0afb17a751254fa3ac4c0e3c1dd90152","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8d24a726784e4264aa93e83f3eda95e1","IPY_MODEL_d7b0ac35f8ca48c593acfe984e7ee4f7"]}},"0afb17a751254fa3ac4c0e3c1dd90152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d24a726784e4264aa93e83f3eda95e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76dffb131c0e4ccb9fe3be63579ec7e3","_dom_classes":[],"description":"Epoch [4/5]: 100%","_model_name":"FloatProgressModel","bar_style":"","max":454,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d5fe52319564b8c940ec4d410971a6e"}},"d7b0ac35f8ca48c593acfe984e7ee4f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e69b77bd2c34dff9fc341f39691e0d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454/454 [00:46&lt;00:00,  9.25it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cf653eb06b04abba47ca2c96bce4981"}},"76dffb131c0e4ccb9fe3be63579ec7e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1d5fe52319564b8c940ec4d410971a6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e69b77bd2c34dff9fc341f39691e0d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8cf653eb06b04abba47ca2c96bce4981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13e37cb5b672448c9434a948822f8a78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7c8994538ba84cd08b09e0f37ea46f59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_22f311f7d479438391df762ed1af5ca0","IPY_MODEL_b7a8035f6f2c479684b0e0e880138c5d"]}},"7c8994538ba84cd08b09e0f37ea46f59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22f311f7d479438391df762ed1af5ca0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b69dcfc69e9d4b9f9512c9cc1efc249c","_dom_classes":[],"description":"Epoch [5/5]: 100%","_model_name":"FloatProgressModel","bar_style":"","max":454,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":454,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c961d672cbf45a4b88f228f42915850"}},"b7a8035f6f2c479684b0e0e880138c5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91fb7bdee0f247de97b38b4a60ffc0e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 454/454 [00:46&lt;00:00, 10.15it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c49af6a58b44a66afcee91336cfeea7"}},"b69dcfc69e9d4b9f9512c9cc1efc249c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5c961d672cbf45a4b88f228f42915850":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91fb7bdee0f247de97b38b4a60ffc0e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c49af6a58b44a66afcee91336cfeea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"k0ylJHEm7Tuj"},"source":["# Seq2Seq with Attention\n","\n","[Original video](https://youtu.be/sQUqQddQtB4)\n","\n","Resources:\n","  * [C5W3L07 Attention Model Intuition](https://youtu.be/SysgYptB198)\n","  * [C5W3L08 Attention Model](https://youtu.be/quoGRI-1l0A)\n","  * [Ben Trevett GitHub](https://github.com/bentrevett/pytorch-seq2seq) + [Seq2Seq CoLab](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)\n","  * Paper [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n","  * Paper [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n","  * [NLP From Scratch: Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n","\n","[Multi30k dataset](https://github.com/multi30k/dataset). This is a dataset with ~30,000 parallel English, German and French sentences, each with ~12 words per sentence."]},{"cell_type":"markdown","metadata":{"id":"tqB4vB13eOHA"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"wm1Qockn7CpJ"},"source":["import os\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import spacy\n","import random\n","import numpy as np\n","\n","from tqdm.notebook import tqdm\n","from torchtext.data.metrics import bleu_score\n","from torchtext.legacy.datasets import Multi30k\n","from torchtext.legacy.data import Field, BucketIterator\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2L77Oge0LSZO","executionInfo":{"status":"ok","timestamp":1617190132522,"user_tz":-180,"elapsed":4233,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"2529e611-01b5-49c6-b08c-24a0873e53c6"},"source":["!python -m spacy download de"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.2.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xqxrRXNvGyC4"},"source":["spacy_de = spacy.load('de')\n","spacy_en = spacy.load('en')\n","\n","\n","def tokenizer_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","\n","def tokenizer_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","\n","german = Field(tokenize=tokenizer_de, lower=True,\n","               init_token='<sos>', eos_token='<eos>')\n","english = Field(tokenize=tokenizer_en, lower=True,\n","                init_token='<sos>', eos_token='<eos>')\n","\n","train_data, valid_data, test_data = Multi30k.splits(\n","    exts=('.de', '.en'), fields=(german, english))\n","\n","german.build_vocab(train_data, max_size=10000, min_freq=2)\n","english.build_vocab(train_data, max_size=10000, min_freq=2)\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=p)\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers,\n","                           bidirectional=True)\n","        self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n","        self.fc_cell = nn.Linear(hidden_size*2, hidden_size)\n","    \n","    def forward(self, x):  # x shape is (seq_length, N)\n","        embedding = self.dropout(self.embedding(x))\n","        # embedding shape is (seq_length, N, embedding_size)\n","        encoder_states, (hidden, cell) = self.rnn(embedding)\n","\n","        # hidden shape is (2, N, hidden_size)\n","        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n","        # output is (1, N, hidden_size*2)\n","\n","        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n","\n","        return encoder_states, hidden, cell\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, output_size,\n","                 num_layers, p):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=p)\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.rnn = nn.LSTM(hidden_size*2 + embedding_size, hidden_size,\n","                           num_layers)\n","        \n","        # 2 hidden from encoder states + 1 hidden from previous step of decoder\n","        self.energy = nn.Linear(hidden_size*3, 1)\n","        self.softmax = nn.Softmax(dim=0)\n","        self.relu = nn.ReLU()\n","        \n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, encoder_states, hidden, cell):\n","        x = x.unsqueeze(0)  # x shape is (N), but we want (1, N)\n","        embedding = self.dropout(self.embedding(x))  # (1, N, embedding_size)\n","        \n","        # compute energy states, attention and context vector\n","        sequence_length = encoder_states.shape[0]\n","        h_reshaped = hidden.repeat(sequence_length, 1, 1)\n","        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n","        \n","        attention = self.softmax(energy)  # (seq_length, N, 1)\n","\n","        # attention: (seq_length, N, 1), snk\n","        # encoder_states: (seq_length, N, hidden_size*2), snl\n","        # we want context_vector: (1, N, hidden_size*2), i.e knl\n","        context_vector = torch.einsum('snk,snl->knl', attention, encoder_states)\n","\n","        # (1, N, hidden_size*2 + embedding_size)\n","        rnn_input = torch.cat((context_vector, embedding), dim=2)\n","\n","        # outputs shape is (1, N, hidden_size)\n","        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n","        # (1, N, hidden_size) --> (N, hidden_size)\n","        predictions = self.fc(outputs).squeeze(0)\n","        return predictions, hidden, cell\n","\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        \n","    def forward(self, source, target, teacher_force_ratio=0.5):\n","        target_len = target.shape[0]\n","        batch_size = source.shape[1]\n","        target_vocab_size = len(english.vocab)\n","\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","        encoder_states, hidden, cell = self.encoder(source)\n","\n","        x = target[0]  # start token\n","        for t in range(1, target_len):\n","            output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n","            outputs[t] = output\n","            best_guess = output.argmax(axis=1)  # (N, target_vocab_size)\n","            x = target[t] if random.random() < teacher_force_ratio else best_guess\n","\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_QO2sESkH4p"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"FmVKRezdkJoj"},"source":["def translate_sentence(model, sentence, german, english, device, max_length=50):\n","    # load german tokenizer\n","    spacy_ger = spacy.load('de')\n","\n","    # create tokens using spacy and everything in lower case\n","    if type(sentence) == str:\n","        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","\n","    # add <sos> and <eos> in beginning and end respectively\n","    tokens.insert(0, german.init_token)\n","    tokens.append(german.eos_token)\n","\n","    # go through each german token and convert to an index\n","    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n","\n","    # convert to tensor\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    # build encoder hidden, cell state\n","    with torch.no_grad():\n","        outputs_encoder, hiddens, cells = model.encoder(sentence_tensor)\n","\n","    outputs = [english.vocab.stoi['<sos>']]\n","\n","    for _ in range(max_length):\n","        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hiddens, cells = model.decoder(\n","                previous_word, outputs_encoder, hiddens, cells)\n","            best_guess = output.argmax(1).item()\n","\n","        outputs.append(best_guess)\n","\n","        # Model predicts it's the end of the sentence\n","        if output.argmax(1).item() == english.vocab.stoi['<eos>']:\n","            break\n","\n","    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n","\n","    # remove start token\n","    return translated_sentence[1:]\n","\n","\n","def bleu(data, model, german, english, device):\n","    targets = []\n","    outputs = []\n","\n","    for example in data:\n","        src = vars(example)['src']\n","        trg = vars(example)['trg']\n","\n","        prediction = translate_sentence(model, src, german, english, device)\n","        prediction = prediction[:-1]  # remove <eos> token\n","\n","        targets.append([trg])\n","        outputs.append(prediction)\n","\n","    return bleu_score(outputs, targets)\n","\n","\n","def save_checkpoint(model, optimizer, filename):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {'state_dict': model.state_dict(),\n","                  'optimizer': optimizer.state_dict(),}\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(filename, model, optimizer, lr, device):\n","    print('=> Loading checkpoint')\n","    checkpoint = torch.load(filename, map_location=device)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","    # if we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BwSOs4ydeTyh"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"hc-xMqQsKoKA"},"source":["# Run TensorBoard\n","\n","LOG_DIR = 'runs/loss_plot'\n","# Delete previous logs dir\n","if os.path.exists(LOG_DIR):\n","    !rm -rf $LOG_DIR\n","\n","# To fix the error, because PyTorch and TensorFlow are installed both:\n","# AttributeError: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'\n","import tensorflow as tf\n","import tensorboard as tb\n","tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# Start TensorBoard before training to monitor it in progress\n","%tensorboard --logdir $LOG_DIR\n","\n","# Reload TensorBoard\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOyYH2rBeMyo","colab":{"base_uri":"https://localhost:8080/","height":204,"referenced_widgets":["3338fd028d924ca98db3ea7de29f575c","4a3415114b73447297d98233b2c3583e","7ff1202b9a2045f0a887c75edcd0b357","050678498da7496cb68f5622b64d71a1","6758a08774c24a88bfb061667804f029","6f93b5997e6846209648253deedf7874","f97e41ab1b014cd49c4c1cc541a0308a","f6d7b6f923704469b3422cec22100369","8290308d011446ca82f391b179c39782","b43cba7c6287465c84bd59867d697fef","a01645f02c5b443989a1c9e01bc0894c","122b859ba9a3478da97ffea45f1528e7","964bf897fadc43aca0bf47fc8c960a99","5c7fe9c5e08241b3a6b11dbdd0e6b8f2","649d88763f094ed3ab0792f2252f18c5","bec561cd14404fe39c95a9d62de5f193","6f52a66fffb34628b73a679e86e600ba","a3459ceff8d64ffbbd17593de5779f00","5dbe36deafd549589ccf532cd4af4318","8f234372ec2c4807ac0db5229156eb3c","b0974953c7dd4a759be573b73dcdb5d7","35d79ba8d2b6483e9b172e3843549228","07a12117b8bb4448a3f7e85d18d70ade","3313436d788948dc906f8fff9c3c7bd8","d667ad28afb3477ea50e84285e4e1650","0afb17a751254fa3ac4c0e3c1dd90152","8d24a726784e4264aa93e83f3eda95e1","d7b0ac35f8ca48c593acfe984e7ee4f7","76dffb131c0e4ccb9fe3be63579ec7e3","1d5fe52319564b8c940ec4d410971a6e","7e69b77bd2c34dff9fc341f39691e0d8","8cf653eb06b04abba47ca2c96bce4981","13e37cb5b672448c9434a948822f8a78","7c8994538ba84cd08b09e0f37ea46f59","22f311f7d479438391df762ed1af5ca0","b7a8035f6f2c479684b0e0e880138c5d","b69dcfc69e9d4b9f9512c9cc1efc249c","5c961d672cbf45a4b88f228f42915850","91fb7bdee0f247de97b38b4a60ffc0e8","7c49af6a58b44a66afcee91336cfeea7"]},"executionInfo":{"status":"ok","timestamp":1617195583379,"user_tz":-180,"elapsed":239569,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"7eb67ec6-f469-4fa0-ea4e-59b490753a3b"},"source":["# training hyperparameters\n","num_epochs = 20  # 20\n","learning_rate = 0.001\n","batch_size = 64\n","\n","# model hyperparameters\n","load_model = True\n","checkpoint = 'seq2seq_attention.pth.tar'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","input_size_encoder = len(german.vocab)\n","input_size_decoder = len(english.vocab)\n","output_size = len(english.vocab)\n","encoder_embedding_size = 100\n","decoder_embedding_size = 100\n","hidden_size = 1024\n","num_layers = 1\n","enc_dropout = 0.5\n","dec_dropout = 0.5\n","\n","# TensorBoard\n","writer = SummaryWriter(LOG_DIR)\n","step = 0\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), batch_size=batch_size,\n","    # sort by length to minimize the number of padding\n","    sort_within_batch=True, sort_key=lambda x: len(x.src),\n","    device=device,)\n","\n","encoder_net = Encoder(input_size_encoder, encoder_embedding_size, hidden_size,\n","                      num_layers, enc_dropout).to(device)\n","\n","decoder_net = Decoder(input_size_decoder, decoder_embedding_size, hidden_size,\n","                      output_size, num_layers, dec_dropout).to(device)\n","\n","model = Seq2Seq(encoder_net, decoder_net).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","pad_idx = english.vocab.stoi['<pad>']\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","\n","if load_model and os.path.exists(checkpoint):\n","    load_checkpoint(checkpoint, model, optimizer, learning_rate, device)\n","\n","sentence = 'ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.'\n","\n","for epoch in range(1, num_epochs+1):\n","    loop = tqdm(train_iterator, leave=False)\n","    loop.set_description(f'Epoch [{epoch}/{num_epochs}]')\n","\n","    model.eval()\n","    translated_sentence = translate_sentence(model, sentence, german, english,\n","                                             device, max_length=50)\n","    print(translated_sentence)\n","    model.train()\n","\n","    for batch_idx, batch in enumerate(loop):\n","        input_data = batch.src.to(device)\n","        target = batch.trg.to(device)\n","\n","        output = model(input_data, target)  # (target_len, batch_size, output_dim)\n","        output = output[1:].reshape(-1, output.shape[2])\n","        target = target[1:].reshape(-1)  # (target_len * batch_size)\n","\n","        loss = criterion(output, target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # Clip to avoid exploding gradient issues, makes sure grads are\n","        # within a healthy range\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","        optimizer.step()\n","\n","        writer.add_scalar('Training loss', loss, global_step=step)\n","        step += 1\n","\n","    save_checkpoint(model, optimizer, checkpoint)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["=> Loading checkpoint\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3338fd028d924ca98db3ea7de29f575c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["['a', 'boat', 'carrying', 'several', 'men', 'is', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n","=> Saving checkpoint\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8290308d011446ca82f391b179c39782","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["['a', 'boat', 'carrying', 'several', 'men', 'being', 'pulled', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', '.', '<eos>']\n","=> Saving checkpoint\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f52a66fffb34628b73a679e86e600ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["['an', 'boat', 'carrying', 'several', 'men', 'being', 'pulled', 'to', 'shore', 'of', 'a', 'large', 'pile', 'of', 'horses', 'horses', '.', '<eos>']\n","=> Saving checkpoint\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d667ad28afb3477ea50e84285e4e1650","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["['a', 'boat', 'carrying', 'several', 'men', 'is', 'stopped', 'to', 'shore', 'by', 'a', 'large', 'team', 'of', 'horses', 'horses', '.', '<eos>']\n","=> Saving checkpoint\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13e37cb5b672448c9434a948822f8a78","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["['an', 'boat', 'carrying', 'several', 'men', 'is', 'being', 'lowered', 'by', 'a', 'large', 'team', 'of', 'horses', 'horses', '.', '<eos>']\n","=> Saving checkpoint\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjcmBP8pL01w","executionInfo":{"status":"ok","timestamp":1617195584994,"user_tz":-180,"elapsed":240837,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"32f889c4-f74d-44f3-d5a0-1e39d766f2d0"},"source":["# Example:\n","# 'a researcher once learned how to translate sentences'\n","sentence = 'Der junge Mann sagte, der Film sei nicht zu schrecklich'\n","\n","model.eval()\n","translated_sentence = translate_sentence(model, sentence, german, english,\n","                                         device, max_length=50)\n","model.train()\n","\n","print(translated_sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['the', 'young', 'man', 'punching', 'to', 'dressed', 'at', 'the', 'little', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdIyzIH1Ym00","executionInfo":{"status":"ok","timestamp":1617197057642,"user_tz":-180,"elapsed":1713192,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"8b24ea9a-45e8-4ae4-9b02-47e22fd8737e"},"source":["# old Bleu score: 20.85\n","# new Bleu score: 20.62\n","score = bleu(test_data, model, german, english, device)\n","print(f'Bleu score: {score*100:.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Bleu score: 20.62\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fOE8ONqbuZm","executionInfo":{"status":"ok","timestamp":1617197059149,"user_tz":-180,"elapsed":1714426,"user":{"displayName":"Max Planck","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBGeFwU-LUM8Wyn9zmAOd8U2BBj-wFfVDmw-TU=s64","userId":"06869868537886587167"}},"outputId":"650af85c-0fee-4ab0-e046-0b3ab68431ad"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","copy_to = '/content/gdrive/MyDrive/Colab Notebooks/PyTorch tutorial'\n","\n","!cp -rf '$checkpoint' '$copy_to'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fw_Khp1pxoD2"},"source":[""],"execution_count":null,"outputs":[]}]}