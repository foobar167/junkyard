{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to Build an AI Agent from Scratch in Raw Python\n",
        "\n",
        "Self-link: https://colab.research.google.com/drive/1g31aYu3ylEurdQjAJtnSxGFcx9aSZa_D\n",
        "\n",
        "Tutorial by Shrinivasan Sankar: https://www.ai-bites.net/lets-build-an-ai-agent-from-scratch-in-raw-python/?ref=ai-bites-newsletter\n",
        "\n",
        "GitHub scource code: https://github.com/ai-bites/langgraph-crash-course/blob/main/0_simple_python_agent.ipynb?ref=ai-bites.net\n",
        "\n",
        "Video: https://youtu.be/_TzW6F1NVsc"
      ],
      "metadata": {
        "id": "iIaNC_RO_NYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary libraries"
      ],
      "metadata": {
        "id": "o-uFbIr_R3uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai httpx dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW3-zNndgBY2",
        "outputId": "221d35a2-a5d8-4c00-f1b0-9c72bbef8112"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary packages"
      ],
      "metadata": {
        "id": "d-mEIl4bZSBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OwUnMhTc-WEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92015fd6-0d35-45f9-e085-7359b781b504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Python version: 3.11.13\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import re\n",
        "import httpx\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "# Print the full version information string.\n",
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "# Show the Python version.\n",
        "import platform\n",
        "print(f\"Python version: {platform.python_version()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"  # Chat-GPT model name\n",
        "\n",
        "# Set your OPENAI_API_KEY in a \"my_openai_key.env\" file and load it.\n",
        "load_dotenv(\"my_openai_key_2.env\")  # OPENAI_API_KEY\n",
        "# !echo $OPENAI_API_KEY\n",
        "\n",
        "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'],)\n",
        "\n",
        "# Check to see if the LLM works.\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello there!\"}],\n",
        ")\n",
        "\n",
        "# The anser should be: \"Hello! How can I assist you today?\"\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "wwhnWgzKCXxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817251b9-776f-4e12-bf9f-2628dca0c794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot\n",
        "Create a chatbot that takes raw messages, stacks them together, and uses the LLM to respond to the messages."
      ],
      "metadata": {
        "id": "y37HgspAwETP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "    def __init__(self, system=\"\"):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "        if self.system:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
        "\n",
        "\n",
        "    def __call__(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        result = self.run_llm()\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
        "        return result\n",
        "\n",
        "\n",
        "    def run_llm(self):\n",
        "        completion = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            temperature=0,\n",
        "            messages=self.messages,\n",
        "        )\n",
        "        return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "30bvGkKpcIgJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent\n",
        "Wrap the above chatbot in Agent class to create ReAct Agent."
      ],
      "metadata": {
        "id": "sOWyHh07w58Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# abot = Agent(prompt)\n",
        "action_re = re.compile('^Action: (\\w+): (.*)$')\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, system_prompt=\"\", max_turns=1, known_actions=None):\n",
        "        self.max_turns = max_turns\n",
        "        self.bot = ChatBot(system_prompt)\n",
        "        self.known_actions = known_actions\n",
        "\n",
        "\n",
        "    def run(self, question):\n",
        "        i = 0  # iteration\n",
        "        next_prompt = question\n",
        "\n",
        "        while i < self.max_turns:  # loop through iterations\n",
        "            i += 1\n",
        "            result = self.bot(next_prompt)\n",
        "            print(f\"\\n Iteration: {i} \\n\\n\"\n",
        "                  f\"{result}\\n\\n\")\n",
        "            actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
        "\n",
        "            if actions:  # there is an action to run\n",
        "                action, action_input = actions[0].groups()\n",
        "                if action not in self.known_actions:\n",
        "                    raise Exception(f\"Unknown action: {action}: {action_input}\")\n",
        "                print(f\" -- running {action} {action_input} --\")\n",
        "\n",
        "                # Make a request to Wikipedia, ArXiv or calculator using action functions.\n",
        "                # print(self.known_actions)\n",
        "                observation = self.known_actions[action](action_input)\n",
        "\n",
        "                next_prompt = f\"Observation: {observation}\"\n",
        "                print(\"Next prompt:\", next_prompt)\n",
        "            else:\n",
        "                return"
      ],
      "metadata": {
        "id": "RrUecbQWrNFY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actions\n",
        "Define actions as functions.\n",
        "\n",
        "The arxiv_search function will invoke arxiv API to fetch data for the agent.\n",
        "\n",
        "The Wikipedia function will use httpx to query Wikipedia and fetch knowledge about any topic unknown to the agent.\n",
        "\n",
        "The calculate function is a Python hack to evaluate any equations\n",
        "given to it."
      ],
      "metadata": {
        "id": "WDJ3TMvJyT4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wikipedia(q):\n",
        "    try:\n",
        "        return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
        "            \"action\": \"query\",\n",
        "            \"list\": \"search\",\n",
        "            \"srsearch\": q,\n",
        "            \"format\": \"json\"\n",
        "        }).json()[\"query\"][\"search\"][0][\"snippet\"]\n",
        "\n",
        "    except IndexError:  # try Russian instead\n",
        "        return httpx.get(\"https://ru.wikipedia.org/w/api.php\", params={\n",
        "            \"action\": \"query\",\n",
        "            \"list\": \"search\",\n",
        "            \"srsearch\": q,\n",
        "            \"format\": \"json\"\n",
        "        }).json()[\"query\"][\"search\"][0][\"snippet\"]\n",
        "\n",
        "\n",
        "def arxiv_search(q):\n",
        "    ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
        "\n",
        "    # url = f'http://export.arxiv.org/api/query?search_query=all:{q}&start=0&max_results=1'\n",
        "    url = f'http://export.arxiv.org/api/query?search_query=all:{q}&start=0&max_results=3'\n",
        "    res = requests.get(url)\n",
        "    et_root = ET.fromstring(res.content)\n",
        "\n",
        "    for entry in et_root.findall(f\"{ARXIV_NAMESPACE}entry\"):\n",
        "        title = entry.find(f\"{ARXIV_NAMESPACE}title\").text.strip()\n",
        "        summary = entry.find(f\"{ARXIV_NAMESPACE}summary\").text.strip()\n",
        "    return json.dumps({\"title\" : title, \"summary\" : summary})\n",
        "\n",
        "\n",
        "def calculate(what):\n",
        "    return eval(what)"
      ],
      "metadata": {
        "id": "FNKUHXkarYDr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt\n",
        "Prompting is quite crucial for ReAct agents. They generally work by few-shot prompting. Meaning, we need to provide a few examples of what is expected of the agent in the prompt itself. For this reason, we need to write a detailed prompt with a few examples. Below is the prompt for the task.\n",
        "\n",
        "Nothing fancy here other than pro-level prompting. We have listed all the actions, explicitly mentioned, “run in a loop of Thought, Action, PAUSE, Observation” so that the agent can invoke actions and think of the perceived observations."
      ],
      "metadata": {
        "id": "J-H5M5eAzBxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "wikipedia:\n",
        "e.g. wikipedia:\n",
        "Returns a summary from searching Wikipedia\n",
        "\n",
        "arxiv_search:\n",
        "e.g. arxiv_search:\n",
        "Returns a summary of research papers\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: What is the capital of France?\n",
        "Thought: I should look up France on Wikipedia\n",
        "Action: wikipedia: France\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "Observation: France is a country. The capital is Paris.\n",
        "\n",
        "You then output:\n",
        "\n",
        "Answer: The capital of France is Paris\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "lb0hIIFLy4nU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Agent\n",
        "It's time to test out our ReAct agent. Let's collate all the actions in a dictionary, create an instance of the agent, and invoke its run method to run the agent."
      ],
      "metadata": {
        "id": "rLatnn0CzouZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "known_actions = {\n",
        "    \"wikipedia\": wikipedia,\n",
        "    \"calculate\": calculate,\n",
        "    \"arxiv_search\": arxiv_search\n",
        "}\n",
        "agent = Agent(prompt, max_turns=3, known_actions=known_actions)\n",
        "\n",
        "\n",
        "def run_tests(question):\n",
        "    bot = ChatBot(question)  # run chatbot without agent\n",
        "    print(bot.run_llm())\n",
        "    print(f\"\\n----------\")\n",
        "    agent.run(question)  # run agent"
      ],
      "metadata": {
        "id": "yBxQn310zdh2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1st Question -- Easy"
      ],
      "metadata": {
        "id": "9Dff2bZEDl4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of Indonesia?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBPIib_GCJD4",
        "outputId": "1dd48b12-a410-436f-cf5b-d06b80deea31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Indonesia is Jakarta.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should look up Indonesia on Wikipedia to find out its capital.  \n",
            "Action: wikipedia: Indonesia  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running wikipedia Indonesia   --\n",
            "Next prompt: Observation: <span class=\"searchmatch\">Indonesia</span>, officially the Republic of <span class=\"searchmatch\">Indonesia</span>, is a country in Southeast Asia and Oceania, between the Indian and Pacific oceans. Comprising over 17\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: The capital of Indonesia is Jakarta.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2nd Question -- Easy"
      ],
      "metadata": {
        "id": "lOrGQ_pBDsdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what is the sum of 7 and 5?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iEEHXIoDD4s",
        "outputId": "c38f4c63-e4d5-43f4-8024-98352f9badce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of 7 and 5 is 12.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I can calculate the sum of 7 and 5 directly.  \n",
            "Action: calculate: 7 + 5  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running calculate 7 + 5   --\n",
            "Next prompt: Observation: 12\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: The sum of 7 and 5 is 12.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3rd Question -- Difficult"
      ],
      "metadata": {
        "id": "fYY-dg4QD34Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"explain the lightrag paper\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWYR53unDPvz",
        "outputId": "ea640c4c-fd91-4572-9b98-5aae5551811c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LightRAG paper presents a novel approach to enhancing the performance of retrieval-augmented generation (RAG) models, which combine retrieval mechanisms with generative models for tasks such as question answering and information retrieval. The key innovation in LightRAG is the introduction of a lightweight and efficient method for integrating retrieved documents into the generative process, aiming to improve both the quality of generated responses and the efficiency of the model.\n",
            "\n",
            "### Key Components of LightRAG:\n",
            "\n",
            "1. **Retrieval-Augmented Generation (RAG)**: RAG models typically retrieve relevant documents from a large corpus and use them to inform the generation of responses. This process can be computationally intensive, especially when dealing with large datasets.\n",
            "\n",
            "2. **Lightweight Integration**: LightRAG proposes a more efficient way to incorporate retrieved information into the generative model. This involves optimizing the way documents are processed and reducing the computational overhead associated with traditional RAG methods.\n",
            "\n",
            "3. **Performance Improvements**: The paper demonstrates that LightRAG can achieve better performance on various benchmarks compared to standard RAG models. This includes improvements in accuracy, relevance, and coherence of generated text.\n",
            "\n",
            "4. **Scalability**: One of the main advantages of LightRAG is its scalability. By streamlining the retrieval and generation process, it can handle larger datasets and more complex queries without a significant increase in computational resources.\n",
            "\n",
            "5. **Applications**: The techniques developed in LightRAG can be applied to a wide range of natural language processing tasks, including chatbots, virtual assistants, and any application that requires generating text based on external information.\n",
            "\n",
            "### Conclusion:\n",
            "\n",
            "Overall, the LightRAG paper contributes to the field of natural language processing by providing a more efficient and effective method for integrating retrieval mechanisms into generative models. This advancement not only enhances the quality of generated responses but also makes the technology more accessible for real-world applications.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should search for research papers related to \"lightrag\" to provide an explanation.  \n",
            "Action: arxiv_search: lightrag  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running arxiv_search lightrag   --\n",
            "Next prompt: Observation: {\"title\": \"NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes\", \"summary\": \"Retrieval-augmented generation (RAG) empowers large language models to access\\nexternal and private corpus, enabling factually consistent responses in\\nspecific domains. By exploiting the inherent structure of the corpus,\\ngraph-based RAG methods further enrich this process by building a knowledge\\ngraph index and leveraging the structural nature of graphs. However, current\\ngraph-based RAG approaches seldom prioritize the design of graph structures.\\nInadequately designed graph not only impede the seamless integration of diverse\\ngraph algorithms but also result in workflow inconsistencies and degraded\\nperformance. To further unleash the potential of graph for RAG, we propose\\nNodeRAG, a graph-centric framework introducing heterogeneous graph structures\\nthat enable the seamless and holistic integration of graph-based methodologies\\ninto the RAG workflow. By aligning closely with the capabilities of LLMs, this\\nframework ensures a fully cohesive and efficient end-to-end process. Through\\nextensive experiments, we demonstrate that NodeRAG exhibits performance\\nadvantages over previous methods, including GraphRAG and LightRAG, not only in\\nindexing time, query time, and storage efficiency but also in delivering\\nsuperior question-answering performance on multi-hop benchmarks and open-ended\\nhead-to-head evaluations with minimal retrieval tokens. Our GitHub repository\\ncould be seen at https://github.com/Terry-Xu-666/NodeRAG.\"}\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: The paper titled \"NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes\" discusses a framework called NodeRAG, which enhances retrieval-augmented generation (RAG) by utilizing graph structures. It addresses the limitations of current graph-based RAG methods that do not prioritize the design of graph structures, which can lead to inefficiencies. NodeRAG introduces heterogeneous graph structures that improve the integration of graph methodologies into the RAG workflow, aligning with the capabilities of large language models (LLMs). The paper presents experimental results showing that NodeRAG outperforms previous methods, including LightRAG, in various performance metrics such as indexing time, query time, storage efficiency, and question-answering capabilities.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4th Qestion -- Difficult"
      ],
      "metadata": {
        "id": "vYyyYxBUElZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is AI Bites?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4EI_EeeE3Az",
        "outputId": "2bbce0ac-b2d2-4885-ea40-188b3b25600d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Bites is a term that can refer to short, digestible pieces of information or content related to artificial intelligence. This could include bite-sized articles, videos, podcasts, or social media posts that provide insights, updates, or explanations about AI concepts, technologies, trends, and applications. The goal of AI Bites is to make complex AI topics more accessible and understandable to a broader audience, allowing people to stay informed about developments in the field without needing extensive background knowledge. If you have a specific context or platform in mind for \"AI Bites,\" please let me know!\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should look up \"AI Bites\" on Wikipedia to find relevant information about it.  \n",
            "Action: wikipedia: AI Bites  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running wikipedia AI Bites   --\n",
            "Next prompt: Observation: &quot;Retrieval Augmented Generation(RAG) — A quick and comprehensive introduction&quot;. <span class=\"searchmatch\">ai</span>-<span class=\"searchmatch\">bites</span>.net. Kiela Douwe, Ho Alan (Oct 13, 2023). &quot;Where did Retrieval Augmented\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: AI Bites appears to be a platform or resource that provides quick and comprehensive introductions to topics related to artificial intelligence, such as Retrieval Augmented Generation (RAG).\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5th Question -- Difficult"
      ],
      "metadata": {
        "id": "K9708y5GZ0Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default answer is wrong. The answer after Wikipedia is write.\n",
        "question = \"Who is Alexander Tuzikov?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7L0v_Vt1Tn2",
        "outputId": "6a92c578-c794-4176-c17a-1b567bebd6d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last knowledge update in October 2023, there is no widely recognized public figure or notable individual named Alexander Tuzikov. It's possible that he may be a private individual or a person who has gained prominence after that date. If you have specific context or details about him, I may be able to provide more relevant information.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should search for information about Alexander Tuzikov on Wikipedia to find relevant details about him.  \n",
            "Action: wikipedia: Alexander Tuzikov  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running wikipedia Alexander Tuzikov   --\n",
            "Next prompt: Observation: Ryabova (Deputy Minister of Communications and Informatization), <span class=\"searchmatch\">Alexander</span> <span class=\"searchmatch\">Tuzikov</span> [ru] (General Director of the United Institute of Informatics Problems\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: Alexander Tuzikov is the General Director of the United Institute of Informatics Problems.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Здесь ответ по умолчанию неверный, но после уточнения в Википедии -- верный.\n",
        "question = \"Кто такой Александр Васильевич Тузиков?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_37Ldd2efIxy",
        "outputId": "2839e42c-c13c-436b-9c1b-8518e9ac227c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Александр Васильевич Тузиков — это российский ученый, специалист в области физики и материаловедения. Однако, на момент моего последнего обновления информации в октябре 2023 года, нет широко известных данных о его деятельности или достижениях. Возможно, он является менее известной фигурой или работает в узкой области, не получившей широкой огласки. Если у вас есть конкретные вопросы о его работе или вкладе, пожалуйста, уточните, и я постараюсь помочь!\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: Я должен поискать информацию о Александре Васильевиче Тузикове в Википедии, чтобы узнать о нем больше.  \n",
            "Action: wikipedia: Александр Васильевич Тузиков  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running wikipedia Александр Васильевич Тузиков   --\n",
            "Next prompt: Observation: <span class=\"searchmatch\">Александр</span> <span class=\"searchmatch\">Васильевич</span> <span class=\"searchmatch\">Тузиков</span> (род. 5 сентября 1958 года, Полоцк) — белорусский учёный, c 2008 по 2022 год -генеральный директор Объединенного института\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: Александр Васильевич Тузиков (род. 5 сентября 1958 года, Полоцк) — белорусский учёный, который с 2008 по 2022 год занимал должность генерального директора Объединенного института информатики.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrong answer\n",
        "question = \"What are the scientific works of Alexandra Kosareva?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOzPc2-0aUFc",
        "outputId": "86c7b37c-9ac1-4662-c54c-7c3ec3c5e925"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last update in October 2023, I do not have specific information on the scientific works of Alexandra Kosareva. To find her publications or contributions to scientific research, I recommend checking academic databases such as Google Scholar, PubMed, or ResearchGate. You can also look for her work in university repositories or specific journals related to her field of study. If you have more context about her area of research, I might be able to provide more targeted advice on where to look.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should search for scientific works related to Alexandra Kosareva to provide relevant information.  \n",
            "Action: arxiv_search: Alexandra Kosareva  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running arxiv_search Alexandra Kosareva   --\n",
            "Next prompt: Observation: {\"title\": \"On some properties of Hopf manifolds\", \"summary\": \"We review old and new properties of Hopf manifolds from the point of view of\\ntheir analytic and metric structure.\"}\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: One of the scientific works of Alexandra Kosareva is titled \"On some properties of Hopf manifolds,\" which reviews both old and new properties of Hopf manifolds, focusing on their analytic and metric structure.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrong answer\n",
        "question = \"What are the scientific works of Dzmitry Paulenka?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLdKLjnAczeh",
        "outputId": "bc11a26b-0636-4727-b402-d60a59bee744"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last update in October 2023, I do not have specific information on the scientific works of Dzmitry Paulenka. To find his publications or contributions to scientific research, I recommend checking academic databases such as Google Scholar, ResearchGate, or institutional repositories. You can also look for his work in relevant journals or conference proceedings in his field of expertise. If you have access to a university library, they may also provide resources to help you find his research.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: I should search for scientific works related to Dzmitry Paulenka to gather relevant information.  \n",
            "Action: arxiv_search: Dzmitry Paulenka  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running arxiv_search Dzmitry Paulenka   --\n",
            "Next prompt: Observation: {\"title\": \"Homeomorphisms between limbs of the Mandelbrot set\", \"summary\": \"We prove that for every hyperbolic component of the Mandelbrot set, any two\\nlimbs with equal denominators are homeomorphic so that the homeomorphism\\npreserves periods of hyperbolic components. This settles a conjecture on the\\nMandelbrot set that goes back to 1994.\"}\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: One of the scientific works of Dzmitry Paulenka is titled \"Homeomorphisms between limbs of the Mandelbrot set.\" In this work, he proves that for every hyperbolic component of the Mandelbrot set, any two limbs with equal denominators are homeomorphic, and the homeomorphism preserves the periods of hyperbolic components. This research settles a conjecture on the Mandelbrot set that dates back to 1994.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Здесь ответ по умолчанию более подробный и полный, чем после поиска в Википедии.\n",
        "question = \"Что такое эффект зловещей долины?\"\n",
        "run_tests(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8HOveX8dywS",
        "outputId": "db6af7d2-0f58-47fe-c52b-9f972a781e90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эффект зловещей долины (или \"uncanny valley\" на английском) — это концепция, описывающая реакцию людей на роботов, анимацию или другие искусственные объекты, которые выглядят почти, но не совсем, как реальные люди. Когда внешний вид объекта становится всё более похожим на человеческий, наша реакция к нему становится положительной, но только до определённого момента. Если объект становится слишком похожим на человека, но всё же имеет некоторые отличия (например, неестественные движения, выражения лиц или детали), это может вызывать у людей чувство дискомфорта или даже отвращения.\n",
            "\n",
            "Термин был введён японским робототехником Масахиро Мори в 1970-х годах. Эффект зловещей долины имеет важные последствия в области дизайна роботов, анимации, видеоигр и виртуальной реальности, поскольку создатели стремятся создать более естественные и привлекательные образы, избегая при этом \"долины\", где возникает негативная реакция.\n",
            "\n",
            "----------\n",
            "\n",
            " Iteration: 1 \n",
            "\n",
            "Thought: Я должен поискать информацию о \"эффекте зловещей долины\" в Википедии, чтобы предоставить точное определение.  \n",
            "Action: wikipedia: Эффект зловещей долины  \n",
            "PAUSE\n",
            "\n",
            "\n",
            " -- running wikipedia Эффект зловещей долины   --\n",
            "Next prompt: Observation: <span class=\"searchmatch\">Эффе́кт</span> «<span class=\"searchmatch\">злове́щей</span> <span class=\"searchmatch\">доли́ны</span>» (яп. 不気味の谷 букими но тани, англ. uncanny valley) — явление, основанное на гипотезе, сформулированной японским учёным-робототехником\n",
            "\n",
            " Iteration: 2 \n",
            "\n",
            "Answer: Эффект зловещей долины (яп. 不気味の谷, англ. uncanny valley) — это явление, основанное на гипотезе, сформулированной японским учёным-робототехником, которое описывает реакцию людей на роботов или анимацию, которые выглядят почти, но не совсем как люди, вызывая чувство дискомфорта или отторжения.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfMWhsFoh4YP"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}